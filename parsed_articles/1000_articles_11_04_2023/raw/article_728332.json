{
    "article_id": "728332",
    "article_name": "Мгновенное создание видео — следующий скачок в ИИ-технологиях",
    "content": "Видео по запросу «корова на вечеринке по случаю дня рождения»\nСначала был текст. GPT-1 в OpenAI создали еще в 2018-м. Потом появились картинки. Midjourney, Dall-E 2 и Stable Diffusion внезапно ворвались в нашу жизнь в прошлом году. Логично, что следующим шагом будет видео. Реалистичные ролики, сгенерированные искусственным интеллектом по любому запросу. В идеале — чтобы в ТикТоке или Ютубе трудно было отличить, что снято человеком, а что сделал ИИ.\nИ мы уже твердо стоим на этом пути. Стартап Runway AI в Нью-Йорке — одна из компаний, разрабатывающих ИИ, способный создавать короткие видеоролики на основе нескольких слов. У них уже есть первые результаты работы своей модели, и… они довольно странные, скажем так.\nОсторожно, в тексте есть сгенерированные видео, так что он довольно весомый.\nЯн Сансавера, архитектор ПО нью-йоркского стартапа Runway AI, печатает краткое описание того, что он хотел бы увидеть в видео: «Спокойная река в лесу».\nМеньше чем через две минуты экспериментальный интернет-сервис создает для него такой ролик. Бегущая вода реки блестит на солнце, проходя мимо деревьев и папоротников, поворачивая за угол и мягко плещась о камни. Всё это выглядит слегка размытым, но на экране смартфона отличить такое от реальной реки, снятой с каким-то фильтром, — не так уж и просто.\n«Спокойная река в лесу», созданная ИИ-моделью Runway\nRunway является одной из нескольких компаний, разрабатывающих технологию ИИ, которая вскоре позволит людям создавать видео, просто вводя несколько слов в одно из полей на сайте. Это стартап на 40 человек, привлекший $95,5 млн. На днях он открыла свой сервис небольшой группе внешних тестировщиков, и процесс здесь максимально простой. Те вбивают свои запросы в сообщение Slack — и получают готовое видео, качество которого потом оценивают.\nЭто будет следующий этап в отраслевой гонке по созданию новых видов ИИ, готовых преобразить всё наше взаимодействие с Интернетом. Сейчас в этой гонке участвуют Google, Microsoft и ещё несколько десятков небольших стартапов. По мнению многих экспертов в индустрии, их технологии \"генеративного ИИ\" могут стать следующим большим рывком вперед, таким же важным, каким раньше стали смартфоны или веб-браузеры.\nСреди генеративных ИИ системы генерации видео — самые сложные. Но и, возможно, самые перспективные. Видеоконтента сейчас потребляется гораздо больше, чем текста и фото, вместе взятых (и не только в плане терабайт, но и в плане длительности просмотра). Ютуб, ТикТок и другие — это теперь в значительной части видео. Сейчас онлайн-видео \nсмотрят\n в среднем по 2 часа в день. Если удастся «откусить» хотя бы долю этого рынка, создавая не защищенный авторскими правами и почти неограниченный по длительности контент, это может значительно изменить всю онлайн-среду, с которой мы взаимодействуем.\nНу, или как минимум облегчит работу видеомонтажеров. Добывать бесплатные фрагменты на нужную тему для вставки или склейки станет намного проще. Кинематографисты и другие цифровые художники тоже получат в свои руки новый мощный инструмент.\nС другой стороны — люди уже переживают, что эти модели станут новым и быстрым способом создания трудно распознаваемой онлайн-дезинформации, мимикрирующей под что угодно, от новостей до внезапных кадров с места событий. Это с учетом того, что дипфейки уже заполонили всю сеть (особенно в сфере порно), а ИИ научились идеально имитировать звуки, так что\n \nвесь\n \nЮтуб\n уже как месяц\n \nзаполнен\n \nроликами\n \"Трамп против Байдена в <популярной онлайн-игре>\". Отличить, что правда, а что ложь, было трудно и до прихода генеративных ИИ. Сейчас, уже в ближайшие месяцы, это станет ещё в тысячу раз сложнее.\nВидео, созданное генеративным ИИ от Google\nGoogle и Microsoft на самом деле\n \nпредставили\n свои первые системы генерации видео в прошлом году, но не открыли их для общественности, потому что боялись, что эти системы в конечном итоге могут быть использованы для распространения огромных доз дезинформации. Как говорят, генератор искусственного интеллекта Google уже может создавать HD-видео 1280x768 со скоростью 24 кадра в секунду. Есть несколько демонстративных роликов и научная\n \nпубликация\n. Но протестировать всё это сами мы не сможем.\nВ то же время исполнительный директор Runway AI Кристобаль Валенсуэла говорит, что, по его мнению, такая технология слишком важна, чтобы держать ее в исследовательской лаборатории. Риски высоки, но навечно такое в ящик не запрешь. История учит нас, что прогресс не остановить, как бы мы ни боялись его последствий. «Это одна из самых впечатляющих технологий, которые были созданы за последние сто лет», — говорит Кристобаль. — «Нужно, чтобы люди действительно научились это использовать».\nТехнология Runway\nС одной стороны, если подумать, в возможности манипулировать видео нет ничего нового. Кинематографисты занимаются этим уже больше века. И с ИИ они уже тоже научились взаимодействовать: дипфейкам уже 7 лет. Но системы, подобные той, которую сделала Runway, могут полностью исключить навыки редактирования. Достаточно одного контекст-промпта (запроса) — и одного нажатия кнопки. Для создания роликов даже никакой софт скачивать не придется.\nИИ генерирует видео из любого короткого текстового описания. Лучше всего, если в сцене есть какое-то действие, но не чересчур много. Подойдет что-то вроде «дождливый день в большом городе», «встреча друзей в баре» или «собака с мобильным телефоном в парке». Карате или супергеройские сражения в стиле вселенной «Марвел» система анимировать пока не научилась. После введения текста достаточно нажать Enter, и модель сгенерирует видео через минуту или две.\nRunway предлагает свои решения через Slack. Чтобы создать видео, пользователи просто вводят краткие описания — так же, как если бы писали быстрые заметки\nТехнология умеет создавать вполне обычные изображения — скажем, кошку, спящую на ковре. В таком случае никаких движущихся элементов там присутствовать не будет (кроме, может быть, слегка вздымающейся, «дышащей» спины животного).\nПока что лучше всего у системы получается оформлять разные странные концепты, создавая забавные видео с фактурой, до которой человек бы просто не додумался. Выходит довольно уникально. Например, вот у нас есть «корова на вечеринке по случаю дня рождения». Почему день рождения у собаки, почему ей именно четыре года, где они находятся, что вообще происходит? Или это телёнок? А зачем тогда корова лижет свечу? В общем, чем страннее запрос — тем забавнее выходит результат. Там, где человек мог бы впасть в творческий ступор, ИИ бросается на амбразуру.\nПока что все видео длятся только четыре секунды, и, если присмотреться, получаются прерывистыми и размытыми. Выходит больше похоже на гифки, причем среднего качества. Иногда изображения странные, искаженные. Часто ИИ решает объединить животных, скажем собак и кошек, в одно целое с неодушевленными предметами, такими как мячи и смартфоны. Но при правильном промпте всё-таки могут выйти неплохие видеоролики. Плюс его всегда можно попросить что-то исправить или изменить.\nПока что, если вы увидите реалистичное видео с высоким разрешением — высок шанс, что оно настоящее. Но, учитывая продвижения Google и остальных только за последние месяцы, это изменится довольно быстро. Ждите, что в конце этого или в начале следующего года в Интернете появятся ролики, как будто снятые на камеру смартфона, демонстрирующие всплытие Ктулху у берегов Коста-Рики или приземление пришельцев рядом с панелькой в Чертаново. Люди, которые пропустили факт возникновения нового типа ИИ, первые несколько дней будут этому верить.\nКак и другие генеративные ИИ технологии, система Runway учится, анализируя цифровые данные — в данном случае фотографии, видео и подписи, описывающие, что в них содержится. Исследователи уверены, что если обучать эту технологию на всё больших объемами данных, её возможности быстро расширятся. Они рассчитывают, что скоро модель будет способна создавать профессиональные мини-фильмы с музыкой и диалогами. А дальше — можно уже пытаться создавать целые кинокартины. По сценариям, которые ей задают.\nКстати, писать эти сценарии уже довольно неплохо умеет ChatGPT…\nНесколько стартапов, в том числе OpenAI, выпустили похожую на Runway технологию, которая может генерировать неподвижные изображения из коротких подсказок. Например, так была сделана «фотография плюшевого мишки, катающегося на скейтборде на Таймс-сквер». А в прошлом месяце социальные сети запестрили\n \nизображениями\n «крутого» Папы Франциска в белом пуховике Balenciaga — удивительно модном наряде для 86-летнего понтифика. Эти изображения за 2 минуты сделал 31-летний строитель из Чикаго, зайдя на сайт Midjourney.\nДаже некоторые из экспертов в области искусственного интеллекта\n \nбыли\n \nобмануты\n этими четкими изображениями Папы Франциска. Не слишком невероятная картина, в высоком разрешении, да ещё и постится по тысячам разных аккаунтов. Это совершенно не то же самое, что дипфейки, которые можно было определить по разным угловатостям. Теперь одурачен может быть каждый. И ни одно изображение, которое мы видим в Интернете, нельзя принимать за чистую монету.\nА скоро такое будет и с видео.\nБудущее здесь\nMidjourney, создавшая «крутого Франциска», опирается на нейронную сеть, которая обучается на огромных объемах релевантных данных. Она ищет шаблоны, прочесывая миллионы цифровых изображений, а также текстовые подписи, которые описывают эти изображения. Когда кто-то описывает картинку для системы, она генерирует длинный список отдельных небольших функций, которые могут входить в этот образ. Одной из них может быть изгиб в верхней части уха собаки. Другой — край мобильного телефона или кусочек облачного неба. Затем вторая нейронная сеть, называемая диффузионной моделью, создает изображение и генерирует пиксели, необходимые для этих функций. В конечном итоге эти пиксели преобразуются в связное изображение.\nRunway AI работает на тех же принципах, только для движущихся изображений. Анализируя тысячи видеороликов, их технология учится объединять множество разрозненных элементов в цельную картинку, а потом — множество неподвижных изображений в одно цельное видео. Причем желательно так, чтобы изображения выстраивались в определенную последовательность, и получалась иллюзия движения. Вся сложность сейчас состоит в обучении модели так, чтобы она понимала взаимосвязь между кадрами и умела их согласовывать.\nА потом, когда это отполировано, придется ещё «внушить» ей кинематографическое чутье.\nРабота Runway AI по запросу «собака с мобильным телефоном в парке».\nПодобно ранним версиям таких инструментов, как DALL-E и Midjourney, технология пока что далека от идеала. Её функции могут спутаться, так что разные концепты сливаются в один. Скажем, если вы попросите плюшевого мишку, играющего в баскетбол, ИИ может выдать плюшевую игрушку-мутанта с баскетбольным мячом вместо руки. Или, если попросите собаку с мобильным телефоном в парке, она может дать вам щенка, держащего смартфон странными человеческими пальцами.\nНо эксперты считают, что они смогут сгладить недостатки, обучая свои системы на все большем количестве данных. И в конечном итоге технология сделает создание видео таким же быстрым и простым, как написание одного предложения.\nЕсли раньше для создания видео нам требовалась тяжелая дорогостоящая камера и несколько месяцев работы. А потом — как минимум несколько минут работы и хороший смартфон. То теперь достаточно будет любого браузера и пары секунд для введения промпта. Насколько это изменит наш мир — пока что даже сложно представить.\nА вы как думаете, за этим ли наше будущее?\nПромокод для читателей нашего блога!\n— \n15% на все тарифы VDS\n (кроме тарифа Прогрев) — по промокоду \nHabrFIRSTVDS\n.\n50 тысяч активных серверов и 10 тысяч клиентов, которые с нами больше 5 лет.\n \n ",
    "tags": [
        "chatgpt",
        "runway ai",
        "ии",
        "firstvds",
        "будущее"
    ]
}