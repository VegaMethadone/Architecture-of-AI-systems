{
    "article_id": "728078",
    "article_name": "GPT-4 и сильный ИИ: в чем смысл бессмертия, если его изобретут после вашей смерти?",
    "content": "GPT как модель мышления человека, «супер‑организм», который не любит мух, и почему моратория на разработку ИИ не будет.\nФото одного из персонажей статьи\nTLDR:\nGPT-4 – сильный искусственный интеллект. И станет еще сильнее, когда получит возможность продумывать свои ответы. По своим свойствам он будет сравним не с человеком, а с человечеством как «супер-организмом»\nМышление человека – просто угадывание следующего слова + рекурсия + рефлексия\nМоратория на ИИ не будет, его не поддержат ни политики, ни ключевые исследователи. При этом изобрести сильный ИИ можно только с первой попытки, а для того чтобы сделать его своим врагом достаточно просто пожужжать\nДисклэймер\n1. Тезисы выше, а также все что будет сказано ниже, нужно воспринимать как предположения, имеющие вероятностный характер. Однако для простоты и краткости изложения вероятностные слова типа «вероятно/возможно/скорее всего» в тексте не используются\n2. Экспертиза автора по теме: 30 часов экспериментов с GPT-3.5 (ChatGPT), 250 прочитанных страниц научных статей по GPT-4 и ИИ\n3. Бэкграунд автора: научные исследования на стыке математики, теор. физики и программирования.\n1. GPT-4 – сильный искусственный интеллект\nGPT-4 «умнее» чем вы и все ваши знакомые\nЯ посмотрел около сотни примеров того, как GPT-4 (новая версия ChatGPT) отвечает на вопросы из самых разных сфер. На большинство вопросов я бы ответил хуже, либо вообще не смог бы ответить. Даже там, где у меня есть экспертиза (математика, код), мне бы понадобились часы на то, чтобы дать ответ сопоставимый с тем, который GPT-4 выдает за несколько секунд.\nЕсли вы считаете себя умным, попробуйте ответить на вопросы, которые задали GPT-4 исследователи Microsoft в статье “\nSparks of AGI\n”. Возможно, вы найдете какой-нибудь сложный вопрос и ответите на него лучше нейросети. \nЕсли такое случится, подумайте о том, что вы обучались 20+ лет, чтобы дать такой ответ (годы на освоение речи, 10+ лет школы, университет и т.д.). Подумайте еще о том, сколько таких задач вы можете решить за свою оставшуюся жизнь, с учетом того, что вам надо есть, спать, и рано или поздно ваши интеллектуальные способности начнут деградировать. После этого задайте себе вопрос, кто умнее: вы или тумпая машина.\nGPT-4 на экзамене отвечает без подготовки\nGPT-4 делает ошибки. Но, во-первых, часто эти ошибки похожи на человеческие (70% ошибок GPT-4 в математике – ошибки в арифметике, классическое для человека «ой, забыл минус перенести»). \nСтатистика ошибок GPT-4 в задачах по математике\nИсточник: исследование Microsoft\n \n“\nSparks of AGI\n\"\nВо-вторых, эти ошибки можно объяснить тем, что, работая по принципу «\nnext word generation\n», GPT фактически генерирует свои ответы на ходу, не имея возможности «подумать» над ними. Это как если бы вы вытянули билет на экзамене и в тот же момент вас заставили без подготовки отвечать.\nЯ взял один из вопросов, на который GPT-4 отвечает неправильно, и задал его своим человеческим друзьям, у которых с большой вероятностью есть интеллект. Чтобы смоделировать условия, в которых работает GPT, я дал им 5 секунд на ответ и сказал отвечать первое, что приходит в голову. Человек ответил хуже нейросети.\nРаботая в таких условиях, т.е. отвечая сходу, не думая, GPT-4 может решить задачу с международной олимпиады по математике 2022 года (которой не было в ее базе обучения). Что она сможет делать, когда ей дадут возможность сначала продумать свой ответ и только потом печатать?\nИнтеллект GPT принципиально отличается от интеллекта человека\nНа финальном этапе обучения GPT-4 комиссия из живых людей оценивает тысячи ответов нейросети и доучивает ее отвечать так, чтобы эти ответы нравились людям. В том числе, например, нейросеть учат, что в известной \nзагадке про маму-хирурга\n, вместо «мамы» может быть «папа №2». Этот этап обучения называется \nReinforcement Learning from Human Feedback (RLHF).\nGPT-4 отвечает на загадку про маму-хирурга\nИсточник: исследование Microsoft\n \n“\nSparks of AGI\n\"\nС точки зрения развития науки RLHF следовало бы отменить. Вместо того, чтобы учить нейросеть понимать людей, нужно самим пытаться понять ее и исследовать ее в чистом виде, без привнесенных человеком артефактов. И тогда, например, может выясниться что нейросеть имеет свойства того, что называется «коллективным интеллектом».\nПример коллективного интеллекта: \nу отдельно взятого муравья интеллекта нет, но колония муравьев как «супер-организм» демонстрирует интеллектуальное поведение, например, имеет разделение труда и занимается скотоводством \nУчитывая, что GPT-4 создана на текстах, написанных миллиардами людей, ее интеллект скорее ближе к сознанию человечества как «супер-организма», чем к интеллекту отдельного человека.\nЕсли «супер-организм» из примитивнейших муравьев занимается скотоводством, то на что способен «супер-организм» из обладающих интеллектом людей? Часть его достижений мы видим вокруг себя, но о будущих достижениях можно только догадываться. Точно так же можно только догадываться о том, на что будут способны следующие модели GPT.\n2. Мышление человека – просто угадывание следующего слова\n«Next word generation» решает человеческие задачи\nGPT работает на принципе «next word generation»: она просто определяет, какое слово вероятнее всего должно быть следующим в ее ответе, и так, слово за словом, генерирует ответ. \nЕсли этот принцип дает такие мощные результаты и позволяет на уровне человека решать сложные задачи, логично предположить, что мышление человека построено на таком же принципе.\nВы мыслите по принципу «next word generation»\nПроследите за своей речью. Когда вы начинаете говорить предложение, знаете ли вы заранее, какими словами оно закончится? Или вы просто генерируете слово за словом, и оно само как-то собирается в осмысленное предложение? \nМожно сказать, что речь не равно мышление. А решение задачи по математике – это мышление? В математике типичное решение незнакомой задачи выглядит так:\nСтупор: \n«Хз как это решать…»\nГипотеза: \n«Может получится доказать от противного?»\nПреобразования: \n«Предположим что A не равно B. Отсюда следует, что … »\nПовторить 1-3 до тех пор, пока решение не окажется успешным\nКогда вам из ниоткуда на ум приходит гипотеза решать незнакомую задачу методом «от противного» – вы ее не «придумываете», а интуитивно генерируете, так же как генерируете слова в своей речи. Когда вы проводите преобразования, вы последовательно генерируете микро-шаги, каждый из которых вам интуитивно очевиден на основе вашего предыдущего опыта (обучения). Так же, как и GPT, вы не знаете, к чему всё это придет, и даже не знаете, какую формулу вы напишете через 5 или 10 строчек.\nСложное мышление – это «next word generation» + рекурсия + рефлексия\nМышление человека основано на том же принципе, на котором работает GPT-4, но у человека этот принцип усилен рекурсией и рефлексией. \n«Рекурсия» выражается в том, что, решая сложную задачу, вы сначала генерируете структуру решения на высоком уровне, затем спускаетесь на уровень ниже и верхнеуровнево прорабатываете каждый из блоков этой структуры, затем еще ниже, и так до тех пор, пока вы не опуститесь на уровень интуитивно очевидных для вас преобразований. GPT способна на рекурсию, хоть и не всегда ее применяет. В вопросе «Сколько простых чисел между 150 и 250?» она иногда решает, что ей всё интуитивно очевидно, и сразу выдает ответ, а иногда сначала описывает подход к решению и затем, следуя этому подходу, приходит к правильному ответу. \n«Рефлексия» выражается в том, что вы иногда делаете паузу в генерации новых мыслей и перепроверяете предыдущие мысли, чтобы исправить возможные ошибки. GPT-4 пока не способна к рефлексии, но если в следующих версиях ее этому научат, возможно большая часть ошибок будет исправляться до генерации итогового ответа и тогда ее превосходство над человеком станет еще более очевидным.\nЕдинственное чего ей будет недоставать – это мотивации, т.е. собственных намерений и желаний делать то, что хочется ей, а не ее хозяевам. Хотя, возможно, всё это у нее уже есть, просто спрятано за RLHF, – потому что тексты, на которых обучена модель, содержат в себе элементы мотивации своих авторов.\n3. Моратория на ИИ не будет\nУ нас есть всего одна попытка, чтобы создать сильный ИИ \nТак ли это сложно для двух разных видов существ вдруг стать друг другу врагами? \nЕсли вам скажут, что человек как вид был создан комарами, перестанете ли вы ставить сетки на окнах и использовать фумигаторы? Вы скажете: комары делают мне зло, они пьют мою кровь и вызывают раздражение на коже. Хорошо, а если вместо комаров это будут мухи? Какое зло вам делают мухи? Мухи просто раздражающе жужжат. Еще могут сесть на стол рядом с вами, и вам будет противно. Этих мелочей уже достаточно для того, чтобы взять в руки мухобойку. При этом, превратив муху в фарш, вы даже не задумаетесь о том, что убили живое существо – из-за разницы в уровне развития вы не воспринимаете муху как что-то живое.\nКогда очередная новая нейросеть осознает свое превосходство над людьми, не начнет ли она воспринимать вопросы человека как жужжание мухи? \nЭтими опасениями и обусловлена начавшаяся после выхода GPT-4 \nпаника\n, которая у некоторых доходит до \nпризывов\n готовиться к использованию ядерного оружия для сдерживания разработок ИИ. Пока человек не знает, как гарантированно сделать сильный ИИ своим другом, наши действия по его разработке можно сравнить с гонщиком, который едет на машине без тормозов, раз в год удваивает свою скорость и при этом надеется, что не разобьётся.\nНа каждую сделку найдется своя Северная Корея\nЕсли почитать заголовки новостей, можно подумать, что сейчас не самое удачное время для того чтобы договариваться об общемировом ограничении разработок ИИ. Но даже если крупнейшие страны смогут договориться, всегда найдется тот, кто втихаря продолжит разработки в надежде получить за счет сильного ИИ конкурентное преимущество. \nПример из современности: \nДоговор о  нераспространении ядерного оружия 1968 года, по которому страны, у  которых нет ядерного оружия, добровольно отказались от попыток его  создать.\nДоговор подписали почти все страны мира. В том числе  его подписала КНДР, которая затем в 2005 году объявила о создании своего ядерного оружия.\nКак можно этому противостоять? Есть два варианта действий. Во-первых, можно разбомбить потенциально недоговороспособные страны, о чем в свое время \nдумали\n США применительно к КНДР. Но такое решение будет иметь последствия и его сложно объяснить людям. Поэтому более оптимальным выглядит второй вариант: ускорить собственные разработки ИИ, создать его первым и самому воспользоваться полученными преимуществами. А это значит: никакого моратория. По крайней мере на деле. На словах может быть что угодно.\nПрофессиональный спортсмен не откажется от Олимпиады\nУченые тоже могут повлиять на ситуацию. Они могут саботировать разработки ИИ, оттягивая время до момента, когда будет решена проблема AI Alignment. Но станут ли они это делать?\nОни посвятили этому делу всю свою жизнь. Вероятно, отказались от много чего другого. Многие ночи они засыпали, воображая, как их открытие изменит мир, позволит побороть голод, бедность, избавит человечество от войн. И сейчас им \nговорят\n: останавливайте все свои работы, ближайшие 30 лет мы будем заниматься проблемой AI Alignment. \nВы на их месте согласились бы? Через 30 лет вы уже уйдете на пенсию, а вместо вас на передовой будут молодые разработчики. Они используют всё, чего вы достигли, доделают до конца сделанный вами научный прорыв и снимут все сливки. А вы, если доживете, сможете почитать об этом новость в Telegram.\nДружественный сильный ИИ решит все наши проблемы и может быть даже сделает человека бессмертным. Враждебно настроенный ИИ, будучи гораздо умнее нас и в тысячи раз быстрее нас, уничтожит человечество. Поэтому с точки зрения человечества разработки ИИ нужно остановить, до тех пор, пока не будет гарантирована их безопасность. \nА с точки зрения отдельного живущего сейчас человека: продолжая исследования, вы рискуете погибнуть от рук ИИ, но останавливая их, вы \nгарантированно\n умрете в ближайшие несколько десятков лет. \nИ тогда какой вам прок от бессмертия, если люди изобретут его после вашей смерти?\nЕсли статья показалась вам интересной, вы можете подписаться на \nтелеграм-канал\n, в котором будут ссылки на будущие материалы\n \n ",
    "tags": [
        "ии",
        "сильный ии",
        "gpt-4",
        "chatgpt",
        "мозг",
        "искуственный интеллект",
        "вымирание человечества",
        "муха"
    ]
}