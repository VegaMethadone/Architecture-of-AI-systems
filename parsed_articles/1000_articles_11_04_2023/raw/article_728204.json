{
    "article_id": "728204",
    "article_name": "Производительность и стабильность Knime на слабых компьютерах",
    "content": "Наступают времена, когда офисному сотруднику недостаточно знать Word и Excel в качестве минимального обязательного базиса программных продуктов. No‑code/Low‑code платформы и продукты — вот что незаметно становится обязательным для владения каждым. Эти платформы есть самый быстрый на сегодня способ без изучения языков программирования овладеть навыками использования искусственного интеллекта, машинного обучения, анализа big data, причём очень бигдата — на сотни миллионов строк.\nПлатформа Knime — один из таких инструментов. На первый взгляд это улучшенный Excel+BI. Но, когда посмотришь поглубже его возможности, то, очевидно — это обязательный инструмент будущего, по крайней мере для тех кто не являясь программистом хочет получить навыки как у программиста. Для простоты — Knime это «графическое» программирование. Берёшь квадратики, размещаешь в виде бизнес‑процесса, соединяешь их между собой и оп! — уже провёл анализ маркетингового плана или парсинг сайтов конкурентов или анализ рекламных текстов с помощью NLP. Или, даже строишь приборную доску управления производственного предприятия будучи простым менеджером/инженером. Или ведёшь обработку научных данных.\nKnime позволяет, конечно, и код писать, причём на трёх языках Python, Java, R, но это не обязательно. Бизнес‑процессы знаешь, рисуешь? Вперёд!\nРазумеется, при работе с огромными массивами данных, требования к компьютерным ресурсам возрастают. И что делать, если вам доступен простенький офисный или домашний компьютер? Или, если вы видите что аренда облачного ресурса на месяц дороже, чем купить компьютер с 64Гб оперативной памяти и процессором гоняющим Atomic Heart или Hogwartz Legacy на среднемалках?\nИ опять всё вам доступно и бесплатно доступно. Ниже пойдёт описание как решалась задача обработки сотни миллионов строк исходных данных на бюджетном компьютере. На её примере вы можете сделать прикидки какой объём данных сможет осилить ваш компьютер.\nИтак.\nВозникла необходимость обрабатывать порядка 75 000 файлов XML в каталогах на локальном компьютере.\nРазмеры файлов от 1 Кб до 121Мб.\nИз одного файла могут извлекаться от одной строки до 6,4 миллионов строк.\nВ итоге суммарное количество строк в одной таблице составило около 225 миллионов строк.\nИспользуемый компьютер\n — домашний десктоп со следующими характеристиками:\nпроцессор AMD Athlon 3000G (2 ядра, 4 потока);\nоперативная память 16Гб, в том числе 2Гб зарезервированы под графическую обработку;\nграфической карты нет, все расчёты выполняет процессор;\nбюджетная материнская плата Gigabyte A520M DS3H;\nхранение информации на nvme SSD Netac, сохранение конечных файлов на HDD 5400 об/мин;\nразгон процессора и оперативной памяти не производился;\nоперационная система — Windows.\nКак видите, компьютер обычный офисный и слабый для обработки таких объёмов данных.\nС другой стороны, какими бы мощными не были ваш компьютер, сервер или облако, жизнь всегда подкидывает задачи на грани возможностей имеющейся техники.\nИ вот опять умение выжимать из имеющегося всё возможное актуально.\nЗадача\n состояла в том чтобы:\nпострочно считать файлы в таблицу;\nобработать строки (вынести теги xml и тела тегов в отдельные колонки, а также в отдельные колонки вывести имена параметров xml и их значения).\nЦель\n: Подготовить массив данных из xml для машинного обучения.\nКакие проблемы надо было решить на низко производительном компьютере:\n1) обработать массив в несколько сотен миллионов строк;\n2) избежать вылетов из-за переполнения памяти;\n3) отнять часть ресурсов компьютера у Knime, чтобы без зависаний и торможений позволить выполнять за компьютером другую работу, пока обрабатывались данные в Knime.\nТеперь рассказ как этого удалось добиться\n.\nНа представленной вам картинке вы видите организацию рабочего потока в knime-workflow\nВручную задаются ноды (те самые квадратики) с каталогами с файлами‑источниками и временный каталог для хранения результатов.\nПри чтении файлов происходит их фильтрация по типу и регулярным выражениям, применяемым к пути и именам файлов.\nСчитывание файлов происходит в узле Line Reader.\nСчитывание и обработка списка файлов ведётся в одном потоке.\nОбработка файлов построчно разделена на два потока — поток файлов большого размера (от 1Мб, отсортированы по убыванию) и поток файлов малого размера (до 1Мб, отсортированы по возрастанию). \nРазмеры файлов в двух потоках разнонаправлены. Два потока и разнонаправленность дали увеличение производительности на одном процессоре более чем в 2 раза по сравнению с однопотоковой обработкой.\nРазделение файлов на два потока по границе в 1Мб мною сделано условно на примере моих данных. Вам же стоит попробовать сделать разделение на основе медианы размеров файлов. Главная цель, чтобы разнонаправленные потоки создали равномерную загрузку компьютера.\nНастройка Knime Preferences — Maximum Working threads for all nodes на примере обработки порядка двух миллионов строк даёт следующие расклады затрат времени:\n3 треда — 1 минута.\n24 треда — 1,065 минуты.\n100 тредов — 0,7 минуты.\nПопытка включить в нодах режим Job manager вместо default на streaming привела только к ухудшению производительности и удлинению общего времени исполнения. Видимо, причина в том, что не все ноды в линии умеют работать в таком режиме.\nПопытка включить в workflow режим Table Backend в положение Columnar Backend вместо default привела только к ухудшению производительности и удлинению общего времени исполнения. Видимо, причина в том, что режим Columnar Backend эффективен в случаях, когда в таблицах много столбцов и мало строк. А у меня ситуация другая — в таблице не более двух десятков столбцов и сотни миллионов строк.\nПараметр knime.ini\n‑Dknime.compress.io \nустановлен в NONE для уменьшения потерь времени на сжатие временных данных. Памяти в 16Гб уже достаточно.\nПосле считывания всех файлов в строки одной таблицы, поток нод с большими файлами заключен в цикл из нод Chunk Loop Start и Loop End, так как обработка строк порциями показала себя быстрее, чем обработка одной таблицы в 225 миллионов строк в один проход. Выигрыш примерно до 2х крат по времени.\nРекомендую пробовать разные chunk на своих компьютерах, поскольку, chunk снижает вероятность вылета Knime на компьютерах с малой памятью.\nChunk в 100 000 строк обычно себя оправдывает, но иногда лучше работает chunk в 1 миллион строк, особенно на сотнях миллионов строк данных. Видимо, потому что сокращается количество итераций и связанных с этим операций.\nОбщий ориентир при определении размера chunk — желательно, чтобы цикл исполнялся за несколько десятков итераций.\nЕсли число итераций цикла достигает нескольких тысяч повторений, то вероятность вылета Knime повышается.\nТаким образом, на миллионы строк в таблице хорош chunk в 100 000 строк (при этом chunk в 1 000 000 работает не хуже), а для таблицы в сотни миллионов строк — chunk в 1 000 000 строк надёжнее.\nРанее ноды Run Garbage Collector вставлялись мною специально, так как их применение исключило вылеты Knime из‑за переполнения памяти. Эти ноды сработали уже на оперативной памяти в 16Гб и позволили процессу доходить до конца. Успешное прохождение процесса стало гарантированным. \nС ними можете на компьютере с работающим процессом Knime выполнять другую работу. При этом, Knime может подвисать, но не останавливать работу, а подвисания всего компьютера редки и кратки.\nНо это оправдывало себя на примерах в миллионы строк.\nНо в примерах на сотни миллионов строк ноды сбора мусора стали приводить к регулярным зависаниям Knime и переключения между другими программами. Видимо, причина в том, что нода Run Garbage Collector не очень хорошо понимает, что есть мусор, а что пока ещё нужные временные данные, и удаляла их, из‑за чего Knime тратил ресурс компьютера на восстановление ситуации.\nРабота с нодами Garbage Collector замедлила работу процесса в 7 раз как минимум, чем без них.\nПо ходу работы объём оперативной памяти был увеличен до 80Гб. К сожалению, не сохранил замеры, в чем выразилось изменение производительности по сравнению с 16Гб. Но субъективно ничем особо лучше не стало. Памяти Knime всё равно хочет больше.\nБыло поставлено принудительное ограничение размера кучи до 8Гб (при памяти в 16Гб) и до 50Гб сейчас при памяти 80Гб. Это ограничение работает постоянно. В диспетчере задач Windows также был понижен приоритет процесса Knime до «ниже среднего», а в «Задать сходство» оставлены для knime только 3 потока из 4. Это ограничение не сохраняется при перезагрузке компьютера. Ограничения введены сознательно, чтобы пользоваться компьютером без зависаний и тормозов во время вычислений Knime.\nНода Variable Expression служит для формирования имён выходных файлов в цикле, вставляя в имя файла номер итерации цикла.\nНоды Chunk Loop Start и Loop End занимают очень много времени.\nChunk Loop Start, похоже, для каждого chunk создаёт пустую таблицу на заданное количество строк, а потом заполняет её данными из обрабатываемой таблицы. Кажется не очень оптимальным вместо простого вырезания из основной таблицы нужного блока.\nВ ноде Loop End происходит склеивание общего результата работы цикла в общую таблицу. Поэтому лучше её заменять на ноду Variable Loop End, так как она не собирает итоговые таблицы, а только переменные.\nРанее, после ноды завершения цикла, стояла нода записи результата в файл. Но при 225 млн строк, размер конечного файла занимает порядка 8Гб и крайне длительное время записи на диск. Поэтому была введена запись результата внутри цикла в отдельные файлы поменьше. Для дальнейшей обработки это будет также в лучшую сторону влиять на производительность.\nОбщее время обработки 225 млн. строк при chunk = 1 000 000 строк занимает при указанных выше условиях 11 часов (Нет! Меньше! см. далее). (Но, кажется, мой компьютер схитрил, при долгой отлучке он ушёл в гибернацию и при пробуждении Knime продолжил как ни в чём не бывало, но часа 2 надо убавить, итого 9 часов).\nОбщее время обработки около 2 млн. строк при chunk = 100 000 строк занимает при указанных выше условиях 0,5 минуты.\nОбщее время обработки около 2 млн. строк при chunk = 1 000 000 строк занимает при указанных выше условиях 1 минуту.\nИ да! Я выяснил, что Knime хитрец! Оказывается при переходе компьютера в гибернацию (а также, кажется, что и в сон) он приостанавливает работу. При пробуждении из гибернации он мгновенно начинает работу и кажется что он не прерывался.\nА я удивлялся, откуда при объективном времени работы в 9–11 часов, статистика Knime показывала 4–5 часов работы или менее.\nНоды статистики учитывают только время реальной работы ноды, а не время с начала процесса.\nФайл описанного процесса Knime, какой он получился в итоговом виде прилагается (см. картинку выше).\nПрилагается также файл статистики работы процесса knime для процесса в 223 млн. строк.\nТам вы можете увидеть, какие ноды занимают больше всего времени.\nВ результате, после многих попыток и вариантов обработки 225 млн. строк обрабатываются за 2,5 часа (по замерам Knime это 55 минут).\nЗная, какой у меня процессор, вы можете зайти на \nсайт \nили аналогичный и сравнить со своим процессором и по бенчмаркам прикинуть во сколько раз медленнее или быстрее ваш процессор обработает подобную задачу. \nПо итогам этого моего опыта с Knime выгоднее инвестировать в самый производительный процессор, чем в память. По данным наблюдения за производительностью в диспетчере задач Knime съест любую память, ему и 80Гб мало, поэтому его кучу придётся ограничивать по любому. А вот процессор явно не успевает за обработкой даже при памяти в 16Гб.\nПолитика памяти workflow установлена на \"размещать в памяти\". Попытка всем нодам назначить \"размещать на диске\" явного эффекта не дала и на переполнение оперативной памяти особо не влияет. Запись промежуточных выходных данных на диск внутри цикла показала себя более эффективной.\nПрактика показала, что запись в итоговый файл обработанных результатов при размере файла более 1Гб (а у меня выходило по 8Гб) занимает чрезвычайно много времени. Поэтому, если вы собираетесь подвергать обработанные данные ещё дальнейшей обработке, то лучше записывать в файлы меньшего размера. Отсюда вывод - chunks надо делать таким, чтобы в отдельный файл попадало порядка 1 миллиона строк, не больше. Точное число зависит от вашего компьютера, скорости вашей дисковой системы.\nЯ в итоге даже в ветке обработки малых файлов переделал окончание процесса на дробное записывание итога основного цикла через цикл с chunk.\nВесь процесс написан на Knime без единой строчки кода. \nНи один питон, джаба и R не пострадали при этом эксперименте.\nВот такой расклад.\nЯ новичок в Knime, первый месяц изучаю его. Буду рад подсказкам, что можно сделать лучше в Knime, как эффективнее построить процесс и ноды.\nОсобенно буду признателен, если кто подскажет, как настроить Apache Spark в домашней локальной сети под Windows, чтобы распределить вычисления Knime на домашние компьютеры без сервера Knime.\nОперативно связаться со мной можно в Telegram https://t.me/RomanKlmnsn или там же в чате https://t.me/SPPR_1C\nИли написать здесь. \nДополнительная информация по производительности\nСтатистика по 1 потоку на 2 миллиона строк и chunk 1 миллион строк:\nСтатистика по 1 потоку на 223 миллиона строк и chunk 1 миллион строк:\n \n ",
    "tags": [
        "knime",
        "mashine-learning",
        "nlp (natural language processing)",
        "r lang",
        "no-code",
        "low-code",
        "производительность",
        "личная эффективность",
        "must have",
        "знать обязательно!"
    ]
}