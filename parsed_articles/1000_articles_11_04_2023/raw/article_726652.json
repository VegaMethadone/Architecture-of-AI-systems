{
    "article_id": "726652",
    "article_name": "Создаем чат-бот для распознавания изображений на основе нейронной сети MobileNetV2",
    "content": "Автор статьи: Виктория Ляликова\nВсем привет! Сегодня рассмотрим решение задачи многоклассовой класификации на основе датасета овощей и фруктов с помощью сверточной нейронной сети архитектуры MobileNetV2. А после этого еще создадим чат-бота, который будет классифицировать эти изображения.\nСегодня уже никого не удивишь чат-ботами, которые могут вести диалоги на естественном языке. В наши дни уже даже школьников учат создавать своих чат ботов. А почему бы тогда не создать бота, который может видеть. Рассмотрим процесс создания пока самого простого  бота, который будет в качестве сообщения принимать фото и отвечать, что на нем изображено. \nПосле поисков набора данных по классификации изображений (распознавание цветов, животных, типа раковых опухолей и т.д.), я остановила свой выбор на датасете, который содержит различные изображения фруктов и овощей, состоящий из 36 классов. При дальнейшей доработке, такого бота можно использовать для поиска рецептов на основе нескольких изображений.\nДатасет “Fruits and Vegetables Image Recognition” доступен на \nKaggle.com\n и состоит из 3825 изображения таких фруктов и овощей как банан, яблоко, груша, виноград, апельсин, киви, арбуз, гранат, ананас, манго, огурцы, морковь, стручковый перец, лук, картофель, лимон, помидоры, редька, свекла, капуста, салат, шпинат, соевые бобы, цветная капуста, болгарский перец, перец чили, репа, кукуруза, сладкая кукуруза, сладкий картофель, паприка, халапеньо, имбирь, чеснок, горох, баклажан. Все данные содержат по 100 изображений для обучения, по 10 изображений для валидации и по 10 изображений для тестирования (в некоторых папках немного меньше).\nПриступаем к решению задачи многоклассовой классификации. Загружаем необходимые библиотеки,  определяем пути к изображениям и определяем некоторые параметры.\nimport cv2\nimport pathlib\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import Callback, ModelCheckpoint,EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.mobilenet_v2 import MobileNetV2\nfrom tensorflow.keras.applications import mobilenet_v2\nfrom tensorflow.keras import layers\n\n# директория обучения\ntrain_dir = pathlib.Path(\"***/datasets/fruits1/train/\")\n# директория тестирования\ntest_dir = pathlib.Path(\"***/datasets/fruits1/test/\")\n# директория валидации\nval_dir = pathlib.Path(\"***/datasets/fruits1/validation/\")\nimg_height = 224\nimg_weigth = 224\nЗагружать изображения будем с помощью полезной утилиты \nimage_dataset_from_directory\n библиотеки \nkeras.preprocessing\n (вернет \ntf.data.Dataset\n), которая возвращает пакеты изображений из подкаталогов вместе с метками классов. Сохраним все классы овощей и фруктов в списке \nclass_names\n.\ntrain_ds = tf.keras.utils.image_dataset_from_directory(train_dir)\ntest_ds = tf.keras.utils.image_dataset_from_directory(test_dir)\nval_ds = tf.keras.utils.image_dataset_from_directory(val_dir)\nclass_names = dict(zip(train_ds.class_names, range(len(train_ds.class_names))))\nnum_classes = len(class_names)\nВсего 36 классов. Посмотрим на изображения\nДля работы с изображениями очень хорошо подходят сверточные нейронные сети, поэтому за основу возьмем MobilenetV2, предобученную на большом количестве изображений из базы ImageNet. MobileNetV2 является облегченной глубокой нейронной сетью, которая использует сверточные блоки глубиной 53 слоя.\nСеть имеет 2 типа блоков: один остаточный блок с шагом 1 (на рисунке слева), другой блок с шагом 2 для уменьшения размера (на рисунке справа). \nКаждый блок имеет 3 различных слоя:\nСвертка 1х1 имеет активационную функцию Relu6 (f(s)=max(0,6))\nГлубинная свертка\nСвертка 1х1 без линейной функции\nПеред тем, как загружать изображения в нашу предобученную нейронную сеть, их необходимо преобразовать в формат, который принимает наша модель, то есть перевести в тензоры с плавающей точкой, а затем произвести нормализацию изображений из интервала от 0 до 255 к интервалу от 0 до 1.Это можно сделать с использованием класса ImageDataGenerator. Данный класс удобен и полезен тем, что берет изображения прямо из папок, а также позволяет расширить набор данных за счет создания копий изображений, изменяя различные свойства изображения (смещение, поворот, увеличение и т.д.). Такой подход позволяет модели лучше обобщать и извлекать различные признаки. Достаточно передать конструктору класса набор различных значений необходимых нам параметров и обо всем он позаботится сам.\ntrain_generator = ImageDataGenerator(\npreprocessing_function = mobilenet_v2.preprocess_input,\nrotation_range = 32,\nzoom_range = 0.2,\nwidth_shift_range = 0.2,\nheight_shift_range = 0.2,\nshear_range = 0.2,\nhorizontal_flip = True,\nfill_mode = \"nearest\")\nТак как используется предобученная нейронная сеть, тогда для перевода изображений в тензоры с плавающей точкой будем использовать готовый метод \nmobilenet_v2.preprocess_input\nТеперь воспользуемся методом \n.flow_from_directory\n для применения полученного преобразования к нашим изображениям из обучающего и валидационного набора данных. \ntrain = train_generator.flow_from_directory(train_dir,\ntarget_size = (img_height,img_width),\n# изображение имеет 3 цветовых канала\ncolor_mode = \"rgb\",\n# создаем бинарные признаки меток класса \nclass_mode = \"categorical\",\nbatch_size = 32,\nshuffle = True,\nseed = 123)\n\nvalidation = train_generator.flow_from_directory(val_dir,\ntarget_size = (img_height,img_width),\n# изображение имеет 3 цветовых канала\ncolor_mode = \"rgb\",\n# создаем бинарные признаки меток класса \nclass_mode = \"categorical\",\nbatch_size = 32,\nshuffle = True,\nseed = 123)\nЗдесь можно обратить внимание, что указан параметр shuffle = True, что говорит о том, что изображения из разных классов не будут перемешиваться. Сначала будут поступать изображения из первой папки, потом из второй и т.д, а затем из последней. Это необходимо, чтобы мы могли потом легко обращаться к меткам класса. \nПерейдем к построению модели. Загружаем предварительно обученную версию сети с размером входного изображения (224, 224, 3) с весами “imagenet”.\nmobilenet_ = MobileNetV2(\ninput_shape = (img_height,img_width,3),\ninclude_top = False,\nweights = 'imagenet',\npooling = 'avg')\nБлокируем возможность изменения значений переменных предобученной модели и оставляем возможность обучаться только последним слоям классификации.\nmobilenet_.trainable = False\nСоздаем 2 обычных слоя с 128 нейронами и один последний слой классификации, с количеством нейронов равных количеству необходимых нам классов и активационной функцией \nsoftmax\ninputs = mobilenet_.input\nx = Dense(128, activation = 'relu')(mobilenet_.output)\nx = Dense(128, activation = 'relu')(x)\noutputs = Dense(num_classes , activation = 'softmax')(x)\nСобираем модель сети,состоящую из предобученной модели и добавленных новых слоев.\nmobilenet = Model(inputs = inputs, outputs = outputs)\nИспользуем метод \nModelCheckpoint\n для сохранения весов модели, основываясь на потерях на этапе проверки и метод EarlyStopping для ранней остановки обучения\nearly_stopping = EarlyStopping(\n\tmonitor='val_loss',\n\tmode='min',\n\tpatience = 2,\n\tverbose=1,\n\trestore_best_weights=True,\n)\ncheckpoint =ModelCheckpoint('***/fruit224mobile.h5',\n                        \tmonitor = 'val_loss',\n                        \tmode = 'min',\n                       \tsave_best_only = True)\n\ncallbacks = [early_stopping, checkpoint]\nКомпилируем и подгоняем модель, используя оптимизатор Адама и категориальную перекрестную энтропию.\nmobilenet.compile(optimizer=’’, loss ='categorical_crossentropy',metrics = ['accuracy'])\n\nhistory = mobilenet.fit(\ntrain, validation_data = validation,\nbatch_size = 32,\nepochs = 20,\ncallbacks = callbacks)\nОценим модель на тестовых данных, используя метод “evaluate”\n(eval_loss, eval_accuracy) = mobilenet.evaluate(test)\nПосмотрим на точность на тестовых значениях\n# получаем предсказанные значения от тестовых изображений\npred = mobilenet.predict(test)\n# получаем номер класса с максимальным весом\npred = np.argmax(pred,axis=1)\n# сопоставляем классы\nlabels = (train.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npred = [labels[k] for k in pred]\n# получаем предсказанные классы\ny_test = [labels[k] for k in test.classes]\n# оцениваем точность\nfrom sklearn.metrics import accuracy_score\nacc = accuracy_score(y_test, pred)\nprint(f'Accuracy on the test set: {100*acc:.2f}%')\nОтличный результат, то есть теперь модель обучена, веса сохранены. \nПереходим к работе с чат-ботом. Прежде чем начинать разработку, бота необходимо зарегистрировать и получить его уникальный id. При этом владельцем бота будет тот, с чьего аккаунта он создавался.  Для создания своего бота в Telegram есть специальный бот-\n@BotFather\n. Находим его и подтверждаем начало диалога, набрав команду \n/start.\n \nДалее вводим команду \n/newbot\n, вводим имя бота (MyTestbot) и username бота (RecFood_bot). Username должен обязательно заканчиваться на bot и быть уникальным.\nДля работы с ботом будем использовать библиотеку aiogram. Она предоставляет множество удобных функций для управления ботом, обработки событий, работы с клавиатурами, интеграции с другими сервисами и т.д. Установим ее\npip install aiogram\nДалее для работы с ботом нам понадобится Токен бота, который является его уникальным идентификатором, его предоставляет BotFather при создании бота.\nТакже для работы с ботом нам понадобятся классы Bot, Dispatcher, executor, types.\nBot - это класс, который отвечает за методы бота и при инициализации в качестве атрибута необходимо передавать токен бота, Dispatcher - обработчик наших будущих сообщений, запросов и т.д, а executor необходим для запуска нашего бота. \nЧтобы зарегистрировать функцию как обработчик сообщений удобнее всего навесить на нее декоратор. В Aiogram обработчики создаются с помощью специальных декораторов \nmessage_handler\nСоздадим экземпляр класса Bot, передав в него токен, объект Disptcher и в него передадим нашего созданного бота и напишем 2 простых обработчика команды start и help. Для того, чтобы заставить бота работать, необходимо в конце программы вызвать метод \nstart_polling\n класса \nexecutor\n, передав туда наш объект Dispatcher.\nimport logging\nimport os\nfrom aiogram import Bot, Dispatcher, executor, types\nfrom keras.models import load_model\nfrom keras_preprocessing import image\nfrom keras_preprocessing.image import img_to_array\nimport numpy as np\nimport tensorflow as tf\nimport cv2\n#включаем логирование\nlogging.basicConfig(level=logging.INFO)\n#объект бота\nbot = Bot(token=API_TOKEN)\n#диспетчер\ndp = Dispatcher(bot)\n#обработка команды старт\n@dp.message_handler(commands=['start'])\nasync def echo(message: types.Message):\n  await message.reply('Привет! Я бот, распознающий овощи и фрукты')\n# обработка команды help\n@dp.message_handler(commands=['help'])\nasync def echo(message: types.Message):\n  await message.reply('Просто отправьте мне изображение, которое содержит овощ или фрукт')\n\nif __name__ == '__main__':\n#запуск пуллинга\n  executor.start_polling(dp, skip_updates=True)\nТеперь необходимо написать обработчик, который загружает фотографию, присланную боту пользователем и выдает ответ, содержащий информацию о том, что изображено на фото. \n@dp.message_handler(content_types=[types.ContentType.PHOTO])\nasync def download_photo(message: types.Message):\n# загружаем фото в папку по умолчанию\n   await message.photo[-1].download()\n# определяем путь к фото\n   img_path = (await bot.get_file(message.photo[-1].file_id)).file_path\n# получаем предсказание\n   pred = predictions(img_path)\n# Отправляем ответ пользователю\n   await message.answer(f\"Я думаю, что это {temp}😊\")\nТеперь создадим функцию, которая с помощью утилиты \nload_img\n из пакета \nkeras.preprocessing.image\n будет преобразовывать входное изображение в тензорный формат заданного размера.\ndef get_img_array(img_path, size):\n   img = tf.keras.preprocessing.image.load_img(img_path, target_size=size)\n   array = tf.keras.preprocessing.image.img_to_array(img)\n   # расширяем размерность для преобразования массива в пакеты\n   array = np.expand_dims(array, axis=0)\n   return array\nИ создадим основную функцию, которая будет выполнять предсказание. Сначала загружаем нашу модель из файла с помощью метода \nload_model\n из пакета \nkeras\n. Определяем массив меток для классификации. Используем метод \nmobilenet_v2.preprocess_input\n для преобразования входного изображения в формат, подходящий для нейронной сети. Выполняем предсказание с помощью метода \ndef predictions(img_path):\n   img_size = (224, 224)\n   classifier = load_model(\"****/fruit224mobile.h5\")\nclass_labels = ['Яблоко', 'Банан', 'Свекла', 'Болгарский перец', 'Капуста', 'Стручковый перец', 'Морковь', 'Цветная капуста',\n               'Перец чили', 'Кукуруза', 'Огурец', 'Баклажан', 'Чеснок', 'Имбирь', 'Виноград', 'Халапеньо', 'Киви',\n               'Лимон', 'Латук', 'Манго', 'Лук', 'Апельсин', 'Паприка', 'Груша', 'Горох', 'Ананас', 'Гранат',\n               'Картофель', 'Редька', 'Соевые бобы', 'Шпинат', 'Сладкая кукуруза', 'Батат', 'Помидор', 'Репа', 'Арбуз']\n\ntry:\n   preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n   img_array = preprocess_input(get_img_array(img_path, size=img_size))\n   pred = np.argmax(classifier.predict(img_array), axis=1)\n   predictions = class_labels[pred[0]]\n   return predictions\nexcept Exception:\n   return \"Проблемы с изображением\"\nВсе, бот готов! Протестируем его сначала на тестовых изображениях\nИ на своих изображениях. Здесь скриншоты сделаны в версии Telegram Desktop.\nПо-моему бот отлично справляется со своей задачей! Благодаря предобученной нейронной сети MobileNetV2 мы быстро настроили и обучили сеть, а затем создали простого бота, распознающего овощи и фрукты.\nНа этом все. В завершение хочу порекомендовать \nбесплатный вебинар\n, на котором эксперты OTUS расскажут какие преимущества дают Байесовские A/B тесты по сравнению с обычными (интерпретируемость, эффективность и другие), как проводить Байесовские A/B тесты и как работать с Байесовскми моделями в PyMC3.\nЗарегистрироваться на бесплатный вебинар\n \n ",
    "tags": [
        "mobilenetv2",
        "машинное обучение",
        "исскуственный интеллект",
        "чат-бот"
    ]
}