{
    "article_id": "726914",
    "article_name": "Kubernetes Volumes: реплицированная MongoDB со StatefulSet",
    "content": "Автор статьи: Рустем Галиев\nIBM Senior DevOps Engineer & Integration Architect\nПривет Хабр!\nВ Kubernetes \nStatefulSet\n — это реплицированные группы Pod’ов, аналогичные ReplicaSet’ам.\nКаждая реплика получает постоянное имя хоста с уникальным индексом (например, \ndatabase-0\n, \ndatabase-1\n и т. д.).\nКаждая реплика создается в порядке от самого низкого до самого высокого индекса и создание блокируется до тех пор, пока под с предыдущим индексом не станет работоспособным и доступным. Это относится и к масштабированию.\nПри удалении \nStatefulSet\n каждый из управляемых подов реплики также удаляется в порядке убывания. Это также относится к уменьшению количества реплик.\nОказывается, этот простой набор требований значительно упрощает развертывание приложений для хранения данных в Kubernetes. Например, сочетание стабильных имен хостов (например, \ndatabase-0\n) и ограничений порядка означает, что все реплики, кроме первой, могут надежно ссылаться на \ndatabase-0\n для целей обнаружения и установления кворума репликации.\nСегодня мы развернем реплицированный кластер MongoDB с \nStatefulSet\n.\nДля начала создадим реплицированный набор из трех модулей MongoDB, используя объект \nStatefulSet\n. Основной контейнер приложения использует образ контейнера \nmongo:3.4.24\n и запускает процесс \nmongod\n. Когда вы запускаете \nmongod\n, запускается процесс MongoDB и запускается он в фоновом режиме. У процесса есть несколько параметров по умолчанию, например, сохранение данных в \n/data/db\n и запуск через порт 27017. \napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: mongo\nspec:\n  serviceName: \"mongo\"\n  replicas: 3\n  selector:\n    matchLabels:\n      app: mongo\n  template:\n    metadata:\n      labels:\n        app: mongo\n    spec:\n      containers:\n      - name: mongodb\n        image: mongo:3.4.24\n        command:\n        - mongod\n        - --replSet\n        - rs0\n        ports:\n        - containerPort: 27017\n          name: peer\nПока не создавайте объект, так как мы будем вносить дополнительные изменения в манифест YAML.\nИнициализируем кластер MongoDB с помощью init Container\nЧтобы автоматизировать развертывание нашего кластера MongoDB на основе StatefulSet, мы собираемся добавить дополнительный контейнер в поды для выполнения инициализации.\nЧтобы настроить этот модуль без создания нового образа Docker, мы собираемся использовать \nConfigMap\n для добавления скрипта в существующий образ MongoDB.\nМы собираемся запустить этот скрипт, используя контейнер инициализации. Контейнеры инициализации (или init Container) — это специализированные контейнеры, которые запускаются один раз при запуске пода. Они обычно используются в таких случаях, когда есть небольшой объем работы по настройке, которую полезно выполнить до запуска основного приложения. В определении пода есть отдельный список \ninitContainers\n, в котором можно определить контейнеры инициализации.\nПоследним этапом производства нашего кластера MongoDB является добавление проверок жизнеспособности в наши контейнеры, обслуживающие Mongo:\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: mongo\nspec:\n  serviceName: \"mongo\"\n  replicas: 3\n  selector:\n    matchLabels:\n      app: mongo\n  template:\n    metadata:\n      labels:\n        app: mongo\n    spec:\n      containers:\n      - name: mongodb\n        image: mongo:3.4.24\n        command:\n        - mongod\n        - --replSet\n        - rs0\n        ports:\n        - containerPort: 27017\n          name: web\n        livenessProbe:\n          exec:\n            command:\n            - /usr/bin/mongo\n            - --eval\n            - db.serverStatus()\n          initialDelaySeconds: 10\n          timeoutSeconds: 10\n      # This container initializes the mongodb server, then sleeps.\n      - name: init-mongo\n        image: mongo:3.4.24\n        command:\n        - bash\n        - /config/init.sh\n        volumeMounts:\n        - name: config\n          mountPath: /config\n      volumes:\n      - name: config\n        configMap:\n          name: \"mongo-init\"\nЗамените содержимое в файле \nmongo.yaml\n. На следующем шаге мы создадим \nConfigMap\n с именем \nmongo-init\n.\nСоздание карты конфигурации\nОбратите внимание, что Pod монтирует ConfigMap Volume (том) с именем \nmongo-init\n. Этот ConfigMap содержит скрипт, который выполняет нашу инициализацию. Во-первых, скрипт определяет, работает ли он на \nmongo-0\n. Если он находится на \nmongo-0\n, он создает \nReplicaSet\n с помощью той же команды, которую мы ранее запускали императивно. Если он находится в другой реплике Mongo,ждет, пока \nReplicaSet exists\n (как бы правильно сказать, не появится), а затем регистрируется как мембер этого \nReplicaSet\n.\nСледующий манифест YAML содержит полный объект \nConfigMap\n:\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: mongo-init\ndata:\n  init.sh: |\n    #!/bin/bash\n\n    # Need to wait for the readiness health check to pass so that the\n    # mongo names resolve. This is kind of wonky.\n    until ping -c 1 ${HOSTNAME}.mongo; do\n      echo \"waiting for DNS (${HOSTNAME}.mongo)...\"\n      sleep 2\n    done\n\n    until /usr/bin/mongo --eval 'printjson(db.serverStatus())'; do\n      echo \"connecting to local mongo...\"\n      sleep 2\n    done\n    echo \"connected to local.\"\n\n    HOST=mongo-0.mongo:27017\n\n    until /usr/bin/mongo --host=${HOST} --eval 'printjson(db.serverStatus())'; do\n      echo \"connecting to remote mongo...\"\n      sleep 2\n    done\n    echo \"connected to remote.\"\n\n    if [[ \"${HOSTNAME}\" != 'mongo-0' ]]; then\n      until /usr/bin/mongo --host=${HOST} --eval=\"printjson(rs.status())\" \\\n            | grep -v \"no replset config has been received\"; do\n        echo \"waiting for replication set initialization\"\n        sleep 2\n      done\n      echo \"adding self to mongo-0\"\n      /usr/bin/mongo --host=${HOST} \\\n         --eval=\"printjson(rs.add('${HOSTNAME}.mongo'))\"\n    fi\n\n    if [[ \"${HOSTNAME}\" == 'mongo-0' ]]; then\n      echo \"initializing replica set\"\n      /usr/bin/mongo --eval=\"printjson(rs.initiate(\\\n          {'_id': 'rs0', 'members': [{'_id': 0, \\\n           'host': 'mongo-0.mongo:27017'}]}))\"\n    fi\n    echo \"initialized\"\nВы заметите, что скрипт, определенный \nConfigMap\n, немедленно завершает работу. Это важно при использовании \ninitContainers\n. Каждый контейнер инициализации, прежде чем запускаться, ждет пока предыдущий контейнер не будет выполнен. Основной контейнер приложения ожидает завершения всех контейнеров инициализации. Если бы этот скрипт не завершился, основной сервер монго никогда бы не запустился.\nСначала создайте объект \nConfigMap\n:\nkubectl apply -f mongo-configmap.yaml\nЗатем мы создадим объект \nStatefulSet\n, который теперь сможет ссылаться на \nConfigMap\n по имени.\nkubectl apply -f mongo.yaml\nПосле создания различия между \nReplicaSet\n и \nStatefulSet\n становятся очевидными. Учитывая, что для создания подов \nStatefulSet\n потребуется некоторое время, вам придется повторно запускать одну и ту же команду несколько раз, пока не будет достигнуто количество трех реплик:\nkubectl get pods\nМежду этим и тем, что вы увидите с \nReplicaSet\n, есть два важных отличия. Во-первых, каждый реплицированный Pod имеет числовой индекс (0, 1,…) вместо случайного суффикса, который добавляется контроллером \nReplicaSet\n. Во-вторых, поды медленно создаются по порядку, а не все сразу, как это было бы с \nReplicaSet\n.\nПредоставление MongoDB как сервиса\nПосле создания \nStatefulSet\n нам также необходимо создать «безголовую» службу для управления записями DNS для \nStatefulSet\n. В Kubernetes сервис называется «безголовым», если у него нет виртуального IP-адреса кластера. Поскольку со \nStatefulSets\n каждый Pod имеет уникальный идентификатор, на самом деле не имеет смысла иметь IP-адрес для балансировки нагрузки для реплицируемого сервиса. Вы можете создать безголовый сервис, используя \nclusterIP:\n None в спецификации сервиса:\napiVersion: v1\nkind: Service\nmetadata:\n  name: mongo\nspec:\n  ports:\n  - port: 27017\n    name: peer\n  clusterIP: None\n  selector:\n    app: mongo\nПосле создания этой службы обычно заполняются четыре записи DNS. Как обычно, создается \nmongo.default.svc.cluster.local\n, но, в отличие от стандартной службы, поиск DNS по этому имени хоста предоставляет все адреса в \nStatefulSet\n. Кроме того, создаются записи для \nmongo-0.mongo.default.svc.cluster​.local\n, а также для \nmongo-1.mongo\n и \nmongo-2.mongo\n. Каждый из них разрешается в определенный IP-адрес индекса реплики в \nStatefulSet\n. Таким образом, с помощью \nStatefulSets\n вы получаете четко определенные постоянные имена для каждой реплики в наборе. Это часто бывает очень полезно при настройке решения для хранения данных с репликацией.\nСоздайте службу с помощью следующей команды:\nkubectl apply -f mongo-service.yaml\nПосле того, как мы объединили \nStatefulSets\n, \npvc\n и проверку живучести, у нас есть защищенная, масштабируемая облачная установка MongoDB, работающая в Kubernetes. Хотя в этой теме речь шла о MongoDB, шаги по созданию \nStatefulSet\n для управления другими решениями для хранения очень похожи и можно следовать аналогичным шаблонам.\nВ завершение хочу пригласить вас на \nбесплатный урок\n, где мои коллеги из OTUS расскажут как устроен мониторинг кластера, его компоненты и приложения в кластере. Вы изучите различные подходы мониторинга, подходы к мониторингу как приложения так и компонентов кластера, основные метрики Kubernetes. Также узнаете про кластеризацию/федерацию Prometheus, дополнительные хранилища метрик для prometheus (victoria metrics; thanos, cortex).\nЗарегистрироваться на бесплатный вебинар\n \n ",
    "tags": [
        "mongodb",
        "kubernetes",
        "statefullset"
    ]
}