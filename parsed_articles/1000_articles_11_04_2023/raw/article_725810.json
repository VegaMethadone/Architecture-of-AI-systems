{
    "article_id": "725810",
    "article_name": "Пять причин, по которым вам нужны синтетические данные",
    "content": "Сбор и разметка данных в реальном мире может быть длительным и дорогостоящим занятием. Кроме того, у этих данных могут быть проблемы с качеством, разнообразием и количеством. К счастью, подобные проблемы можно решать при помощи синтетических данных.\n\r\n\n\r\n\n\r\nДля обучения модели машинного обучения нужны данные. Задачи data science обычно непохожи на соревнования Kaggle, где у вас есть отличный крупный датасет с готовой разметкой. Иногда приходится собирать, упорядочивать и очищать данные самостоятельно. Такой процесс сбора и разметки данных в реальном мире может быть долгим, неудобным, неточным, а иногда и опасным. Более того, в конце этого процесса может оказаться, что полученные в реальном мире данные не соответствуют вашим требованиям с точки зрения качества, разнообразия (например, дисбаланс классов) и количества.\n Мы перечислим распространённые проблемы, которые возникают при работе с реальными данными:\n\r\n\n\r\n\n\r\n\nСбор и разметка реальных данных не масштабируются\n\r\n\nРучная разметка реальных данных не всегда возможна\n\r\n\nРеальные данные имеют проблемы с конфиденциальностью и безопасностью\n\r\n\nРеальные данные не программируемы\n\r\n\nПоказатели модели, обученной исключительно на реальных данных, недостаточно высоки (например, маленькая скорость разработки)\n\r\n\n\r\nК счастью, подобные проблемы можно решить при помощи синтетических данных. Возможно, вы задаётесь вопросом, что же такое синтетические данные? Синтетические данные — это искусственно сгенерированные данные, обычно создаваемые при помощи алгоритмов, симулирующих процессы реального мира, от поведения других водителей на дороге до взаимодействия света с поверхностями. В этом посте мы расскажем об ограничениях данных реального мира и о том, как синтетические данные помогают преодолеть этих проблемы и повышать точность модели.\n\r\n\n\r\n\nСбор и разметка реальных данных не масштабируются\n\r\nДля маленьких датасетов обычно можно собирать и размечать данные вручную; однако для обучения во многих сложных задачах машинного обучения требуются огромные датасеты. Например, модели, обучаемые для беспилотного вождения, требуют больших объёмов данных, собираемых с датчиков, прикреплённых к автомобилям или дронам. Этот процесс сбора данных очень медленный, он может занимать месяцы или даже годы. После сбора сырых данных их должны вручную аннотировать живые люди, что тоже долго и дорого. Более того, нет гарантии, что полученные размеченные данные принесут пользу в качестве данных обучения, поскольку они могут не содержать примеров, заполняющих текущие пробелы в знаниях модели.\n\r\n\n\r\n\n\r\nДля разметки таких данных обычно применяется труд людей, вручную рисующих метки поверх данных датчиков. Это очень дорогостоящий процесс, поскольку высокооплачиваемые команды ML часто тратят большую долю своего времени на проверку меток и их возврат разметчикам. Главное преимущество синтетических данных заключается в том, что можно сгенерировать любое нужное количество идеально размеченных данных. И для этого необходим лишь способ генерации качественных синтетических данных. \n\r\n\n\r\n\nОпенсорсное ПО для генерации синтетических данных:\n\r\n\n\r\n\nKubric\n (обработка видео с множеством объектов, маски сегментирования, карты глубин и оптический поток) и \nSDV\n (табличные, реляционные и временные данные).\n\r\n\n\r\n\nВот некоторые из множества компаний, продающих продукты или создающих платформы, способные генерировать синтетические данные\n: \nGretel.ai\n (синтетические датасеты, обеспечивающие конфиденциальность реальных данных), \nNVIDIA\n (omniverse) и \nParallel Domain\n (беспилотный транспорт). Другие компании можно посмотреть в \nсписке 2022 года компаний, занимающихся синтетическими данными\n. \n\r\n\n\r\n\nРучная разметка данных иногда может быть невозможной\n\r\n\n\r\nНекоторые данные люди не могут полностью интерпретировать и разметить. Ниже представлены некоторые примеры, в которых единственным вариантом остаются синтетические данные:\n\r\n\n\r\n\n\r\n\nТочная оценка глубины и \nоптического потока\n по отдельным изображениям.\n\r\n\nСферы применения беспилотного вождения, в которых используются данные, невидимые человеческому глазу.\n\r\n\nГенерирование deepfake, которые можно использовать для тестирования систем распознавания лиц.\n\r\n\n\r\n\nРеальные данные имеют проблемы с конфиденциальностью и безопасностью\n\r\n\n\r\nСинтетические данные крайне полезны для применения в областях, в которых непросто получить реальные данные. Например, это касается данных дорожно-транспортных происшествий и большинства типов данных о здоровье, на которые накладываются юридические ограничения (в частности, на \nэлектронные медицинские карты\n). В последние годы исследователей в сфере здравоохранения заинтересовала тема прогнозирования мерцательной аритмии (нарушения сердечного ритма) при помощи сигналов электрокардиографии и фотоплетизмографии. Разработка детектора аритмии сложна не только тем, что аннотирование таких сигналов — монотонный и дорогостоящий процесс, но и из-за юридических ограничений. Это одна из причин, по которой \nпроводятся исследования по симуляции таких сигналов\n.\n\r\n\n\r\nВажно подчеркнуть, что сбор реальных данных не только требует времени и энергии, но и может быть по-настоящему опасным. Одна из основных проблем робототехники, например, беспилотных автомобилей, в том, что они являются физическим применением машинного обучения. Нельзя использовать небезопасную модель в реальном мире, которая приведёт к автокатастрофе из-за нехватки релевантных данных. Подобных проблем позволяет избежать аугментация датасета синтетическими данными.\n\r\n\n\r\n\nВот некоторые из компаний, использующих синтетические данные для повышения безопасности применения ИИ\n: \nToyota\n, \nWaymo\n и \nCruise\n.\n\r\n\n\r\n\nРеальные данные не программируемы\n\r\n\n\r\n\nСинтетическое изображение частично невидимого ребёнка на велосипеде, появляющегося из-за школьного автобуса и едущего по улице в среде, напоминающей калифорнийский пригород.\n\r\n\n\r\nСистемам беспилотного вождения часто приходится иметь дело с относительно «редкими» (по сравнению с обычными условиями вождения) событиями, например, с пешеходами ночью или с велосипедистами, едущими посередине дороги. Для обучения таким сценариям моделям часто нужны сотни тысяч или даже миллионы примеров. Серьёзная проблема заключается в том, что собираемые в реальном мире данные могут не соответствовать требованиям качества, разнообразия (например, дисбаланса классов, погодных условий, местоположения) и количества. Ещё одна проблема заключается в том, что в случае автономных автомобилей и роботов мы не всегда знаем, какие именно данные потребуются, в отличие от традиционных задач машинного обучения с фиксированными датасетами и бенчмарками. Хотя бывают полезными \nтехники аугментации данных\n, систематически или случайно изменяющие изображения, эти техники способны \nпривносить собственные проблемы\n. \n\r\n\n\r\nИ здесь на помощь приходят синтетичекие данные. API генерирования синтетических данных позволяют проектировать датасеты. Эти API экономят кучу средств, поскольку изготовление роботов и сбор данных в реальном мире — чрезвычайно затратная задача. Гораздо лучше и быстрее попытаться сгенерировать данные и определить принципы проектирования при помощи генерирования синтетического датасета.\n\r\n\n\r\n\nВот некоторые из примеров того, как синтетические данных помогают моделям обучаться: \nпредотвращение мошеннических транзакций (American Express)\n, \nулучшенное распознавание велосипедистов (Parallel Domain)\n и \nанализ хирургических операций (Hutom.io)\n.\n\r\n\n\r\n\nПоказатели модели, обученной исключительно на реальных данных, недостаточно высоки\n\r\n\n\r\n\nЭтапы цикла разработки модели\n\r\n\n\r\nСуществует \nмножество факторов, влияющих на жизнеспособность/показатели проекта машинного обучения в разработке и продакшене\n (например, получение данных, аннотирование, обучение модели, масштабирование, развёртывание, мониторинг, повторное обучение модели и скорость разработки). Недавно \n18 инженеров машинного обучения приняло участие в исследовании-интервью\n, целью которого стало понимание распространённых практик MLOps и сложностей в различных организациях и сферах применения (например, в беспилотном вождении, компьютерном оборудовании, розничной торговле, рекламе, системах рекомендаций и так далее). Одним из выводов исследования стала важность скорости разработки, то есть способность быстро прототипировать и выполнять итерации с идеями.\n\r\n\n\r\nОдин из факторов, влияющих на скорость разработки — это необходимость наличия данных для первоначального обучения и оценки модели, \nа также для частого повторного обучения модели\n вследствие постепенного снижения точности модели из-за дрейфа данных, дрейфа концепций или даже из-за training-serving skew.\n\r\n\n\r\n\n\r\nРезультаты исследования также говорят, что эта потребность заставила некоторые организации создать команду для частой разметки актуальных данных. Это дорогой и долгий процесс, ограничивающий возможность быстрого повторного обучения моделей.\n\r\n\n\r\n\n\r\nСтоит заметить, что в этой схеме не отражено, что синтетические данные можно использовать для операций наподобие \nMLOps-тестирования систем рекомендаций\n.\n\r\n\n\r\nСинтетические данные имеют потенциал применения наряду с данными реального мира в жизненном цикле машинного обучения (показанном на изображении выше), чтобы обеспечивать более долговременную точность моделей.\n\r\n\n\r\n\nЗаключение\n\r\nГенерирование синтетических данных всё чаще используется в рабочих процессах машинного обучения. На самом деле, \nGartner\n прогнозирует, что к 2030 году синтетические данные будут использоваться в обучении моделей машинного обучения гораздо больше, чем данные реального мира.\n \n ",
    "tags": [
        "машинное обучение",
        "Synthetic",
        "synthetic dataset",
        "Synthetic Data",
        "augmentation",
        "generating",
        "GAN",
        "VAE",
        "Omniverse",
        "Unity",
        "Blender"
    ]
}