{
    "article_id": "726222",
    "article_name": "Пора забывать GridSearch — встречайте ProgressiveGridSearch. Фракталы в ML, постепенно увеличиваем разрешение",
    "content": "Здравствуйте, меня зовут Николай Стрекопытов и я придумал как подбирать гиперпараметры бескомпромиссно лучше GridSearch’а. Нужно лишь изменить порядок вычислений. И да, это заявка на обновление индустриального стандарта - скоро вы сможете улучшить свои ML-пайплайны заменой нескольких строчек кода.  \nСначала коротко  \nРазберем как проводит вычисления GridSearch, а как ProgressiveGridSearch. Первый перебирает все возможные комбинации стандартным вложенным циклом, то есть если нужно перебрать элементы матрицы, то первый алгоритм сначала переберет все столбцы по первой строке и только после приступит ко второй строке, то есть это просто брутфорс. Я предлагаю действовать разумнее. Постепенно увеличивать разрешение вычислений, то есть сначала получить представление о функции крупным мазками по всему диапазону, затем средними мазками, а дальше мелкими и так далее до останова (такой подход дает возможность адекватно приближать функцию в невычисленных узлах).  \nВ качестве функций возьмем два изображения, визуально процессы выглядят так:  \nИзображение: усредненное лицо взятое из \nhttps://habr.com/ru/company/piter/blog/308720/\nПока не ясно лучше ли метод, чем аналоги из optuna, но его уже можно использовать как генеративный алгоритм для фильмов ужасов (гифку получше залью чуть позже)\nПо анимациям процессов видно, что пока GridSearch проходит одну строчку ProgressiveGridSearch уже получает массу информации о ландшафте функции и это для размерности 2 и порядка разрешения 4 и отрыв растет прямо пропорционально размерности и порядку разрешения, что видно по второй анимации, где размерность все те же 2, но порядок разрешения уже 7\nТеперь подробнее\nРешение получилось красивым, а, как известно, математические результаты бывают либо красивыми, либо неправильными.\nСразу предупрежу, что речь дальше пойдет о многокритериальной оптимизации, гиперкубах и рекурсии, которые в совокупности порождают фрактал поэтому текст под спойлером предназначен для смелых духом и полных сил, а остальные могут поддержать меня поставив звездочку репозиторию, посмотреть картинки и перейти к заключению.\nМатематическая сторона \nИдея строится на том чтобы получать представление о ландшафте функции сначала крупными мазками, затем средними, затем мелким и так далее до заданной мелкости или пока не сработает критерий останова. Такой подход дает инвариантность относительно стартовой точки поиска, а это уже огромное преимущество\nМатематически задачу можно поставить так: следующий узел-кандидат выбирается так, что он дальше всего расположен от всех предыдущих узлов. Первыми узлами будет разумно выбрать вершины гиперкуба (отрезка/квадрата/куба для 1D/2D/3D), являющимся нашим диапазоном вариантов, что эквивалентно формуле: \nРешение этой многокритериальной оптимизационной задачи оказалось неожиданно красивым и легко вычисляемым, рассмотрим его для одномерного случая \nВ качестве \nя взял квадрат евклидовой нормы и точки-решения оказались серединами отрезков, границы которых уже в последовательности, но внутри отрезка нет ни одной точки последовательности\nГрафики (x-xl)^2 для k=3 и k=5\nПо графикам видно, что эти точки действительно являются Парето-оптимальными (при изменении координат нельзя увеличить ни один из функционалов не уменьшив хотя бы один, это вариант обобщения понятия экстремума для многомерных критериев)\nДля большей наглядности рассмотрим порядок без построения кривых расстояний\ndepth = 4, то есть узлов 16. Красным на верхнем графике показан узел, в котором вычисляется на данной итерации, а синим все остальные. На нижнем графике красным показаны узлы, в которых уже было произведено вычисление, а синим те, в которых еще нет\nНо как этот результат обобщается для N-мерного случая? Здесь и появляются гиперкубы и фрактал. Точками-решениями будут являться вершины гиперкуба, а каждый гиперкуб делится на \n с вдвое меньшей стороной. Таким образом возникает последовательность вложенных друг в друга гиперкубов, образующая фрактал, вершины которых являются решением задачи оптимального упорядочивания \nПри желании эту закономерность можно увидеть и в одномерном случае, но на двумерном уже сильно заметнее\nКрасные ужевычисленные узлы, а белый вычисляемый сейчас\nПоскольку речь идет о поиске на сетке, то я свожу этот метод к целочисленному, а не непрерывному, а это дает свой вклад: 1) это универсализирует метод потому что мы вместо точек просто оперируем индексами и автоматом получаем и целочисленный, и непрерывный метод, да еще и с кастомизируемыми по распределению шага сетками 2) Парето-оптимальных решений у целочисленной задачи больше потому что максимально далекое вещественное число от 0 и 15 внутри отрезка это 7.5, а самых далеких целых уже два - 7 и 8 и эту особенность нужно учитывать, иначе будут коллизии и повторные вычисления \nПриступаем к программированию\nОказалось, что алгоритм оптимального упорядочивания узлов по сути является построением dim-арного дерева заданной глубины и обход его узлов поэтажно.\nНам нужно всего два класса - Hypercube и ProgressiveGridSearch\nimport numpy as np\nfrom typing import Callable, List, Union\n\n# Это просто \"контейнер\" для узлов-кандидатов, который еще и дает потомков\n# лежащих внутри него гиперкубов и тоже являющихся \"контейнерами\" для узлов-кандидатов\nclass Hypercube:\n    def __init__(self, resolution_degree: int, start_point: np.array, parent=None):\n        self.resolution_degree = resolution_degree\n        self.start_indexes = start_point\n        self.parent = parent\n\n        self.side = 2 ** resolution_degree - 1\n        self.dim = self.start_indexes.shape[0]\n\n        self.node_order_graph = None\n        self.set_node_order_graph()\n\n    def set_node_order_graph(self):\n        self.node_order_graph = []\n        \n        schema_string = '{0:0' + str(self.dim) + 'b}'\n\n        for node_number in range(2 ** self.dim):\n            binary_mask = schema_string.format(node_number)\n\n            point = np.array(self.start_indexes)\n\n            for index, flag in enumerate(binary_mask):\n                if flag == '1':\n                    point[index] += self.side\n\n            self.node_order_graph.append(point)\n\n    def split(self):\n        for node in self.node_order_graph:\n            yield Hypercube(resolution_degree=self.resolution_degree - 1,\n                            start_point=np.around((node + self.start_indexes) / 2).astype(int),\n                            parent=self)\n\n    def compute_curr_depth(self):\n        res = 0\n        if self.parent is None:\n            return res\n        else:\n            parent = self.parent\n            while parent is not None:\n                res += 1\n                parent = parent.parent\n\n            return res\n\n\nclass ProgressiveGridSearch:\n    def __init__(self, func: Callable, params: List, stop_criterion: Callable, max_resolution_degree: int = 10):\n        self.func = func\n        self.params = params\n        self.stop_criterion = stop_criterion\n        self.max_resolution_degree = max_resolution_degree\n\n        self.number_of_nodes = 2 ** max_resolution_degree\n\n        self.dim = 0\n        self.grids = []\n\n        for param in self.params:\n            if type(param) is Real:\n                self.dim += 1\n                grid = np.linspace(param.left_boundary, param.right_boundary, num=self.number_of_nodes)\n                self.grids.append(grid)\n            elif type(param) is Integer:\n                self.dim += 1\n                grid = np.arange(param.left_boundary, param.right_boundary)\n                self.grids.append(grid)\n\n        self.mask = np.zeros([self.number_of_nodes] * self.dim).astype(bool)\n        self.values = np.full_like(self.mask, fill_value=np.nan).astype(float)\n\n        self.nodes_queue = None\n        self.curr_hypercube = None\n        self.number_of_functions_calls = None\n\n    def __iter__(self):\n        hypercube = Hypercube(resolution_degree=self.max_resolution_degree, start_point=np.zeros(self.dim).astype(int))\n\n        self.generator = (curr_hc.node_order_graph for curr_hc in self.append_generator(hypercube))\n        self.number_of_functions_calls = 0\n\n        self.nodes_queue = iter([])\n        return self\n\n    def __next__(self):\n        try:\n            node_indexes = next(self.nodes_queue)\n\n            # Это фильтрация коллизий\n            if self.mask[tuple(node_indexes)].item() is True:\n                return next(self)\n\n            node_point = []\n\n            for k, index in enumerate(node_indexes):\n                node_point.append(self.grids[k][index])\n\n            node_point = np.array(node_point)\n\n            # Это префильтрация коллизий\n            if self.curr_hypercube.resolution_degree != self.max_resolution_degree and self.curr_hypercube.resolution_degree != 1:\n                if np.any(node_indexes % 2 == 0) and np.sum(node_indexes) % 2 == 0 and np.sum(node_point) != 0:\n                    return next(self)\n\n                b = node_indexes - self.curr_hypercube.start_indexes\n\n                if np.any(b % 2 == 0) and np.all(node_indexes != 0):\n                    return next(self)\n\n            self.mask[tuple(node_indexes)] = True\n            self.number_of_functions_calls += 1\n\n            return node_point, node_indexes\n        except StopIteration:\n            self.nodes_queue = iter(next(self.generator))\n            return next(self)\n\n    def append_generator(self, hypercube: Hypercube):\n        lst = [hypercube]\n\n        while lst:\n\n            self.curr_hypercube = lst.pop(0)\n            yield self.curr_hypercube\n\n            if self.curr_hypercube.resolution_degree == 1:\n                continue\n\n            for sub_elem in self.curr_hypercube.split():\n                lst.append(sub_elem)\n\n    # Здесь будет расположен сам цикл поиска минимума/максимума функции на сетке с критериями останова\n    def optimize(self):\n        for point in self:\n            raise NotImplementedError\n\n\noptimizer = ProgressiveGridSearch(func=evaluator, \n                                  params=[Real('lr', left_boundary=1e-10, right_boundary=1e-1),\n                                          Integer('batch_size', left_boundary=16, right_boundary=512),\n                                          Integer('latent_space_dimension', left_boundary=128, right_boundary=1024),\n                                          String('activation', necessary_values=['relu', 'hard_sigmoid'])],\n                                  stop_criterion=LastDifferenceBetweenBestLowerThan(1e-1)))\nБолее ста строк чтобы превзойти вложенный цикл\nЗаключение\nПреимущества алгоритма:\nВ основном пользователи GridSearch не знают хорошего шага сетки, по которой задают поиск и задают его интуитивно. Но они с большим шансом знают желаемое время на поиск и желаемую точность, что можно обеспечить сеткой переменного разрешения реализованной в ProgressiveGridSearch\nАлгоритм легко модифицируется кастомными критериями останова и в будущем фильтрацией узлов на очереди к вычислению (узлов-кандидатов)\nProgressiveGridSearch быстрее находит точки близкие к оптимальным (в среднем), то есть просто лучше как метод оптимизации\nПоиск настраивается проще, нет необходимости указывать шаг сетки, хотя как опция это возможно \nПреимущество ProgressiveGridSearch над GridSearch стремительно нарастает прямо пропорционально количеству переменных и количеству узлов, которые нужно проверить\nНедостатки:\nВременная сырость продукта - код можно оптимизировать и отсутствует заточенность интерфейса на неизвестные мне, но возможно распространенные, use case'ы из-за недостатка обратной связи - надеюсь на вашу помощь с этим\nМикроскопический оверхед на вычисления на усреднения узлов, устраняющийся C-extesion’ом и кэшированием порядка узлов для заданных N - размерности и D - вектора разрешений для соответствующих компонент\nПланируемые фичи:\nКастомные критерии останова\nСетка с неравномерным шагом\nОтдельность повышения разрешения по критерию для каждой переменной\nФильтрация узлов-родителей по значению функции в них (например, оставлять лишь половину лучших)\nСортировка узлов-кандидатов по аналогичным образом\nКэширование порядка узлов?\nДругие методы оптимизации алгоритмически заданных функция (есть еще несколько оригинальных идей)\nОставляйте в комментариях свои мысли, в том числе предлагайте фичи\nПриглашаю вас в свой блог \nhttps://t.me/research_and_deep_learning\n . В нем я пишу в основном о своих исследования и разработках, но бывают и трезвые оценки и разборы другие работ. В комментариях вы можете повлиять на мои работы до их публикации или просто размылить свои глаза от LLM/GPT нехайповым, но содержательным материалом\nПользуйтесь этим продуктом \nhttps://github.com/nstrek/progressive_search\n, расскажите о нем коллегам\nЕсли вы нанимаете исследователей или R&D специалистов или вашему проекту нужен свежий взгляд, то с радостью с вами познакомлюсь - я как раз ищу работу\nКто увидел возможность оптимизировать оптимизатор им же самим - молодец, а остальные могут дождаться следующей статьи.\nТакие вот фракталы и незаметная теория управления на службе у машинного обучения. \nПМ-ПУ лучший и вне СПбГУ\n%%% Пока вы видите этот абзац статья и код активно дорабатываются, смело пишите ваши замечания в комментарии или в тг %%%\nНад чем я уже точно работаю\nДоведение кода от прототипа до production-ready\nЕще более разумный порядок узлов за счет изменения порядка нод-гиперкубов внутри одного этажа\nЗагрузка в PyPI\nДокументация и readme.md\nСейчас коллизии фильтруются проверкой, я хочу сделать так чтобы повторные ноды вообще не генерились \nКартинка, которая более понятно визуализирует фрактал\nКому не хватило красивой картинки с фракталом\nЭто получилось при разработке в качестве ошибки, экспериментировал с фильтрацией узлов-кандидатов  \nА это по сути \nhttps://ru.wikipedia.org/wiki/Треугольник_Серпинского\n , только у него треугольники равносторонние, а тут прямоугольные  \nА так выглядит одно из состояний процесса если узлы с последнего этажа случайно перемешать\nF.A.Q.\nТут пока пусто\n \n ",
    "tags": [
        "сезон machine learning",
        "методы оптимизации",
        "нейронные сети",
        "машинное обучение",
        "подбор гиперпарметров"
    ]
}