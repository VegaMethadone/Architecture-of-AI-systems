{
    "article_id": "725984",
    "article_name": "Многомодульный BDSM. Бутылочные горлышки среди модулей",
    "content": "Часто бывает, что после разбиения проекта на модули скорость его сборки сильно ниже ожидаемой. Причины могут быть разные, от кривых настроек Gradle до неподходящего железа. Сегодня я хочу разобрать одну из причин — бутылочные горлышки среди модулей, и как с ними бороться.\nА что за горлышки такие?\nПростыми русскими народными словами бутылочное горлышко это \nузкое место\n. Но я как представитель высокоинтеллектуального и высоковыпендрежного класса программистов привык использовать английский аналог — bottleneck. Буквальный перевод которого и значит — бутылочное горлышко. На самом деле у меня просто вызывает улыбку слово «горлышко». Как-то непосредственно и по-детски оно звучит.\nЛадно. А как вообще модуль может стать узким местом, а-ля «бутылочным горлышком»?\nВсё просто. Допустим, у нас есть модуль, который… Просто долго собирается. Ну вот в нём просто много кода. И всё. \nПроблема в том, что другие модули могут зависеть от него. А значит, не начнут собираться, пока он не закончит. \nЧто это значит для нас? Что если мы попробуем запустить параллельную сборку нашего проекта, допустим, на трёх Gradle Worker, то увидим простои.\nВ момент простоя Gradle Worker’у нечем заняться, так как он ожидает сборки нашего бутылочного горлышка. Как следствие, мы не используем 100% потенциальных ресурсов, и сборка собирается дольше, чем могла бы. \nМногие внедряют многомодульность ради скорости сборки, а тут такая подстава.\nС другой стороны, ну были какие-то простои, но вроде немного… Так-то оно так, но когда мы захотим добиться ещё большего уменьшения времени сборки и попробуем использовать 6 Gradle Worker, то увидим более печальную картину.\nЧуть ли не половину времени Gradle Worker’ы будут простаивать. И вот это уже не шутки. Ведь мы использовали всего-то 6 Gradle Worker. В наше время 12 или 16 поточные процессоры в локальных машинах не редкость и хотелось бы утилизировать всю их мощь. 6 Gradle Worker забьют их максимум на 70%. А что уж говорить про CI, где 64 или 128 потоков это норма. \nКак итог написанного выше: из-за бутылочных горлышек время сборки больше, чем могло бы быть, что, по сути, равноценно увеличению времени сборки. Значит, разработчики дольше разрабатывают, а значит, теряются деньги. Никто не любит терять деньги.\nЛогично, что надо как-то бороться с этими паразитами, но для начала их надо как-то найти.\nПоиск бутылочных горлышек\nИтак, какие варианты: Google, частный сыщик или может объявление на столбе?\nЕсли без глупых шуток, то варианта у нас всего два:\nРучной, точнее, глазной, ну то есть визуальный. Из минусов — низкая точность, я бы сказал «на глаз», и не очень быстро. Из плюсов — не требует никакой подготовки. \nАвтоматизированный. По сути, антипод ручного. Из плюсов — более высокая точность и высокая скорость. Из минусов — надо кодить, но точно ли это минус?\nРучной способ\nВесь способ основывается на \nGradle Scan\n. Это встроенная возможность Gradle генерировать очень и очень подробный отчёт о сборке. Для того чтобы он сгенерировался нужно просто добавить параметр --scan. Например:\n./gradlew assembleDebug --scan\nВ итоге вам придёт ссылка на отчёт, который необходимо будет активировать. \nИз этого отчёта нас интересует только один раздел — Timeline. В котором, как ни странно, нам нужен будет сам timeline. Выглядит он примерно так:\nМы видим каждого из Gradle Worker’ов в качестве горизонтальной линии. В данном случае их 8. А также можно увидеть, чем занимался каждый из Gradle Worker в любой момент времени. Серым цветом обозначены какие-либо Tasks, а когда ничего нет, то это простой. \nС такого отдаления мало что можно разглядеть, поэтому приблизим первый блок с простоями, благо Gradle Scan позволяет это сделать.\nТут уже можно подробно разглядеть и сами простои и их причины. \nДалее, видим, что в определённый момент времени какой-либо модуль собирался в одиночестве. Смело обвиняем его в том, что он блокировал сборку, а значит, является бутылочным горлышком. Проводим экзекуцию (об этом далее) и заново начинаем поиск.  \nСразу оговорю важный момент, полностью от простоев вы не избавитесь. Всегда будут микромоменты, когда кто-то кого-то блокирует, или кто-то кого-то ждёт. Поэтому не стоит сильно упарываться, и как только достигните показателя в 5—10% простоев, то можно остановиться. \nТакже нужно понимать, что если вы достигли идеального результата и все четыре ваших Gradle Worker’а всё время чем-то заняты…\nТо просто запустите проект на 16-ти Gradle Worker’ах и разрушьте иллюзию.\nВ итоге опять чуть ли не половину времени занимают простои. Можно очень долго повышать количество Gradle Worker и долго пытаться бороться с горлышками. Но лучше просто в количестве Gradle Worker отталкивайтесь от количества ваших модулей и вашего железа. Большинству компаний вряд ли понадобится больше 16 штук. \nТакой способ хорошо подходит, если у вас меньше 100 модулей или 5—7 разработчиков. Просто раз в квартал находите самые злостные бутылочные горлышки и исправляете.\nА что, если модулей сильно больше? Или разработчиков 25? Как следствие проблемы с бутылочными горлышками будут возникать чаще и бить больнее. Ведь простои на 60 секунд за год накапают на приличное количество впустую потраченного времени. Значит, это дело надо как-то автоматизировать.\nАвтоматический способ\nПо сути, нам просто надо автоматизировать те действия, что мы совершали в ручном способе. А как вообще автоматизировать то, что мы наблюдаем? Начнём с того, как не надо это делать.\nКак не стоит мерить\nВо-первых, не стоит строить автоматизацию вокруг длительности сборки модуля. Ведь тот факт, что модуль собирается долго, ещё не означает, что он является бутылочным горлышком. Он может ни от кого не зависеть, да и от него будет зависеть только, например, app. В итоге блокировать он никого не будет и спокойно себе соберётся параллельно с другими модулями.\nВо-вторых, не стоит строить автоматизацию вокруг количества связей модулей. Может показаться, что если от нашего модуля зависит, допустим, 20 других модулей, то он плохой и выступает бутылочным горлышком. Это может быть какой-нибудь core-network, который просто выступает фасадом для всех библиотек связанных с сетью, и собирается от силы 2 секунды. Да и не факт, что он прям заблокирует Gradle Worker’ы, ведь параллельно с ним могут в спокойном режиме собираться какие-нибудь core-database или core-location.\nСами по себе это действительно рабочие показатели, которые могут многое рассказать о проблемах с вашими модулями. Но в нашем «уголовном деле» о бутылочных горлышках это лишь косвенные улики.\nПоэтому сначала посмотрим, что интересного нам может предоставить Gradle, и что мы можем с этим сделать. Начнём с визуализации данного действа, а потом закрепим это кодом.\nВизуализация\nВспомним, что нам показывает Timeline в Gradle Scan: несколько Gradle Worker, которые в определённый момент времени занимаются какой-то задачей, связанной с отдельными модулями. На глаз легко увидеть простои.\nБолее того, мы можем не только их увидеть, но и померить сколько времени Gradle Worker простаивал. И из этого мы уже видим виновника простоев. Что из информации, которую нам предоставляет Gradle, может помочь нам сделать это автоматически?\nЧто нам даёт Gradle\nКонечно же, Gradle предоставляет нам время начала работы над каждой из Task.\nТакже он предоставляет нам время конца этой Task. Благодаря этому, мы можем вычислить и продолжительность каждой из Task. \nПо сути, это вся информация, которая нам может понадобиться. Немного. Может возникнуть вопрос — «И ради этого ты рисовал диаграммы? Серьёзно?». И мой ответ: «Да, так понятнее».\nДанные у нас есть, но что с ними теперь делать?\nЧто нам с этим делать?\nКонечно же, двумерный массив. Скорее, конечно, список списков, ведь так чуть удобнее.\nГлавный список у нас будет размером равным количеству секунд времени сборки. Длится сборка 87 секунд, значит и список будет из 87 элементов. Во вложенном списке будут модули, которые собирались в данную секунду. Если попытаться это визуализировать, например, для двух Gradle Worker, то это будет выглядеть как-то так.\nВесьма похоже на обычный timeline, только разбитый на сегменты. \nТеперь надо с помощью этих данных научится вычислять бутылочные горлышки. Пробежимся по главному списку и если в данную секунду количество собираемых модулей меньше чем 2 (количество Gradle Worker), то начисляем единственному модулю 1 балл. \nПо сути, 1 балл у модуля означает, что в данный момент собирался только он, а все остальные его ждут, а значит, был простой ресурсов на 1 секунду.\nТак как вряд ли вы используете всего два Gradle Worker, то надо как-то усложнить алгоритм. Поэтому рассмотрим на примере аж трёх Gradle Worker.\nОсновная логика остаётся прежней, но чуть обрастает жирком. Всё так же бежим по главному списку и выставляем каждому модулю в списке количество баллов равное общему количеству Gradle Worker минус количество занятых Gradle Worker и в конце поделим результат на количество занятых Gradle Worker. Для понимания я даже сделал сверхсложную формулу: (wA - wU) / wU, где wA это общее количество Gradle Worker, а wU количество занятых Gradle Worker.\nВ итоге мы видим, насколько каждый из модулей внёс свой вклад в простои в секундах. Например, если у нас работали два Gradle Worker из трёх, то каждому из модулей зачисляем по 0.5 секунды. А если работал только один, то модуль получит аж 2 секунды.\nАлгоритм может показаться не очень точным. Так оно и есть, но тут высокая точность не важна, так как итоговая цель — не отсортировать все модули по вредности, а выявить только самые вредные модули. Ведь если модуль приводит к простоям на полсекунды, то на исправление этой ситуации вы потратите больше времени, чем сможете выиграть.\nА как это выглядит с точки зрения кода?\nКод\nДля начала нам надо как-то достать необходимые данные из Gradle. Это можно сделать внутри кастомного \nGradle Plugin\n.\nДостаём данные\nДля этого Gradle нам предоставляет такую штуку как \nBuildService\n, в который мы можем имплементировать \nOperationCompletionListener\n.  \npublic interface OperationCompletionListener {\n\n   void onFinish(FinishEvent event);\n}\nВ его метод onFinish приходит нужная нам информация о каждой из завершённых Task. \nИз этого мы уже можем слепить собственный data класс с нужными нам полями.\ndata class TaskExecutionData(\n   val projectName: String,\n   val taskName: String,\n   val startTime: Long,\n   val endTime: Long\n)\nЗдесь projectName — имя модуля, taskName — имя Task, startTime и endTime — время начала Task в миллисекундах и окончания Task в миллисекундах.\nДанные мы получили, теперь их надо как-то обработать.\nОбрабатываем данные\nУ нас есть куча данных по каждому из Task. Для начала соберём из них Set которому дадим лаконичное название taskDataSet.\nНастало время сделать наш список списков, то есть Timeline.\nprivate fun createTimeline(\n   taskDataSet: Set<TaskExecutionData>\n): List<Set<TaskExecutionData>> {\n    ...\n}\nСначала вычисляем общее время сборки — buildTime. Для этого находим время начала самой первой Task — startTime и время окончания самой последней Task — endTime. Дальше buildTime вычислить несложно, просто вычитаем startTime из endTime. \nval startTime = taskDataSet.minOf { it.startTime }\nval endTime = taskDataSet.maxOf { it.endTime }\nval buildTime = endTime — startTime\nВ итоге создаётся список размером c buildTime. То есть количество миллисекунд, которое заняла сборка. Да-да, именно миллисекунд. В отличии от визуализации, где всё считалась в секундах, в реальном коде лучше использовать миллисекунды. Дело в том, что многие Task по длительности сильно меньше, чем одна секунда, и может сложиться ситуация, когда мы не учли какую-то Task или случайно посчитали её дважды.\nval timeline = 0..buildTime\nОсталось превратить наш timeline в список списков. Для этого бежим по списку timeline через map и в каждой из миллисекунд формируем абсолютное время — calcTime.  Далее находим в списке Task которые выполнялись в данную calcTime миллисекунду с помощью оператора filter.\ntimeline.map { currentBuildTime ->\n   val calcTime = startTime + currentBuildTime\n   taskDataSet\n       .filter { calcTime >= it.startTime }\n       .filter { calcTime < it.endTime }\n       .toSet()\n}\nСшив все куски вместе, получаем полноценный метод, который строит необходимый нам timeline.\nprivate fun createTimeline(\n   taskDataSet: Set<TaskExecutionData>\n): List<Set<TaskExecutionData>> {\n   val startTime = taskDataSet.minOf { it.startTime }\n   val endTime = taskDataSet.maxOf { it.endTime }\n   val buildTime = (endTime — startTime)\n\n   val timeline = 0..buildTime\n   return timeline.map { currentBuildTime ->\n       val calcTime = startTime + currentBuildTime\n       taskDataSet\n           .filter { calcTime >= it.startTime }\n           .filter { calcTime < it.endTime }\n           .toSet()\n   }\n}\nТеперь надо из этого timeline сделать список модулей с заблокированным ими временем. \nДля этого сначала определяем количество Gradle Worker, задействованных при сборке. \nval maxWorkerCount = timeline.maxOf { it.size }\nЗатем бежим по timeline и для каждой миллисекунды определяем время простоя — blockedTime, по знакомой нам формуле.\ntimeline.forEach { set ->\n     val blockedTime = (maxWorkerCount — set.size).toDouble() / set.size\n     ...\n}\nНу и осталось подсчитать время простоя вызванное каждым из модулей. Для этого просто прибавляем blockedTime к значению из Map, в которой ключом является имя модуля, а значением — общее время простоя, вызванное модулем.\nset.forEach { taskData ->\n    val moduleName = taskData.projectName\n    val previous = blockedTimeMap.getOrDefault(moduleName, 0)\n    blockedTimeMap[moduleName] = previous + blockedTime\n}\nВсё вместе это выглядит так.\nprivate fun createBlockedTimeList(\n   timeline: List<Set<TaskExecutionData>>\n): List<Pair<String, Double>> {\n   val maxWorkerCount = timeline.maxOf { it.size }\n   val blockedTimeMap = mutableMapOf<String, Double>()\n   timeline.forEach { set ->\n     val blockedTime = (maxWorkerCount — set.size).toDouble() / set.size\n     set.forEach { taskData ->\n       val moduleName = taskData.projectName\n       val previous = blockedTimeMap.getOrDefault(moduleName, 0)\n       blockedTimeMap[moduleName] = previous + blockedTime\n     }\n   }\n   return blockedTimeMap.toList()\n}\nСделаю небольшое отступление и скажу, что данное решение скорее для примера. В реальности лучше в качестве ключа использовать имя Task, а не модуля. За счёт этого можно будет применить фильтр к имени Task и найти не только слишком долго собирающиеся модули, но и, например, модули со слишком долгой кодогенерацией или слишком долгим прохождением Unit-тестов.\nНо вернёмся к нашему коду. Мы составили список, теперь надо сформировать из него итоговый результат и вывести его.\nВыводим результат\nВсё просто: фильтруем, да сортируем. \nval bottlenecks = blockTimeList\n    .filter { it.second > 5000.0 }\n    .sortedBy { it.second }\n    .takeLast(5)\n    .reversed()\n\nprintln(\"Bottlenecks:\\n${bottlenecks.joinToString(\"\\n\")}\")\nБежим по нашему списку и для начала отсеиваем некритичные для нас простои. Пусть это будет 5 секунд, то есть 5000 миллисекунд. Далее сортируем по времени простоя, забираем 5 самых злостных нарушителей и разворачиваем список, чтобы проще было читать. \nВ итоге мы увидим что-то вроде такого:\nBottlenecks:\n(feature_1_impl, 100000)\n(base_module_1, 90000)\n(feature_2_impl, 50000)\n(base_module_3, 40000)\n(app, 30000)\nМы нашли самые вредные из горлышек. Основная задача выполнена. Можно вместо вывода в лог сделать проверку на CI на то, что не появилось модулей, которые создают простоев более чем на, допустим, 10 секунд, и запускать перед залитием кода в develop. Так можно отсечь большую часть проблем.\nВ целом, можно применить более сложный и точный алгоритм с учётом большего количества различных показателей, вроде тех же длительности и количества связей. Но, честно говоря, я не вижу в этом сакрального смысла. Пока, по крайней мере. Ведь самых злостных нарушителей такой алгоритм найдёт, а с мелкими бороться невыгодно. \nТак что, теперь давайте разберём, какие виды горлышек бывают, и как с ними бороться.\nВиды горлышек, и как с ними бороться\nЯ попытался как-то систематизировать виды горлышек, которые наблюдал лично. Поэтому я не могу ручаться, что это прям все-все виды. Вероятно, в вашем проекте может возникнуть что-то иное. Я выделил для себя следующие виды в порядке их вредности для времени сборки:\nРазросшийся базовый модуль. \nГлавный модуль.\nМодуль с плохой иерархией.\nПродуктовый монолит.\nТеперь подробнее про каждый из них. Начнём с базового модуля. \nРазросшийся базовый модуль\nКак и говорит нам название — это просто \nбазовый модуль\n, который, по какой-то причине, стал слишком большим. Причины могут быть разные, от изначально неудачной структуры базовых модулей, до неожиданного усложнения на каком-то из слоёв приложения. \nРассмотрим на примере. Допустим, у нас есть модуль base-data, в котором хранятся все базовые классы для работы с данными. Походы в сеть, работа с базой данных и т.п.\nЭто может вылиться в то, что если в вашем приложении произойдёт усложнение в работе с данными, то модуль станет собираться сильно дольше. При этом он будет блокировать сборку других модулей, которым нужна работа с данными. \nВ итоге у нас появляется простой.\nКак побороть это? Распил. Надо залезть внутрь модуля и понять — нет ли в нём составных частей, которые можно было бы вынести отдельно. \nВ 90% случаев в базовых модулях такие части можно найти без особых усилий. Скорее всего, они даже будут слабо связаны между собой. Наш модуль base-data без зазрения совести разделяем на два модуля: base-network и base-database.\n \nКаждый из этих «дочерних» базовых модулей будет собираться быстрее, чем base-data, а самое главное — они могут собираться параллельно друг другу. В итоге на timeline мы увидим сильные изменения.\nПомимо того, что базовые модули теперь собираются быстрее за счёт параллельности, так теперь и части модулей не нужна связь на base-database, и они смогут начать собираться сразу после сборки base-network, не дожидаясь base-database.\nКак результат, простоев стало сильно меньше. Мы победили!\nНо… Модуль то базовый и, как следствие, сильно популярный. Если распил его на составляющие вряд ли займёт у вас много времени, то вот разбираться в связях, кого и куда теперь надо подключать, ведь не всем нужна работа с сетью, и не всем нужна работа с базой данных, может занять очень и очень много времени. Даже на сотне модулей это неприятная задача, что уж говорить о 400 модулях и больше. Пока разберёшься с частью связей в develop, кто-то накинет ещё парочку.\nТут можно воспользоваться «лайфхаком». Можно превратить base-data в прокси модуль, к которому мы как api подключим новые модули base-network и base-database. Как следствие, все, кто подключает к себе base-data, транзитивно получат и его «дочерние» модули. При этом сам base-data может не содержать кода вообще.\n \nС точки зрения timeline у нас не всё так прекрасно: base-network и base-database собираются параллельно, но вот другие модули вынуждены ждать завершения base-data.\nЗато мы получили возможность в момент распила сразу не разбираться со всеми зависимостями. Можно сначала выкатить распил. Затем запретить использовать base-data в новых модулях и в самом конце, потихоньку, без спешки разбираться с зависимостями по одному модулю. За счёт этого «лайфхака» и низкой связности распил базовых модулей вряд ли будет для вас слишком сложным. Поэтому повышаем сложность и посмотрим на app.\nГлавный модуль\nОбычно он у всех называется app, но может называться и по-другому или их может быть несколько. В него в итоге приходят все ветви дерева модулей. Он ствол этого могучего дерева, и из-за этого с ним есть проблемы.\nОн собирается последним, и стандартные модули не могут собираться параллельно с ним. И он становится бутылочным горлышком, не по своей воле, конечно, но всё таки. \n \nПолучается, что пока собирается app, у нас генерируется простой. Ведь ему просто не с кем сбориться параллельно. \nЧто тут можно сделать? Распил. Опять. \nРаз мы не можем побороть тот факт, что app является бутылочным горлышком, то надо хотя бы уменьшить время его сборки. \nПоэтому выносим из app всё, что можно вынести, оставляя только то, что вынести нельзя или не имеет смысла. Желательно при этом распиливать в несколько модулей.\nЗа счёт этого время сборки существенно улучшится, а время простоев уменьшится.\nНо неужели никак нельзя избавиться от app как бутылочного горлышка насовсем? Вообще, способ есть. Но он крайне не универсален. Имя этого способа dynamic-feature. Магия тут в том, что app не подключает к себе dynamic-feature как обычный модуль. Наоборот, это dynamic-feature подключает к себе app и другие модули. \nПольза тут именно в модулях, которые нужны только dynamic-feature. Они-то не обязаны зависеть от app и, как следствие, могут собираться с ним параллельно.\nЗа счёт этого наше дерево модулей можно превратить в лес, и для скорости сборки это хорошо. Естественно, если у вас больше одной dynamic-feature. Если одна, то ситуация с app повторяется. \nСпособ, откровенно говоря, не для всех, даже если создавать install-time dynamic-feature. Как минимум придётся сменить или \nпереработать связывание модулей\n. Да и публикация становится чуть сложнее.\nПоэтому посмотрим на что-то более однозначное и доставляющее больше проблем.\nМодуль с плохой иерархией\nКак понятно из названия это какой-то модуль, у которого нечаянно или специально накосячили с иерархией.\nРассмотрим на таком примере:\nФичёвый модуль feature-1-impl подключает к себе feature-2-impl, а тот в свою очередь подключает к себе feature-3-impl. Но ведь фичёвые модули не должны подключать друг друга напрямую? Да, не должны. Потому иерархия и плохая. Причин для её возникновения может быть множество — плохо распилили, недопоняли иерархию, торопились, банально опечатались, неудачно скопипастили build файл и т.п. Причин может быть множество, и они в текущем контексте не важны.\nВажно то, что такая иерархия очень плохо влияет на скорость сборки.\nМогут генерироваться простои очень больших размеров. Так как, по сути, часть модулей стала собираться последовательно.\nЧто тут делать? Распил? На удивление, не распил. Нужно восстановить правильную иерархию. Для начала надо найти причину, почему такая иерархия вообще установилась. На удивление всё просто: отключаем неверную зависимость в build-файле и пытаемся собрать. Скорее всего, что-то отвалится и сборка не пройдёт. По сути, это и будет причина. В зависимости от ситуации общий для двух модулей компонент надо будет либо вынести в отдельное место, либо разделить на составные части, либо банально копировать. В итоге иерархия станет правильной.\nНа время сборки это подействует крайне приятным образом, уменьшив количество простоев очень серьёзно.\nНесмотря на большой вред для времени сборки, такой тип горлышек довольно легко чинится. Что для нас определённо плюс.\nНу и давайте, наконец, взглянем на последний тип — продуктовые монолиты.\nПродуктовые монолиты\nА что за название такое — «продуктовый монолит»? А это просто я его сам придумал :) \nПродуктовый монолит — это либо наследие из одномодульных времён, либо ошибка коллективного бессознательного группы разработчиков, когда они ради возможности что-то переиспользовать начинают всё складывать в какой-то один модуль. Каждый выносит только что-то своё, что не может навредить, но разработчиков-то 20, и в итоге получается гигантский монолитный модуль. Часто такими модулями являются модули со слишком общим названием — вроде utils или shared-list-ui, user-api/user-feature.\nПри этом такой модуль с точки зрения иерархии может прикидываться невинной овечкой.\nНо в timeline раскрывается его истинная суть. За счёт своего объема он может собираться в 5 и более раз дольше, чем обычный модуль, чем и вызывает простои.\nИ как бы уже всё не радужно, но в реальности всё ещё хуже, потому что часто продуктовые монолиты содержат в себе и плохую иерархию. А так как модуль огромный, то и неправильных связей может быть много.\nВ итоге на timeline мы видим форменный ужас.\nВ итоге вместо параллельной сборки мы наблюдаем последовательную.\nА что с этим делать? А то же самое, что мы делали с предыдущими типами горлышек. Восстанавливаем иерархию и распиливаем. Порядок этих действий может варьироваться, в зависимости от ситуации. \nДля начала, допустим, восстановим иерархию с помощью каких-то общих модулей.\nTimeline уже станет сильно лучше. В случае с продуктовым монолитом восстановить иерархию может быть сложнее, так как модуль в целом больше, то и причин иметь неправильную зависимость у него может быть больше.\nНу и теперь распил, тут опять же всё непросто и для начала разделим наш монолит на три части. \nПопутно может выясниться, что не всем его частям нужны дополнительные зависимости к общим модулям, что ещё более положительно скажется на скорости сборки.\n \nРазбираться с монолитами — это всегда тот ещё геморрой. Это долго и неприятно, но и результат обычно внушающий. \nИтог\nВ случае с бутылочными горлышками, как и с сердечно-сосудистыми заболеваниями, — лучше заниматься профилактикой, а если уж подхватили, то лечить, пока проблема не разрослась, и дальше держать руку на пульсе.\nНу и самое главное, бутылочные горлышки — это дорого. Как с точки зрения времени разработчика, так и с точки зрения времени железа. Бороться с ними точно нужно. К сожалению, это не тот случай, где можно победить проблему в зародыше, так как сходу сложно определить, станет ли конкретный модуль проблемой. Но когда проблемный модуль уже проявил себя, то стоит избавиться от него как можно раньше. Так как потом исправлять его будет сильно дороже.\nДругие статьи цикла:\nМногомодульный BDSM: стоит ли внедрять Gradle модули и какие типы модулей бывают?\nМногомодульный BDSM: как связать Gradle модули и как с ними общаться после этого?\n \n ",
    "tags": [
        "gradle",
        "модули",
        "bottlenecks",
        "многомодульность",
        "многомодульность в android",
        "многомодульный проект",
        "android"
    ]
}