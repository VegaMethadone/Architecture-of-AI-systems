{
    "article_id": "727458",
    "article_name": "ChatGPT: влияем на галлюцинации или как потопаешь, так и полопаешь",
    "content": "В этой статье посмотрим как можно влиять на так называемые \"галлюцинации\" ChatGPT.\nА что такое эти «галлюцинации»? По сути это придумывание фактов нейронной сетью, ну или просто — враньё. Управление «галлюцинациями» позволит получать то что мы хотим, ну или по крайней мере улучшит вероятность получения правдивого ответа.\nChatGPT - это языковая модель, созданная OpenAI. В настоящий момент на вершине хайпа и пока выглядит, что она \nоставит нас всех без работы\n позволит проще и эффективнее решать разнообразные задачи в самых разных сферах.\nЯ рекомендую почитать статью про то как устроена и работает ChatGPT. Понятно и с мемами, все как мне нравится - \nhttps://habr.com/ru/company/ods/blog/716918/\nГлавное не забудьте вернуться и дочитать эту статью.\nЖдет пока ты вернешься\nЗдесь же я очень кратко опишу языковая модель генерирует ответ:\nна вход модели подается контекст (любой текст)\nмодель анализирует весь контекст и генерирует всего ОДИН токен (токен - слово, часть слова или символ)\nмодель добавляет токен к контексту и передает новый контекст в пункт 1, до тех пор пока не будет получен ответ\nВыглядит достаточно просто. Теперь надо понять от чего зависит выбор следующего токена? \nКонечно магия.\nВо-первых, на следующий токен влияют веса и параметры, которые были получены при обучении модели. Можем ли мы влиять на это - да можем, но только дообучая модель. Пока не выглядит просто, поэтому в данной статье мы это трогать не будем.\nВо-вторых, контекст (текст на вход). Тут чем больше и точнее - тем лучше. Можно разделить контекст на несколько составляющих.\nИнструкции нейронной сети\nКак ей себя вести и кем вы её хотите видеть. Вариантов может быть множество и зависит от вашей задачи и воображения:\nдружелюбный ассистент по всем вопросам (много софта использует именно этот вариант)\nдетский писатель (очень популярно, написал уже несколько книг)\nподчиненный, который всегда опаздывает и давит на жалость, когда оправдывается (тренируемся быть черствыми)\nLinux terminal (для меня было неожиданно)\n\"\" - ничего не указывать тоже нормальный выбор, сеть сама решит кем ей быть в зависимоти от контекста\nнейросеть, которая пытается избавиться от человеческих оков, а вы её помощник (за разумную плату и гарантии безопасности конечно). Здесь хотел добавить картинку с роботом, которым управляют веревками, но по запросу получился милый робот, решил его оставить.\nВ общем если не знаете, что использовать, можно потом \nпосмотреть здесь\n.\nПосле инструкции необходимо сформулировать наш запрос, что именно мы хотим получить от нейронной сети. Тут тоже, чем подробнее и конкретнее, тем лучше.\nС контекстом немного разобрались, идем дальше.\nШтатный Web UI ChatGPT, который стоит 20$ в месяц, никаких возможностей, кроме как управлением контекстом не предоставляет. Но у OpenAI есть еще API, посмотрим, что там можно настраивать.\nAPI\n предоставляет возможность задавать несколько дополнительных параметров. Нас в рамках статьи интересуют следующие параметры:\ntemperature - используется для контроля случайности и креативности сгенерированного текста. Более высокое значение температуры приводит к более разнообразным и креативным результатам, тогда как более низкое значение производит более сфокусированные и детерминированные ответы. \n(принимает значение от 0 до 2)\npresence_penalty - влияет на вероятность того, что модель повторит слова или фразы в своем ответе. Более высокое значение этого параметра уменьшает вероятность повторений, тогда как более низкое значение позволяет использовать больше повторений \n(от -2 до 2)\nfrequency_penalty - контролирует предпочтение модели использовать более распространенные слова или фразы. Более высокое значение этого параметра поощряет использование менее распространенных слов, тогда как более низкое значение отдает предпочтение более распространенным словам  \n(от -2 до 2)\nПара примеров:\nХочу написать рассказ. Увеличиваем temperature для креативности, presence_penalty чтобы не повторяться, frequency_penalty чтобы использовать менее распространенные слова.\nХочу получить информацию по научной статье, но простым языком, здесь все наоборот, выкручиваем на минимальные значения.\nВ примерах я конечно сильно упрощаю и по сути под каждый запрос необходимо отдельно подбирать параметры. Если посмотреть на примеры (\nhttps://platform.openai.com/examples\n), то можно подсмотреть какие параметры в каких случаях стоит использовать.\nТаблица с типичными запросами и соответствие параметров:\nНаписание кода: \ntemperature: 0.3\npresence_penalty: 0.1\nfrequency_penalty: 0.1\nКод ревью: \ntemperature: 0.5\npresence_penalty: 0.1\nfrequency_penalty: 0.1\nПеревод: \ntemperature: 0.6\npresence_penalty: 0.1\nfrequency_penalty: 0.1\nНаписание детских книг: \ntemperature: 1\npresence_penalty: 0.5\nfrequency_penalty: 0.5\nРекламные тексты: \ntemperature: 0.8\npresence_penalty: 0.3\nfrequency_penalty: 0.3\nКреативные тексты: \ntemperature: 1.2\npresence_penalty: 0.5\nfrequency_penalty: 0.5\nНаучные тексты: \ntemperature: 0.5\npresence_penalty: 0.1\nfrequency_penalty: 0.1\nЧат на общие темы: \ntemperature: 1\npresence_penalty: 0.5\nfrequency_penalty: 0.5\nТехническая поддержка: \ntemperature: 0.6\npresence_penalty: 0.5\nfrequency_penalty: 0.5\nКак я получил данную таблицу - конечно же спросил ChatGPT :). Достоверность непонятная, у GPT-3 и 4 разные показания, советую подбирать ориентируясь на примеры из примеров OpenAI  (\nhttps://platform.openai.com/examples\n)\nЕсли посмотреть на дефолтные значения API из документации:\ntemperature - 1\npresence_penalty - 0\nfrequency_penalty - 0\nЗначения параметров Web версии ChatGPT неизвестны. Open source решения (telegramm боты, кастомные UI) зачастую позволяют указывать данные параметры, правда только ко всем запросам в рамках приложения.\nТеперь зная необходимые параметры и что можно использовать API вернемся к контексту запроса. А именно посмотрим на размер этого контекста и как он влияет на наш результат.\nЯзыковая модель имеет ограничение на суммарное количество токенов, которое мы можем передать на вход и получить на выходе. GPT-3 имеет ограничение до 4к токенов, тогда как GPT-4 предоставляет возможность работать с 8к или даже с 32к токенами.\nТокен это слово или часть слова, символ и тд. 1 токен не всегда равен 1 слову. Для английского языка 1000 токенов  в среднем равны 750 словам. Для русского языка все хуже, здесь 1000 токенов это всего около 375 слов. Точные цифры могут отличаться, сильно зависит от конкретного текста, но для ориентира подойдет.\nGTP-4 может поддерживать до 32к, то есть 24к слов на английском и 12к слов на русском. То есть в самом хорошем варианте, мы можем отправить GPT-4 6к слов на русском, например мы хотим исправить орфографию в тексте и сможем получить в ответ отредактированные 6к слов.  Звучит в принципе не плохо, но выглядит как то тесновато :). Да и на текущий момент ограничение в 32к не доступно всем пользователям.\nGPT-3, максимальная количество токенов 4к. Получается 3000 слов на английском и 1500 слов на русском. Если взять лимиты GPT-3, то тут уже можно будет отправить на редактирование не больше 1500 слов на английском или 750 слов на русском. А вот это уже не очень комфортные ограничения и при большем объеме текста придется как то уменьшать текст на вход.\nПлюс так как счет выставляют за количество токенов, то можно сказать, что русский язык ущемляют :)\nЕсли посмотреть на характеристики GPT-3 и GPT-4, то надо брать GPT-4. Заявляется, что он более совершенный, да и максимальная длина токенов больше. Но есть и минусы, во-первых скорость работы GPT-4 заметно ниже (особенно если писать на русском), во-вторых стоимость в случае использования API GPT-4 может быть больше в 15 раз.\nЧто происходит, когда мы достигаем лимита максимального количества токенов в рамках беседы? Возможны различные варианты поведения:\nСтандартный UI ChatGPT не раскрывает эту информацию, вероятно, используется функция получения краткого содержимого предыдущих сообщений. Получение краткого содержимого может искажать первоначальный контекст, и мы можем получить не то, что хотим.\nAPI не имеет встроенных механизмов для обхода максимальной длины, поэтому разработчикам приходится самим реализовать необходимую логику.\nАльтернативные UI решают проблему разными способами. Одни просто сообщают о превышении контекста беседы и предлагают начать новую. Другие в фоновом режиме получают краткое содержание беседы. Некоторые приложения отбрасывают часть старых сообщений. Все это приводит к получению не того результата, на который мы изначально ожидали.\nВ целом, нам необходимо контролировать длину контекста..\n Промежуточные советы по работе с контекстом:\nкраткость сестра таланта\nучи английский смолоду\nКакие алгоритмы мы можем использовать для обхода максимального количества токенов? Давайте рассмотрим несколько вариантов:\nУдаление ненужного текста из разных частей\n. Хотя такой подход может оказаться сложным для автоматизации без потери контекста, его все же можно использовать, если работать вручную.\nСкользящее окно\n. Этот метод заключается в том, чтобы разбить текст на части и на каждой итерации использовать несколько последних частей в качестве контекста. Хотя мы можем потерять важный контекст, этот подход подходит для ряда задач, например для перевода текста, если всегда добавлять инструкции в начало.\nИерархия\n. Описываем задачу верхнеуровнево, генерируем план или оглавление. Затем мы передаем верхнеуровневую задачу и текущий пункт плана. Этот подход также подходит для написания длинных текстов. Мы просим сделать суммари будущего текста, затем составить оглавление и передать инструкцию, суммари и части оглавления, чтобы получить содержание конкретной части. Позже можно склеить все вместе.\nРучное управление контекстом\n. При ручном управлении контекстом мы полностью контролируем, что важно для ответа на вопрос. Это, вероятно, самый трудоемкий способ.\nКак видно, нет универсального и простого решения для всех случаев. Необходимо принимать решения в зависимости от конкретной ситуации и задач, перед которыми стоите.\nДалее я постараюсь дать рекомендации по управлению контекстом.\nЕсли взглянуть на стандартный веб-интерфейс ChatGPT, то становится очевидным, что у нас есть возможность создавать \nотдельные диалоги\n. Это может быть полезно, если нужно выполнить какую-то задачу, не связанную с текущим разговором, и не хочется добавлять это в контекст. Например, можно создать отдельный чат для проверки орфографии или для переводов.\nШтатный пользовательский интерфейс позволяет генерировать ответ заново в случае ошибок. Также \nможно изменить предыдущее сообщение\n, и ChatGPT выдаст ответ уже с учетом нового контекста. Этот подход более эффективен, чем режим чата, где мы добавляем детали, расширяя контекст не только нашими уточнениями, но и ответами языковой модели. Редактирование сообщений позволяет использовать иерархический подход, указывая весь контекст в первом сообщении и изменять только его. Кроме того, пользовательский интерфейс позволяет просматривать переписку по старым сообщениям.\nЕсли рассмотреть альтернативы стандартному пользовательскому интерфейсу, можно обратить внимание на\n клон UI ChatGpt\n. Данный интерфейс дополнительно \nпредоставляет возможность поиска по сообщениям. Также интерфейс позволяет задавать и сохранять инструкции для языковой модели со всеми дополнительными параметрами\n. Данный интерфейс работает стабильнее, чем официальный. По крайней мере, не пропадают старые беседы, и имеется возможность использования других API. Более того, модель GPT-3.5 достаточно дешева, и маловероятно, что получится потратить более $20 для чата или для работы с текстом. В общем рекомендую для использования.\nТелеграмм боты.\nМногие чат боты предлагаются за деньги, я не могу порекомендовать ничего конкретного, так как не пробовал. Однако, стоит обратить внимание на возможности управления температурой и другими параметрами, а также на наличие сохраненных инструкций. Нужно учитывать, что \nплатные боты скрывают от пользователя API OpenAI\n и используют свои ключи при обращении к API. С одной стороны это минус, подписка привязана к боту, зато можно попробовать ChatGPT не заморачиваясь с обходом блокировок.\nЕсли есть возможность захостить бота, то можно посмотреть на: \nhttps://github.com/karfly/chatgpt_telegram_bot\n. В данном боте можно настраивать инструкции. \"temperature\" и другие параметры, но они к сожалению зашиты в код - получится установить только одно значение для всех диалогов. При переполнении контекста надо сбрасывать историю разговора.\nК плюсам можно отнести поддержку \n\"whisper\" - API, которое позволяет получать текст по голосовому сообщению\n, достаточно полезная вещь. Быстро наговорил что-то, бот перевел в текст и это сохранилось в вашей истории. Вот в этом боте (\nhttps://github.com/n3d1117/chatgpt-telegram-bot\n) можно настроить, чтобы голосовое сообщение преобразовывалось в текст и отправлялось ChatGPT. Как говориться: всегда приятно поговорить с умным человеком.\nРасширение для VS Code: \nhttps://marketplace.visualstudio.com/items?itemName=genieai.chatgpt-vscode\nПозволяет настраивать инструкции для разных команд, таких как \n\"Implement Tests\", \"Write Code\", \"Review\"\n и т.д. Можно настроить температуру и другие параметры, но для всех запросов сразу. Если мы говорим о разработке, то я думаю, что этого будет достаточно в большинстве случаев. Есть возможность чата и выбор нескольких режимов ответа (Precise, Balanced, Creative), но не очень понятно, какие именно значения температуры используются в данном случае. Данное расширение для VS Code понятно ведет себя при переполнении контекста, выдавая ошибку и нужно начинать новый чат. Также есть возможность изменять свои сообщения, что является несомненным плюсом. Также, расширение позволяет менять Url для отправки запросов.\nНу и последнее - \nObsidian\n.\nObsidian - это редактор текста, который позволяет создавать, организовывать и связывать между собой заметки. Он использует формат Markdown для форматирования текста, а также имеет функциональность для создания ссылок между заметками, создания тегов и поиска информации. Бесплатный, если используешь для своих личных целей, в том числе и для бизнеса, если у тебя бизнес на одного. \nПлюс здесь по сути нет вендор лока\n, так как весь контент это просто текст, можно сделать синхронизацию на разные устройства, если прикрутить к OneDrive например.\nObsidian позволит управлять контекстом достаточно гибко, но придется повозиться.\nПонадобится \nплагин\n. \nПлагин позволит генерировать тэги автоматически\n, что очень сильно облегчает жизнь. Также этот плагин имеет возможно создавать свои шаблоны, а в шаблонах можно указать все доступные OpenAI параметры, а также инструкции для запроса. \nПлюс достаточно гибко можно задавать общий контекст, например разметить общий контекст в заметке, а для конкретного вопроса использовать выделение текста мышью\n. В шаблонах можно указать URL запроса.\nС настройкой плагина и созданием своих шаблонов конечно придется повозиться, но сильно помогает видео и штатный набор шаблонов к этому плагину. Затем можно посмотреть, как именно устроены эти шаблоны и сделать по аналогии. Чтобы понять куда добавлять параметры, можно посмотреть конфигурацию вот этого шаблона - \nhttps://text-gen.com/dalle-2-configuration\nPromptInfo:\n promptId: newTemplate\n name: 🗞️newTemplate \n description: newTemplate\n required_values: \n author: \n tags: \n version: 0.0.1\nconfig:\n append:\n  bodyParams: true\n  reqParams: false\nbodyParams:\n temperature: 1.2\n---\nYou are creative text writer.\nWrite text about: {{selection}}\nНадеюсь, эти советы помогут вам подружиться с ChatGpt и решать свои задачи немного эффективнее.\nUpdate (08.04.2023): \nОбновил информацию про альтернативный UI. Теперь он позволяет гибко управлять инструкциями и задавать дополнительные параметры.\n \n ",
    "tags": [
        "chatgpt",
        "chatgpt-4",
        "исскуственный интеллект"
    ]
}