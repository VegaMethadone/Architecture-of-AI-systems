{
    "article_id": "728402",
    "article_name": "Тестирование исполняемого кода Go",
    "content": " \n«Каждый, уважающий себя программист, осваивая новый язык пишет свой логгер» (с) давно было, источник цитаты канул в Лету, в общем — забылся.\nСобственно вся история вопроса началась тут. Когда-то, около 3 лет назад, осваивая новый для себя язык, тоже написал свой логгер. Он писался подглядыванием в стандартный логгер, и первое что мне захотелось изменить в нем — это устранить буфер сообщений из структуры самого логера. Это мне показалось тогда нормальным, логгер становится реентерабельным и стало можно пробрасывать один и тот же логгер в несколько горутин, обрамив мьютексом только сам процесс вывода.\nЭто уменьшает фактическое время блокировок, а значит «хорошо и правильно». :)\nПозже, логгер был заброшен, в боевых проектах применялся в основном zap и кое-где попадался logrus. Судя по бенчмаркам, zap был шустр, и в общем-то на этом можно было бы статью и закончить .. но, в один прекрасный момент меня посетила мысль: «а не завести ли свой гитхаб и выложить в него что-нибудь хорошее?» :)\nИ тут собственно возникло неожиданное продолжение, т. к. выкладывать на гитхаб, писанное на коленке и в начале пути не комильфо, надо бы подчистить и улучшить. Подчистки и улучшения конечно же сопровождались покрытием тестами и бенчмарками. И вот тут, для себя, сделал «открытие», что в Golang всё не совсем так, как это представляется с высоты 40+ лет программирования и опыта писания собственных (Ре)Ассемблеров, компиляторов и пр.. И так.\nДля статьи был взят стандартный, библиотечный логгер из пакета log, и доработан в части накопления данных по времени исполнения и аллокациям, перенеся пакет в тестируемый код. Дополнение:\nconst MaxRepeats = 1000            // for tests into main() only\nconst MaxPoints = MaxRepeats*2 + 4 // small more that need\n\n// StatItem -- one record for test statistics\ntype StatItem struct {\n\tMallocs     uint64\n\tFrees       uint64\n\tHeapObjects uint64\n\tMoment      time.Time\n}\n\n// A Logger represents an active logging object that generates lines of\n// output to an io.Writer. Each logging operation makes a single call to\n// the Writer's Write method. A Logger can be used simultaneously from\n// multiple goroutines; it guarantees to serialize access to the Writer.\ntype Logger struct {\n\tmu        sync.Mutex // ensures atomic writes; protects the following fields\n\tprefix    string     // prefix on each line to identify the logger (but see Lmsgprefix)\n\tflag      int        // properties\n\tout       io.Writer  // destination for output\n\tbuf       []byte     // for accumulating text to write\n\tisDiscard int32      // atomic boolean: whether out == io.Discard\n\t// Profiling memory usage for tests\n\tMStat  runtime.MemStats\n\tPoints [MaxPoints]StatItem // array! Allocating may be by compiler\n\tLen    int\n}\n\nfunc (l *Logger) AddPoint() {\n\tif l.Len < MaxPoints {\n\t\truntime.ReadMemStats(&l.MStat)\n\t\tl.Points[l.Len].Mallocs = l.MStat.Mallocs\n\t\tl.Points[l.Len].Frees = l.MStat.Frees\n\t\tl.Points[l.Len].HeapObjects = l.MStat.HeapObjects\n\t\tl.Points[l.Len].Moment = time.Now()\n\t\tl.Len++\n\t\t// for go benchmarks only:\n\t\tif l.Len > MaxPoints {\n\t\t\tl.Len = 0\n\t\t}\n\t}\n}\n\nНичего сверхестественного, добавляем структуру сохранения и метод для снятия данных в заданной точке. Пытаемся избежать аллокаций и в логгер добавляем массив заранее определенного размера, известного на стадии компиляции. Как-бы любой «уважающий себя компилятор» выделит память под логгер и массив одним запросом.. :)\nДалее, делаем ручной тест:\npackage main\n\nimport (\n\t\"bytes\"\n\t\"memtest/logger\"\n\t\"os\"\n)\n\n// Global vars. Waiting this will be allocated by compiler\nvar outbuf [1024]byte                       // array! allocating may be by compiler\nvar outWriter = bytes.NewBuffer(outbuf[:0]) // create slice from array and generate new Writer may be by compiler too\n\nfunc main() {\n\tvar stdLog = stdlogger.New(outWriter, \"\", 0)\n\tstdLog.AddPoint() // [0]\n\tfor i := 0; i < stdlogger.MaxRepeats; i++ {\n\t\toutWriter.Reset()\n\t\tstdLog.AddPoint()\n\t\tstdLog.Print(\"This a simple message\")\n\t\tstdLog.AddPoint() // [2] for first cycle!\n\t}\n\tstdLog.AddPoint()\n\n\t// clear out flags and switch for see\n\tstdLog.SetFlags(0)\n\tstdLog.SetOutput(os.Stdout)\n\tfor i := 0; i < stdLog.Len; i++ {\n\t\t//stdLog.Printf(\"\\n%v\", stdLog.Points[i])\n\t}\n\n\tstdLog.Printf(\"Total time=%d ns\", stdLog.Points[stdLog.Len-].Moment.Sub(stdLog.Points[0].Moment).Nanoseconds())\n\tstdLog.Printf(\"Total allocates=%d, frees=%d, heap objects=%d\",\n\t\tstdLog.Points[stdLog.Len-1].Mallocs-stdLog.Points[0].Mallocs,\n\t\tstdLog.Points[stdLog.Len-1].Frees-stdLog.Points[0].Frees,\n\t\tstdLog.Points[stdLog.Len-1].HeapObjects-stdLog.Points[0].HeapObjects, \n\t)\n\tstdLog.Printf(\"\\nAvg time=%d ns/op\", stdLog.Points[stdLog.Len-1].Moment.Sub(stdLog.Points[0].Moment).Nanoseconds()/stdlogger.MaxRepeats)\n\tstdLog.Printf(\"Avg allocates=%d, frees=%d, objects=%d /op\",\n\t\t(stdLog.Points[stdLog.Len-1].Mallocs-stdLog.Points[0].Mallocs)/stdlogger.MaxRepeats,\n\t\t(stdLog.Points[stdLog.Len-1].Frees-stdLog.Points[0].Frees)/stdlogger.MaxRepeats,\n\t\t(stdLog.Points[stdLog.Len-1].HeapObjects-stdLog.Points[0].HeapObjects)/stdlogger.MaxRepeats,\n\t)\n\tstdLog.Printf(\"\\nFirst run time=%d ns\", stdLog.Points[2].Moment.Sub(stdLog.Points[0].Moment).Nanoseconds())\n\tstdLog.Printf(\"First run allocated=%d, frees=%d, objects=%d\",\n\t\tstdLog.Points[2].Mallocs-stdLog.Points[0].Mallocs,\n\t\tstdLog.Points[2].Frees-stdLog.Points[0].Frees,\n\t\tstdLog.Points[2].HeapObjects-stdLog.Points[0].HeapObjects,\n\t)\n}\n\nЗапускаем .. и получаем нечто странное:\n/tmp/GoLand/___go_build_memtest\nTotal time=12754376 ns\nTotal allocates=1005, frees=0, heap objects=1005\nAvg time=12754 ns/op\nAvg allocates=1, frees=0, objects=1 /op\nFirst run time=60205 ns\nFirst run allocated=6, frees=0, objects=6\n Всего аллоцировано 1005 объектов в куче! Количество проходов = 1000 и за первый проход аллоцировано 6 объектов. Одна аллокация в цикле тестирования и первом проходе понятна: там выводится строка, под которую выделяется память внутри fmt.Sprintf(), что нормально.\nОткуда 5 аллокаций при первом проходе?\nХорошо, пишем бенчмарк:\npackage stdlogger\nimport (\n\t\"bytes\"\n\t\"testing\"\n)\nvar outbuf [1024]byte // array! allocating may be by compiler\nvar outWriter = bytes.NewBuffer(outbuf[:0]) // create slice from array and generate new Writer may be by compiler too\nfunc Benchmark_stdLog(b *testing.B) {\n\tvar stdLog = New(outWriter, \"\", 0)\n\tb.ResetTimer()\n\tfor i := 0; i < b.N; i++ {\n\t\toutWriter.Reset()\n\t\tstdLog.AddPoint()\n\t\tstdLog.Print(\"This a simple message\")\n\t\tstdLog.AddPoint()\n\t}\n}\n\n , запускаем командой go test -bench=. -benchmem -cpu=1, чтобы не смотреть во сколько потоков запускает тест и .. получаем ответ:\ngoos: linux\ngoarch: amd64\npkg: memtest/stdlogger\ncpu: Intel(R) Core(TM) i5-9400F CPU @ 2.90GHz\nBenchmark_stdLog         8744750               134.3 ns/op            24 B/op          1 allocs/op\n.. просто удивительная разница по времени исполнения! А ведь в первом и втором цикле вызывается ровно один и тот же код, и массив точек съема данных для бенчмарка закольцован, а цикл в main() не выходит за его границу. Ну ок, давайте запустим тест с явным указанием повторов:\nа) командой: go test -bench=. -benchmem -cpu=1 -benchtime=1x -count=1000\ngoos: linux\ngoarch: amd64\npkg: memtest/stdlogger\ncpu: Intel(R) Core(TM) i5-9400F CPU @ 2.90GHz\nBenchmark_stdLog               1             11981 ns/op             416 B/op          6 allocs/op\n… тут ещё 998 строк примерно как ниже:\nBenchmark_stdLog               1              7366 ns/op             184 B/op          4 allocs/op\nб) командой:  go test -bench=. -benchmem -cpu=1 -benchtime=1000x -count=1\ngoos: linux\ngoarch: amd64\npkg: memtest/stdlogger\ncpu: Intel(R) Core(TM) i5-9400F CPU @ 2.90GHz\nBenchmark_stdLog            1000              2334 ns/op              24 B/op          1 allocs/op\nКак всё интересно-то! Параметр -benchtime – в нашем случае это количество повторов, передаваемое в цикл b.N. То есть, при N=1 мы получаем 1000 перезапусков теста и оценку скорости исполнения «в среднем», но по 1 повтору кода. И тут внезапно обнаруживаем, что «в среднем» у нас не 6 аллокаций, а .. только 4. То есть пара объектов сохраняет свое время жизни между вызовами тестируемой функции несмотря на всю локальность объявлений..\nВторой вариант дает нам 1000 повторов цикла при однократном запуске теста и тут однократность первых аллокаций вполне штатно показывает на одно размещение внутри цикла. Ну, мы же помним про fmt.Sprintf(), ничего удивительного, кроме .. времени исполнения. Давайте увеличим количество повторов:\ngo test -bench=. -benchmem -cpu=1 -benchtime=100000x -count=1\ngoos: linux\ngoarch: amd64\npkg: memtest/stdlogger\ncpu: Intel(R) Core(TM) i5-9400F CPU @ 2.90GHz\nBenchmark_stdLog          100000               153.9 ns/op            24 B/op          1 allocs/op\nНу вот, всё ожидаемо.\nА теперь вопрос на засыпку: почему бенчмарк в пункте «б» исполнившись в точности также 1000 раз за 1 проход показал иное время исполнения 2334 наносекунды на цикл, в то время как тест в main() выдал почти в 6 раз большее значение: Avg time=12754 ns/op?\nА давайте увеличим константу const \nMaxRepeats \n= 10000\n и прогоним main() ещё раз:\nTotal time=124476321 ns\nTotal allocates=10005, frees=0, heap objects=10005\nAvg time=12447 ns/op\nAvg allocates=1, frees=0, objects=1 /op\nFirst run time=132694 ns\nFirst run allocated=6, frees=0, objects=6\n, странно не правда ли? Среднее время исполнения в main() практически не изменилось! То есть нечто крайне интересное происходит при тестировании go test -bench=…\nЗаглядываем в код benchmark.go и .. видим, что принципиальных отличий нет, кроме блокировки мьютексом исполняемого кода (даже понятно зачем) и ручного запуска runtime.GC() перед началом цикла тестовой функции. Ровно тот же самый вызов runtime.ReadMemStats(&memStats) для подсчета аллокаций до и после запуска тестируемой функции, тот же вызов time.Now() для подсчета времени исполнения..\nНу, ок. Давайте вызовем тоже GC предварительно в нашем main(), а ещё дополним вывод количества сохраненных точек и размер массива для контроля .. и получим:\nLen=20002, cap=20004\nTotal time=125534130 ns\nTotal allocates=10005, frees=0, heap objects=10005\nAvg time=12553 ns/op\nAvg allocates=1, frees=0, objects=1 /op\nFirst run time=55850 ns\nFirst run allocated=6, frees=0, objects=6\nНичего революционного однако не произошло.. как было 12.5 микросекунд на цикл исполнения так примерно и осталось. Как было 5 дополнительных аллокаций, так и осталось. Как-бы уже возникают вопросы к скорости исполнения, которые показывает бенчмарк, ибо отличие в 6 раз должно быть как-то объяснено.\nВопрос на засыпку 2: А что тогда измеряет benchmark? :)\nЕщё один момент:\nВ тесте main() логгер создается локально, что требует выделения памяти или на стеке или в куче. Хорошо. Давайте перенесем объявление логгера в статический глобал. Тут уже, компилятор точно знает что это одна такая переменная, размер занимаемой памяти фиксирован и известен на стадии компиляции и ее можно выделить статически:\nvar stdLog = stdlogger.Logger{\n\tMStat:  runtime.MemStats{},\n\tPoints: [20004]stdlogger.StatItem{},\n\tLen:    0,\n}\nfunc main() {\n\tstdlogger.SetOutput(outWriter)\n \tstdlogger.SetFlags(0) \tstdlogger.SetPrefix(\"\")\n\t// .. далее по тексту выше\n , запускаем main() .. и получаем:\n/tmp/GoLand/___go_build_memtest\npanic: runtime error: invalid memory address or nil pointer dereference\n[signal SIGSEGV: segmentation violation code=0x1 addr=0x18 pc=0x48cad6]\ngoroutine 1 [running]:\nmemtest/stdlogger.(*Logger).Output(0x56e240, 0x1?, {0xc00001c1b0, 0x15})\n        ~/myProjectsGo/memtest/stdlogger/stdlog.go:237 +0x356\nmemtest/stdlogger.(*Logger).Print(0x56e240, {0xc00009af10?, 0xc0000a0150?, 0x7ff4d8554bb8?})\n        ~/myProjectsGo/memtest/stdlogger/stdlog.go:256 +0x5a\nmain.main()\n        ~/myProjectsGo/memtest/main.go:30 +0xdd\nУх-ты! Паника! Забавно, что она возникает там, где и должна возникать в коде этого логера, т. к. внутренний буфер l.buf []byte не инициализируется ни в самом коде логера NEW() ни тут в нашем тестовом коде. Однако, динамически выделенная память под логгер функцией New() работает штатно, а вот объявление глобальной переменной — нет.\nЗабавный фокус Go, о котором хорошо осведомлены авторы пакета:\nvar std = New(os.Stderr, \"\", LstdFlags)\n  Стандартный логгер — также глобален, но выделяет память динамически, тоже вызывая метод log.New().. Каким волшебным образом, динамически создаваемая структура методом New(), без явной инициализации слайса, тем не менее, нормально аллоцирует память далее в коде исполнения, в то время как та же самая структура, но объявленная по сути статически, уже такого не делает?\nОткуда все-таки берутся аллокации там, где компилятор точно знает размер и способен выделять память самостоятельно? А так ли это? Давайте проверим, и выведем пустую строку:\nfunc main() {\n\tstdLog := stdlogger.New(outWriter, \"\", 0)\n   \truntime.GC()\n\tstdLog.AddPoint() // [0]\n\tfor i := 0; i < stdlogger.MaxRepeats; i++ {\n\t\toutWriter.Reset()\n\t\tstdLog.AddPoint()\n\t\tstdLog.Print(\"\")\n\t\tstdLog.AddPoint() // [2] for first cycle!\n\t}\n\tstdLog.AddPoint()\n\n, запускаем main() и получаем:\nLen=20002, cap=20004\nTotal time=121876995 ns\nTotal allocates=4, frees=0, heap objects=4\nAvg time=12187 ns/op\nAvg allocates=0, frees=0, objects=0 /op\nFirst run time=17479 ns\nFirst run allocated=4, frees=0, objects=4\nВо-от. Fmt.Sprintf() не аллоцировал память, что видно по средним показателям, но первый вызов цикла все равно аллоцировал 4 объекта в куче. Забавно, что теперь, вернувшись к примеру из самого начала (такое же локальное создание логгера в начале main()) получили существенно меньшее время исполнения первого прохода.. это как? :)\nПутем манипуляций с пакетом, можно убедиться что поле логгера buf []byte на самом деле под капотом имеет 2 аллокации: память под сам массив + память под структуру слайса. (сколько аллокаций делает make(map[...]...) можно догадаться, глянув на структуру мапы под капотом). Кроме того строчка l.buf = l.buf[:0] на самом деле создает новый слайс и сохраняет его в старом месте, а не обнуляет, как можно наивно подумать. Ну и кроме этого, передача результата fmt.Sprintf() в параметр l.Output() также под капотом может содержать аллокацию, т. к. строка в Go это структура из указателя и размера строки.\nНо, если это так, то почему аллокация в этих случаях делается один раз и только при первом проходе?\nВ целом, вопросов возникло много, буду признателен тем, кто хорошо разобрался в том, что творится под капотом Go. Пока ясно одно: внутренняя аллокация памяти «на стеке» и «в куче» не имеет принципиальной разницы, что и указано авторами, где-то в Faq по модели памяти Go. И то и другое — есть внутренний механизм, и по сути одинаковый.\nВ данном обзоре сознательно не полез в Ассемблер, хотя и догадываюсь что все ответы можно найти там, но, в этом случае, текст статьи получился бы исключительно для «профи», которым это всё известно и так.\nСпасибо, если дочитали до конца. Это моя первая статья в жизни. :)\n \n ",
    "tags": [
        "Go",
        "tests",
        "benchmarks",
        "logging"
    ]
}