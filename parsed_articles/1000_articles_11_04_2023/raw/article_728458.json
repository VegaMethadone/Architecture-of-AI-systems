{
    "article_id": "728458",
    "article_name": "Как выжать 1,5 терафлопса производительности для 32-битных чисел с плавающей точкой на одном процессоре M1",
    "content": "Если вы занимаетесь обучением крупных современных нейросетей, эта статья будет вам не совсем в тему, ведь у A100 скорость в сто раз выше (156 терафлопсов).\n\r\n\nТак что же интересного в этих полутора терафлопсах?\n\r\n\n\r\n\nработа на одном ядре MacBook Air 2020 года с питанием от батареи;\n\r\n\nвыполнение с задержкой ~0,5 \nнаносекунды\n на инструкцию.\n\r\n\n\r\n\nМы говорим не о мощных ускорителях или тензорных ядрах графических процессоров, а лишь о настоящей производительности линейной алгебры, которая отстоит от регистров процессора \nна один цикл\n.\n\r\n\nКак ни странно, Apple прячет от нас эту штуку! Но в этой статье мы рассмотрим код, который позволит нам приподнять завесу тайны. Для всего кода используется заголовок \naarch.h\n в замечательном \nрепозитории\n corsix.\n\r\n\nЧто такое сопроцессор AMX?\n\r\n\nПо сути, это SIMD на стероидах. Важная особенность в том, что отношение AMX:CPU не равно 1:1. Сопроцессор AMX есть не у каждого ядра.\n\r\n\nВот размеры, которые можно использовать для загрузки или хранения значений: \n\r\n\n\r\nРазмер \nminimum\n равен ширине полного регистра AVX512.\n\r\n\nНо откуда загружаются или где хранятся эти значения? Понятно, что такие размеры довольно быстро заполнили бы файл регистра NEON. Есть отдельный регистровый файл специально для AMX, выглядит он весьма странно.\n\r\n\nРегистры распределены по группам X, Y и Z. В группах X и Y хранятся входные значения для каждой инструкции, а в группе Z — выходные значения.\n\r\n\n\r\n\nГруппы X и Y уже не маленькие! На них ушел целый килобайт. Ну а Z вообще ни в какие ворота:\n\r\n\n\r\n\nСпойлер: 1024 байт (1/4 от группы Z-регистров) могут быть полностью заняты одной инструкцией AMX.\nИ как же попасть из X и Y в Z? Способов так много, что все они едва ли уместятся в кодировку ISA, поэтому большую часть информации об инструкциях Apple закодировали в регистре общего назначения. Оказалось, что с этим классно работать, ведь есть возможность конфигурировать код на AMX на лету, \nво время его выполнения\n.\n\r\n\nЦель этого поста — добиться от сопроцессора предельной мощности. Есть инструкции умножения векторов, которые выводят векторы одинаковой длины, но они далеко не исчерпывают вычислительные возможности этой микросхемы. Чтобы добиться реального эффекта, придется вместо этого использовать внешнее произведение.\n\r\n\nЧто такое внешнее произведение? Пусть есть два вектора u и v? тогда:\n\r\n\n\r\n\n\r\n\nВнешнее произведение этих векторов — это матрица, которая содержит произведения всех возможных попарных комбинаций их элементов. Это немного проясняет, почему группа регистров Z настолько больше групп X и Y.\n\r\n\n\r\n\n\r\n\nВ микросхеме AMX это сводится к очень простой, вот такой инструкции:\n\r\n\n\r\n\nЕщё есть флаг, который можно установить, чтобы суммировать с нарастанием (accumulate) данные из прошлого результата:\n\r\n\n\r\n\nИтак, у нас есть все необходимое, чтобы написать умножение матриц: перезагрузим 16 значений с плавающими точками из входных матриц и суммируем их внешние произведения с нарастанием в выводе размерностью 16x16. При этом уменьшение размерности K никакой роли не играет!\n\r\n\nУпростим задачу и неявно транспонируем матричное умножение. Как \nA\n, так и \nB\n (наши входные данные) как основную размерность будут иметь размерность уменьшения \nK\n. На практике это не имеет большого значения, но значительно упрощает код.\n\r\n\nВот ссылка, при помощи которой предложенное решение можно проверить:\n\r\n\nvoid reference_16x16xK(float *A, float *B, float *C, uint64_t K) {\n  for (uint32_t m = 0; m < 16; ++m) {\n    for (uint32_t n = 0; n < 16; ++n) {\n      C[n * 16 + m] = 0;\n      for (uint32_t k = 0; k < K; ++k) {\n        C[n * 16 + m] += A[k * 16 + m] * B[k * 16 + n];\n      }\n    }\n  }\n}\n\r\n\nА вот как проверить его на AMX:\n\r\n\n// only set for k == 0\nuint64_t reset_z = 1ull << 27;\n\nfor (uint32_t k = 0; k < K; ++k) {\n  uint64_t idx = k % 4;\n  // 64 bytes = 16 floats\n  AMX_LDX((uint64_t)A + k * 64);\n  AMX_LDY((uint64_t)B + k * 64);\n\n  // now we do 4 indepedent outer products (avoiding pipeline hazards)\n  AMX_FMA32(reset_z);\n  reset_z = 0;\n}\n\r\n\nПримечательно, что мы не обращались по адресу \nни к одному\n регистру. Вернее, обращались, но тайно. Точно так же, как \nreset_z\n кодируется битовой маской, адреса регистров кодируются в аргументах, передаваемых \nAMX_*\n. Указатели на A и B используют лишь до 56 бит, поэтому инженеры Apple запрятали данные в оставшихся восьми битах. Мы просто случайно установили их все в значение 0. Итак, в данном случае применяются регистры \"0\" для X и Y.\n\r\n\nКод для сохранения регистров Z в памяти немного сложнее: заполняется только первый столбец. Это означает, что нужно занять регистры 0, 4, 8 и т. д.:\n\r\n\nfor (uint64_t i = 0; i < 16; ++i) {\n  const uint64_t z_register = (i * 4ull) << 56;\n  AMX_STZ(z_register | (uint64_t)C + i * 64);\n}\n\r\n\nК сожалению, если загрузить размещенный выше код, мы увидим, что он страшно тормозит. А ведь это всего какая-то пара сотен гигафлопов. Почему же? Есть две причины.\n\r\n\nПервая — конфликт при конвейерной обработке (pipeline hazard)\n\r\n\npipeline hazard — общее название случаев, когда результаты одной инструкции требуются для выполнения последующей до того, как первая завершится. \nКаждая инструкция AMX_FMA32 зависит от предыдущей, поскольку мы суммируем с нарастанием в единое подмножество регистрового файла. В итоге используется 25% регистрового файла на полную мощность, а остальное мы оставляем незадействованным, что мешает распараллеливанию на уровне инструкций.\n\r\n\nВторая причина — неэффективная загрузка из памяти. Одновременно можно загружать 128 байт, но приведенный выше код загружает всего 64 байта. Аналогично мы можем выполнять загрузку в \nдругие\n регистры, а не загружать каждый раз в одни и те же. Это тоже позволяет немного распараллелиться на уровне инструкций.\n\r\n\nИ какой же у нас план?\n\r\n\n\r\n\nМы планируем загрузить 128 байт в X и Y и затем рассчитать блок 32x32. Для этого потребуется 4 независимых расчета блоков по 16x16, что позволит добиться параллелизма на уровне инструкций, а также более эффективно использовать загруженную память (каждый 64-байтовый регистр используется дважды).\n\r\n\nvoid mm32x32xK(float* A, float* B, float* C, uint64_t K) {\n\n  // flag to load/store 128 bytes\n  const uint64_t load_store_2 = 1ull << 62;\n  const uint64_t load_store_width = 128; // in bytes\n\n  // only set for k == 0\n  uint64_t reset_z = 1ull << 27;\n\n  for (uint32_t k = 0; k < K; ++k) {\n    uint64_t idx = k % 4;\n    // load to X, Y (skipping every other index because we're loading 128 bytes)\n    AMX_LDX(load_store_2 | (idx * 2) << 56 | (uint64_t)A + k * load_store_width);\n    AMX_LDY(load_store_2 | (idx * 2) << 56 | (uint64_t)B + k * load_store_width);\n\n    // offset into X and Y registers is byte-wise\n    const uint64_t offset = idx * load_store_width;\n\n    // now we do 4 indepedent outer products (avoiding pipeline hazards)\n    AMX_FMA32(reset_z | (0ull << 20) | ((offset +  0ull) << 10) | ((offset +  0ull) << 0));\n    AMX_FMA32(reset_z | (1ull << 20) | ((offset + 64ull) << 10) | ((offset +  0ull) << 0));\n    AMX_FMA32(reset_z | (2ull << 20) | ((offset +  0ull) << 10) | ((offset + 64ull) << 0));\n    AMX_FMA32(reset_z | (3ull << 20) | ((offset + 64ull) << 10) | ((offset + 64ull) << 0));\n    reset_z = 0;\n  }\n\n  for (uint64_t i = 0; i < 16; ++i) {\n    // store interleaved\n    AMX_STZ(load_store_2 | ((i * 4ull + 0) << 56) | (uint64_t)C + i * load_store_width);\n    AMX_STZ(load_store_2 | ((i * 4ull + 2) << 56) | (uint64_t)C + (16 + i) * load_store_width);\n  }\n}\n\r\n\nВыше я добавил комментарии, но есть еще пара интересных штук с флагами для инструкций. Corsix отлично все объясняет, поэтому я просто оставлю ссылки на объяснения:\n\r\n\n\r\n\nзагрузка и хранение\n флагов;\n\r\n\nфлаги\n FMA.\n\r\n\n\r\n\nКак быстро мы к этому пришли? Ну, это зависит от числа килобайт, но к 1.5TFlops мы приходим при высоких значениях.\n\r\n\n\r\n\nНе удивительно, что большие задачи получают лучшую относительную производительность, ведь у кеша больше возможностей для разогрева, а у процессора — для чередования инструкций.\n\r\n\nВ целом на фоне больших современных нейросетей, работающих с общим искусственным интеллектом, эти размеры просто микроскопические. Тем не менее такой тип производительности открывает двери и для меньших нейросетей, которые могут найти себе место в реальных современных вычислениях. Если прогноз можно выполнить на ноутбуке с питанием от батареи за пару десятков наносекунд, то, скорее всего, он имеет ценность больше, чем та ценность, которую мы могли бы добавить в местах, где иначе могла бы применяться эвристика.\n\r\n\nИными словами, по мнению автора, выполненный прогноз имеет ценность больше, чем та ценность, которой можно было бы добиться через эвристику.\nА что думаете по этому поводу вы? Спасибо за внимание!\n\r\n\n\r\n\n\r\n\nПрофессия Data Scientist (25 месяцев)\n\r\n\nПрофессия Fullstack-разработчик на Python (16 месяцев)\n\r\n\n\r\n\n\n                        \nКраткий каталог курсов\n\n                        \nData Science и Machine Learning\n\r\n\n\r\n\nПрофессия Data Scientist\n\r\n\nПрофессия Data Analyst\n\r\n\nКурс «Математика для Data Science»\n\r\n\nКурс «Математика и Machine Learning для Data Science»\n\r\n\nКурс по Data Engineering\n\r\n\nКурс «Machine Learning и Deep Learning»\n\r\n\nКурс по Machine Learning\n\r\n\n\r\n\nPython, веб-разработка\n\r\n\n\r\n\nПрофессия Fullstack-разработчик на Python\n\r\n\nКурс «Python для веб-разработки»\n\r\n\nПрофессия Frontend-разработчик\n\r\n\nПрофессия Веб-разработчик\n\r\n\n\r\n\nМобильная разработка\n\r\n\n\r\n\nПрофессия iOS-разработчик\n\r\n\nПрофессия Android-разработчик\n\r\n\n\r\n\nJava и C#\n\r\n\n\r\n\nПрофессия Java-разработчик\n\r\n\nПрофессия QA-инженер на JAVA\n\r\n\nПрофессия C#-разработчик\n\r\n\nПрофессия Разработчик игр на Unity\n\r\n\n\r\n\nОт основ — в глубину\n\r\n\n\r\n\nКурс «Алгоритмы и структуры данных»\n\r\n\nПрофессия C++ разработчик\n\r\n\nПрофессия «Белый хакер»\n\r\n\n\r\n\nА также\n\r\n\n\r\n\nКурс по DevOps\n\r\n\nВсе курсы\n\r\n\n\n                    \n \n ",
    "tags": [
        "skillfactory",
        "m1",
        "производительность",
        "математика",
        "программирование",
        "числа",
        "матрицы",
        "векторы",
        "c++",
        "amx"
    ]
}