{
    "article_id": "727670",
    "article_name": "AI, остановись! Может ли искусственный интеллект остановить сам себя?",
    "content": "(картинка из \nhttps://www.ibtimes.co.uk/stop-robots-protesters-descend-sxsw-campaign-against-artificial-intelligence-1492126\n)\nПривет хабр! Как вы знаете, мы в \nSmart Engines\n много занимаемся распознаванием на мобильных устройствах, где обрабатываем кадры видеопотока в реальном времени. Почти три года назад \nмы писали о том\n, что в подобных системах возникает крайне интересная задача - принятие решение о том, что захват кадров можно прекратить и текущий результат распознавания принять за окончательный. В той статье мы рассказали о достаточно простом, но эффективном, подходе для решения этой задачи, который смотрит на нее как на монотонную задачу остановки. Сегодня мы расскажем вам о другом подходе к этой задаче, рассматривающем ее как задачу классификации.\nЕсли вам интересно узнать как обучить простой классификатор, узнающий удачный момент для остановки процесса распознавания, и вы уже успели простить нас за кликбейтный заголовок, добро пожаловать под кат!\nВ начале кратко напомним постановку задачи. Мы распознаем текстовую строку в последовательности видеокадров. На каждом \n-м шаге процесса мы умеем получать комбинированный результат распознавания строки, учитывающий все n обработанных кадров, и в любой момент можем остановить процесс, вернув клиенту текущий результат. А если захотим, можем захватить очередной кадр, распознать его, и получить новый результат, который может быть чуть лучше, чем текущий, “заплатив” при этом некоторую условную цену \n (выраженную, например, во времени, которое нужно затратить на обработку нового кадра и комбинирование нового результата с текущим).  В случае, если мы принимаем решение остановиться на шаге \n, мы несем убыток вида \n, где \n - мера неточности аккумулированного результата на шаге \n, выраженная в нашем случае как расстояние \n до истинного значения.\nВ \nнашей предыдущей статье\n на эту тему мы описали подход к принятию решения об остановке процесса, основанный на аппроксимации близорукого правила. Подход работал примерно так:\nОцениваем ожидаемое расстояние от текущего аккумулированного результата до следующего (к примеру, моделируя возможное изменение аккумулированного результата в случае, если на следующем кадре придет что-то похожее на то, что мы видели на предыдущих кадрах);\nОстанавливаемся, если оценка этого расстояния становится меньше некоторого порога (на самом деле, порогом является все та же стоимость наблюдения \n).\nТеперь давайте попробуем построить простой метод с обучением. Переформулируем задачу остановки как задачу классификации: пусть мы добыли откуда-то множество пар \n, где \n - вектор вещественных чисел, а \n - либо 0 либо 1. Вектор \n будет обозначать последовательность расстояний между последовательными аккумулированными результатами распознавания для каких-то \n последовательно идущих кадров, а \n - метка класса, решение о том, нужно ли останавливаться после обработки таких \n кадров (0 - останавливаться рано, 1 - можно останавливаться). Если мы теперь обучим классификатор, принимающий на вход последовательность расстояний и угадывающий правильную метку, мы можем применять его в процессе распознавания после каждого кадра, начиная с \n-го (подавая ему на вход фиксированное окно последних рассчитанных расстояний).\nКлассно и просто, но откуда мы возьмем разметку? Можно попытаться завязаться на настоящие значения ошибок некоторой распознавалки на некотором датасете, но это может жестко прибить классификатор к конкретной задаче, чего делать не очень хочется (не обучать же классификатор для остановки распознавания для каждой комбинации задача-распознавалка-комбинирование). Можно поступить проще - в качестве “эксперта-разметчика” заставим работать \nтот самый метод\n, аппроксимирующий близорукое правило. Мы уже знаем, что он эффективнее чем тривиальное правило остановки, а еще мы знаем, что он точно не идеален, поскольку предполагает монотонность задачи остановки, что от реальности далековато. Обучив ограниченный классификатор на основе данных, полученных таким методом, можно попытаться уменьшить зависимость решающего правила от того, насколько монотонной является задача.\nСхема получения данных для обучения метода остановки\nНе вдаваясь в мелкие детали (их вы можете прочитать в основном тексте научного доклада, ссылка будет в конце статьи), мы обучили простой классификатор с помощью банального \nscikit-learn\n \n(MLP, 3 скрытых слоя, активация relu, с адамом, кросс-энтропия как лосс), взяв в качестве обучающей выборки последовательности результатов распознавания \nнашей распознавалкой\n полей \nMIDV-500\n и MIDV-2019 (только тех типов документов, которых нет в тестовой выборке, всего по 16000 примеров для каждого из классов), а тестировались на \nMIDV-2020\n. На вход подавались векторы из 4-х последовательных расстояний.\nУ обученного метода есть возможность настраивать естественный порог уверенности классификации, варьируя который можно снова построить профиль ожидаемой эффективности (зависимость среднего количества обрабатываемых кадров от средней ошибки) и тем самым сравнив новый метод остановки со старыми. Получается недурно:\nПрофили эффективности на MIDV-2020\nКак видим, обученный метод достигает меньшей средней ошибки распознавания при среднем количестве обрабатываемых кадров 8 и больше (максимальный импакт - 12.7% уменьшение средней ошибки относительно базового метода).\nПотом, без переобучения, мы попробовали этот же классификатор на вообще другой задаче: распознавание текстовых объектов дорожной сцены из датасета \nRoadText-1K\n, с \nраспознавалкой от clovaai\n:\nПрофили эффективности на RoadText-1K\nЗдесь картина получилась похожая, меньшая средняя ошибка уже при среднем количестве обрабатываемых кадров 5 и больше, с максимальным импактом 15.4% относительно базового метода.\nЯвляется ли такой подход стрельбой из пушки по комарам? Может быть и является, но интересно другое - классификатор удалось построить на данных, собранных фактически в автоматическом режиме (поскольку разметка для решения об остановки была получена другим методам), и увеличение эффективности обученного метода относительно базового может означать как раз то, что таким обучением мы смогли сделать метод более “общим”, уже не так сильно завязанным на требования о монотонности задачи.\nСпасибо за внимание, и надеемся что вам было интересно!\nСтатья подготовлена по мотивам доклада на международной конференции по распознаванию образов ICPR 2022: K. Kryuchkova, A. Sheshkus and K. Bulatov, \"Neural network-based prediction of the stopping moment for text recognition in a video stream,\" 2022 26th International Conference on Pattern Recognition (ICPR), Montreal, QC, Canada, 2022, pp. 1450-1456, doi: \n10.1109/ICPR56361.2022.9956040\n.\n \n ",
    "tags": [
        "распознание документов",
        "ocr",
        "компьютерное зрение",
        "видеопоток",
        "алгоритмы",
        "математическая статистика"
    ]
}