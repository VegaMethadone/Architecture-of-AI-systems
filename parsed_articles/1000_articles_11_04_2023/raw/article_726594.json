{
    "article_id": "726594",
    "article_name": "Как перевезти вашу инфраструктуру в K8S в SberCloud, и почему не надо летать в облаках?",
    "content": "Прежде чем начать, приглашаю вас подписаться на наш \nTG-канал\n и \nYouTube\n — мы всегда рады новым друзьям!  \nГлава 1: Китайские достижения.\nВ наши дни весь современный бизнес имеет взлеты и падения - если мы говорим о команде, разрабатывающей свой продукт. Мы можем стать либо свидетелями рождения истории, либо её участниками. Именно так в 1987 году бывший офицер Шэньчжэнь создал свою компанию с капиталом в 20 000 юаней. Её название знает сейчас каждый инженер, но многие не задумываются в смысловом содержании этого названия Hua - “Китай” и Wei - “Достижение”.\n“Так, стоп”, - мысленно подумал сейчас про себя каждый, - “Зачем я сейчас читаю про это? Я хочу узнать что-то про \nSberCloud\n,\n \nи как там обстоят дела с \nk8s\n”. А вот нельзя говорить о \nSberCloud \nи не говорить о\n Huawei Cloud\n, ведь по своей сути это один и тот же продукт, который предоставляется нам сейчас на рынке. Но не хотелось бы впадать в полемику и говорить о том, почему так и никак иначе. Лучше обсудим ряд вопросов, которые действительно интересуют любого инженера, решившего связать свою проектную деятельность со \nSberCloud\n.\nЗачем нам SberCloud?\nМожем ли мы там работать?\nКакие потенциальные трудности мы можем обрести?\nЧто мы получим в конечном счете?\nГлава 2: Бесконечность не предел.\nБыстрый рост продукта, желанная аудитория пользователей, актуальность и потребность - именно эти тезисы вынуждают каждый проект увеличивать темпы разработки, придумывать новые фичи и оптимизировать свой продукт, чтобы быть на плаву. Если размышлять из логики, что у нас имеется \nprod- \nи \nstage-\nконтур, и для счастья ничего больше не надо, то это ошибочное мнение. Всегда были и будут проекты, где помимо одного \nprod\n-контура нужно иметь ещё 5-10 \nstage\n-окружений, которые будут повторять инфраструктуру и сетевое взаимодействие основного контура. Каждый разработчик должен спокойно пушить свои релизы и не аффектить своими работами других сотрудников. При этом должна быть уверенность, что после деплоя в \npre-prod\n ничего не изменится.\nПоднимаем для каждого контура свой сервер, чтобы разграничить среды разработки, и приступаем к настройке сетевого взаимодействия. Все просто! Наше количество текущих серверов всего лишь 80 штук, они включают в себя \nstage\n-стенды для разработчиков, prod, базы данных, файловые хранилища, внутренние инструменты для взаимодействия и составления документации. И вот мы в точке невозврата: как обслуживать всё это, и при этом соответствовать всем требованиям по безопасности? Ведь каждый уважающий себя инженер думает не только о процессах оптимизации, но и о защите своей работы. Нельзя дать пропасть потраченному времени, бессонным ночам и выпитым чашкам кофе.\nОтвет прост, как вопрос: нам нужно кастомизировать наш код, нам нужно облако, где будут \nmanaged\n-решения, призванные упростить обслуживание необходимых компонентов инфраструктуры, нам нужны процессы автоматизации, нам нужен \nIaC\n. Не долго думая \nно долго согласовывая\n наши глаза падают на недорогие ресурсы облачного провайдера \nSberCloud\n. Полдела сделано, но работы ещё бесконечно много.\nГлава 3: Нужно работать не 12 часов, а головой.\nЭтап первый -\n разговариваем с разработкой. \nНеобходимо менять текущие подходы в разработке приложений и отказываться от явных костылей:\nСоздавайте обработку переменных окружения в конфигурациях для последующего их переопределения на этапе деплоя.\nПроектируйте микросервис для работы процессов с единым портом и последующей возможностью распараллеливания задач.\nДобавляйте корректное логирование без лишней информации.\nВносите комментарии в коде и пишите документацию к приложениям.\nИдеальный микросервис - это не тот, который деплоится быстро, а тот, который деплоится в любую инфраструктуру.\nЭтап второй -\n больше не значит лучше. \nРанее мы уже осознали нашу проблему, так что самым важным этапом нашей задачи является создание не 80 \nVPS\n, а среды, которая бы поддерживала автоматизацию развертывания, масштабирования и управления контейнеризированными приложениями. Получается, что нам необходим \nKubernetes.\nНа такой случай \nSbercloud \n предлагает нам \nCloud Container Engine (CCE)\n. Но надо знать, что везде есть как плюсы так и минусы - поговорим о них прямо сейчас.\nРанее уже упоминалось в рамках данной статьи о применении подхода \nInfrastructure as Code\n (IaC) - для этих целей планировалось использовать \nTerraform\n, а значит нам необходим провайдер. У \nSberCloud \nон имеется в открытом доступе и в нем описана большая часть ресурсов, и здесь можно обнаружить сразу явный минус - отсутствие актуализации версии провайдера (последний релиз был 5 месяцев назад на момент написания данной статьи).\nЕсли сравнить тот же провайдер, который имеется у ранее упомянутого \nHuawei\n, то нетрудно заметить, что нет значительной части приятного функционала для дальнейшего развертывания и обслуживания инфраструктуры.\nТакже, не отходя далеко \nот кассы\n провайдера, нужно сказать про главный минус \nCCE\n (помимо предложенных 3-х версий \nKubernetes)\n: стоит заметить, что присутствует функционал выбора развертывания мастеров, и если вы захотите выбрать 3 мастера (это и правильнее, когда речь идет про отказоустойчивость), с их созданием будут проблемы. Всё потому, что количество выделенных серверов под данный процесс в различных \nAZ \nограничено, и их лимиты уже исчерпаны другими пользователями \nSberCloud\n.\nВсе эти минусы присущи почти любому облаку и нельзя сказать, что останавливают нас на пути к \nцели\n, поэтому, сжав зубы перед поставленной задачей, мы приступили к написанию \nTerraform\n-модуля. Но у нас остается принципиальный вопрос общего вида инфраструктуры. Для этих требований мы обратились к документации и выбрали стандартную концепцию с использованием \nElastic Load Balance\n (ELB) для \nAdvanced \nтарифа.\nПосле ряда неудач и успехов с выбором необходимых конфигураций для \nECS\n-нод, был развернут наш первый \nCCE\n-кластер и созданы\n node pool\n, но это лишь начало.\nЭтап третий - \nготовим инфраструктуру.\nКогда речь идет про сетевое взаимодействие, то имеется ряд необходимых задач и вариантов решения. По настройке сетевого взаимодействия с текущей инфраструктурой проекта. К примеру корректный резолвинг внутренних доменов или \nFQDN\n, которые не принадлежат нашему будущему кластеру \nk8s\n. Исходно вложенный функционал \nCCE Sbercloud\n уже имел отличную функцию предустановки \nHelm Chart CoreDNS\n:\nВ нашем же случае дефолтные конфигурации данного ПО нас не устраивали, и было принято решение произвести корректировку чарта посредством \nTerraform \nи предложенной документации \nSberCloud \nпо работе с ресурсами \naddon\n.\n## Addon template\n\ndata \"sbercloud_cce_addon_template\" \"coredns\" {\n\n  cluster_id = var.cluster_id\n  name       = \"coredns\"\n  version    = \"1.23.1”\n}\n\nresource \"sbercloud_cce_addon\" \"addon\" {\n\n  cluster_id    = var.cluster_id\n  template_name = \"coredns\"\n  version       = \"1.23.1\"\n  values {\n    basic_json  = jsonencode(jsondecode(data.sbercloud_cce_addon_template.coredns.spec).basic)\n    custom_json = jsonencode(merge(\n      jsondecode(data.sbercloud_cce_addon_template.coredns.spec).parameters.custom,\n      {\n        stub_domains = {\"site-example.com\": [\"10.10.10.10:53\"]}\n      }\n    ))\n  flavor_json = jsonencode(jsondecode(data.sbercloud_cce_addon_template.coredns.spec).parameters.flavor2)\n  }\n}\nКонечный результат, располагаемый в configmap \ncoredns\n:\n   .:5353 {\n        bind {$POD_IP}\n        cache 30\n        errors\n        health {$POD_IP}:8080\n        kubernetes cluster.local in-addr.arpa ip6.arpa {\n            pods insecure\n            fallthrough in-addr.arpa ip6.arpa\n        }\n        loadbalance round_robin\n        prometheus {$POD_IP}:9153\n        forward . /etc/resolv.conf {\n            policy random\n        }\n        reload\n    }\n\n    site-example.com:5353 {\n        bind {$POD_IP}\n        errors\n        cache 30\n        forward . 10.10.10.10:53\n    }\nОтлично, решение этой проблемы было найдено через документацию, но у нас присутствует ещё целевой ряд проблем с ограничением трафика к нодам, а также к ограничению трафика к \nELB\n, который планируется у нас как входная точка трафика для пользователей. И тут уже простым решением правки конфигурации через ресурс обойтись сложно. Так как \nCCE\n является нашим \nmanaged \nрешением, то идеологический вариант с ручным вмешательством в \nsecurity groups\n серверов \nNode pool\n нам не подойдет, вследствие чего мы пошли масштабней и решили ограничивать трафик к подсети наших нод с помощью применения \nNetwork ACLs\n - этот механизм закрывает вопрос с доступом трафика к серверам, но остается задача с \nELB.\nНа этапе поднятия \nprovider Sbercloud \nпредоставляет нам возможность автоматизированного создания балансировщика через установку \nHelm Chart ingress-nginx\n и \nannotations\n:\napiVersion: v1\nkind: Service\nmetadata:\n   annotations:\n      kubernetes.io/elb.class: union\n      kubernetes.io/session-affinity-mode: SOURCE_IP\n      kubernetes.io/elb.subnet-id: 5083f225-9bf8-48fa-9c8b-67bd9693c4c0\n      kubernetes.io/elb.autocreate:\n\"{\\\"type\\\":\\\"public\\\",\\\"bandwidth_name\\\":\n   \\\"cce-bandwidth- 1551163379627\\\",\n   \\\"bandwidth_chargemode\\\":\\\"bandwidth\\\",\\\"bandwidth_size\\\":5,\n   \\\"bandwidth_sharetype\\\":\\\"PER\\\",\n   \\\"eip_type\\\":\\\"5_bgp\\\",\\\"name\\\":\\\"james\\\"}\"\n   labels:\n      app: nginx\n      name: nginx\n spec:\n   externalTrafficPolicy: Local\n   ports:\n   - name: service0\n     port: 80\n     protocol: TCP\n     targetPort: 80\n   selector:\n     app: nginx\ntype: LoadBalancer\n\nПосле чего, в зависимости от описанных нами ранее портов и протоколов, поднимаются дополнительные компоненты балансировщика: \nListener - порты для входа трафика.\nBackend Server Groups - конечные точки для проксирования.\nНо при этом по умолчанию отсутствует немаловажный аспект \nWhitelist\n - это список ip, которым разрешен доступ до нашего порта балансировщика на уровне сетевого протокола L7, и уже тут возникают трудности.\nСогласно документации \nSberCloud ELB\n можно создать Whitelist на уровне провайдера \nTerraform\n, но у нас остается вопрос закрепления \nWhitelist \nза \nListener \nна уровне \nTemplate \nи  \nprovider Terraform \nего покрыть не может, ввиду отсутствия \nData Sources \nу этой сущности. Получается процесс добавления и изменения списка доступных IP-адресов будет иметь ручные действия с нашей стороны? К сожалению это так, именно поэтому сразу хочется поставить большой минус.\nЭтап четвертый \n-\n \nвнутреннее сетевое взаимодействие по локальной сети.\nSecurity groups\n и \nNetwork ACLs\n прекрасно справляются, в свою очередь, с ограничением сетевого взаимодействия как на входящий, так и на исходящий трафик, но любой человек, который редко работает с сетями \nk8s\n, может столкнуться с интересным явлением получения запроса к любой конечной точке из контейнера нашего пода с ip-адресом этого контейнера. Первый вопрос каждого пользователя будет звучать приблизительно так: “Если контейнеры вращаются на нодах, у которых есть локальный сетевой интерфейс, как мой запрос может иметь IP-адрес контейнера?”.\nПроблема, описанная в четвертом этапе, заключается непосредственно  в использовании не совсем корректных правил фаервола, выставленных параметром настройки \nCCE Service Forwarding Mode\n,\n \n- режим \niptables\n. Данный режим является стандартным и говорит о том,\n сетевой прокси, располагаемый на каждой ноде\n нашего кластера \nkubernetes, \nбудет\n \nиспользовать для обработки трафика правила \niptables, \nкоторые также  включают в себя стандартный набор правил \nmasquerade\n.\nОсновная функция маскарадинга заключается в изменении адреса пакетов, выходящих из \ncontainer network\n на IP-адрес \nworker node\n. Но, не смотря на прямое наличие данных правил, их функционирование оставляло желать лучше и требовало бы в будущем ручного вмешательства на всех нодах кластера \nk8s\n, что является не приемлемым вариантом в нашем случае.\nДля автоматизации данного процесса был найден - \nip-masq-agent\n. Решение, найденное весьма интересным образом за чашкой кофе, является очень простым, и требует лишь написания корректной конфигурации в \nconfigmap\n с обозначением подсетей нашего \nCCE\n кластера, включая дополнительно подсеть \nMaster node\n:\napiVersion: v1\ndata:\n  config: |\n    nonMasqueradeCIDRs:\n      - Master node Subnet\n      - Nodepool Subnet\n      - Service Network Segment\n    resyncInterval: 5s\n    masqLinkLocal: false\nkind: ConfigMap\nmetadata:\n  name: ip-masq-agent\n  namespace: kube-system\nИ применением \nyaml \nманифеста \nDaemonSet \nс тегом образа контейнера агента:\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ip-masq-agent\n  namespace: kube-system\nspec:\n  selector:\n    matchLabels:\n      k8s-app: ip-masq-agent\n  template:\n    metadata:\n      labels:\n        k8s-app: ip-masq-agent\n    spec:\n      hostNetwork: true\n      containers:\n      - name: ip-masq-agent\n        image: registry.k8s.io/networking/ip-masq-agent:v2.8.0\n        securityContext:\n          privileged: false\n          capabilities:\n            add: [\"NET_ADMIN\", \"NET_RAW\"]\n        volumeMounts:\n          - name: config\n            mountPath: /etc/config\n      volumes:\n        - name: config\n          configMap:\n            # Note this ConfigMap must be created in the same namespace as the daemon pods - this spec uses kube-system\n            name: ip-masq-agent\n            optional: true\n            items:\n              # The daemon looks for its config in a YAML file at /etc/config/ip-masq-agent\n              - key: config\n                path: ip-masq-agent\n\nКак следствие, получаем желаемый результат в виде локальных IP-адресов наших \nNode \nвместо ip контейнеров при обращении из контейнера к ресурсам локальной сети.\nЭтап пятый \n- мониторинг.\nПосле приготовления всех основных архитектурных элементов, была острая необходимость обложиться метриками и к счастью или сожалению, здесь появилась одна из задач, решения которой нет до сих пор. Изначально было весьма неприятно узнавать о недоступности одного из \nstage\n-окружений от отдела разработки. Как минимум, это увеличивало время решения задачи из-за разности часовых поясов, и когда разработка уже знает, о том что релиз фичи придется отложить, не подозревающий системный администратор или \nDevOps \nинженер ещё только мечтает в кровати о том, какой кофе он будет пить на завтрак.\nОсновной целью этой задачи было применить все возможные средства для хранения метрик и удобного оповещения ответственных при возникновении проблем, и хотя применение стандартного решения в виде использования \nHelm\n-чарта\n Kube-prometheus-stack\n в сумме с \nblackbox exporter\n помогает отслеживать состояния нод, подов, стендов и основных компонентов \nk8s\n. Остается вопрос мониторинга \nManaged Database\n,\n \nрасполагаемых в \nSberCloud\n, и здесь начинается самое интересное.\nРанее мы уже проговаривали, что есть ряд требований по безопасности, которые необходимо учесть при построении инфраструктуры. В их число также входит и обеспечение безопасной сетевой связности между компонентами приложения и базой данных. В нашем случае подключение к \nMongoDB\n должно происходить только по защищенному \nSSL-соединению\n,\n \nи в этой части присутствует полное взаимопонимание со стороны отдела Кибербезопасности и \nDevOps\n-инженеров. Но есть одна маленькая загвоздка, связанная непосредственно с \nDocument Database Service \n(MongoDB в Sbercloud), которая гласит о необходимости использования функции отключения проверки имени хоста в сертификате \nSSL \nc помощью параметра настройки “sslAllowInvalidHostnames”.\nИ хотя для \nMongoDB \nимеется официальный \nPercona\n-экспортер, в основе которого располагается \nmongo-go-driver\n, в нем отсутствует работа с данным параметром и, как следствие, его передача в строку подключения \nMongoDB \nне представляется возможным. Таким образом, данный вариант нам не подходит, но можно воспользоваться встроенными средствами мониторинга \nCloud Eye\n, который записывает метрики и отображает их в виде графика. Для push-алертов с метрик достаточно лишь использовать аналогичный сервис отправки сообщений \nSimple Message Notification\n (SMN)\n. Данный сервис включает в себя\n ряд стандартных ресурсов \nTopics\n, \nSubscriptions\n, \nMessage Template, позволяющих после первичной настройки\n произвести отправку алерта в любого вида конечную точку, как по протоколу \nSMTP\n, так и по протоколу \nHTTP.\nВсе было бы хорошо, если бы не одно интересное “но”, которое нельзя не подметить. После создания любого рода доставщика до конечной точки необходимо подтвердить права владения \nendpoint’ом\n через форму подтверждения, присылаемую на этот \nendpoint.\n И если вопросов относительно Email нет (ведь все логично, и эта стандартная процедура многим знакома), то как быть с протоколами \nHTTP \nи \nHTTPS \n? Вопрос оказался настолько интересным и занятным, что ни документация, ни техническая поддержка облака не может дать на него корректный ответ по сей день.\nМногие из читающих, я уверен, сразу же подумали: “Зачем рассказывать о том, что не работает? Ну не доработали функционал, поступи как настоящий \nDevOps \n- возьми конечную точку \nAPI\n, \naccess key\n и \nsecret key\n и напиши \nexporter\n сам!” Вопрос данного решения остается лишь в трудозатратах и реализации.\nУ \nSberCloud \nприсутствует весьма неплохая документация относительно взаимодействия c \nAPI\n, но, к сожалению, на написание универсального решения может понадобиться весьма большое количество времени, так как запросы к \nAPI \nимеют сложную структуру и непременно должны содержать \nID \nсущностей или виртуальных машин. Это изрядно осложняет как задачу по созданию экспортера, так и задачу по поддержке и обслуживанию мониторинга со стороны других администраторов.\nГлава 4: Параллельные прямые не пересекаются.\nПоговорим о главном: в конечном счете, каждый человек, занимающийся той или иной проблемой, любит принимать участие в определённых этапах решения задачи. Кому-то нравится придумывать идеи и планировать решение задачи, кто-то любит, молча закрывшись от всех, реализовывать чужие задумки, а кто-то предпочитает показывать и представлять решение большой публике. В данном случае в нашей работе пришел момент, когда мы завершили все основные этапы работы с инфраструктурой клиента, и надо было представить результат. \nПрактическая идея была проста в своей сути, увеличение количества различных \nstage\n-стендов, путем расположения их в различные \nnamespace kubernetes\n. Всё это дает возможность нескольким разработчикам без труда деплоить решения своих задач, не мешая другим. Установка \nlimits\n и \nrequests\n помогла предотвратить неожиданные проблемы связанные с потреблением оперативной памяти и \nCPU одним из стендов\n. Малое количество серверов с большими конфигурациями позволило отойти от горизонтального масштабирования и упростило жизнь системным администраторам, а клиент, в свою очередь, получил более быструю реализацию своих идей, придерживаясь минимального \nTime to market\n для продукта.\nГлава 5: Обобщим про SberСloud.\nSberСloud \nвыглядит как весьма интересный продукт, которому есть к чему стремиться. Он помогает закрывать большую часть желаемых потребностей клиента и оптимизировать сроки развертывания вашей будущей инфраструктуры, но зачем хвалить там, где хвалить не надо? Как и у любого облака здесь имеются свои недоработки, пробелы в документации и вопросы к \nroadmap \nразвития проекта, но и текущего функционала нам хватило, чтобы закрыть имеющиеся боли бизнеса.\nПолучается, все остались довольны? Все, но не всем. Ведь остались незакрытые вопросы, связанные с инфраструктурой, которые (само собой) отправились в \nbacklog - это и\n острый вопрос относительно мониторинга \nMongoDB, \nи вопрос автоматизации процессов по изменению \nWhitelist \nдля \nELB\n. Однако основные поставленные задачи со стороны бизнеса были выполнены, а по поводу остального  можно сказать лишь одну простую вещь “Нет предела совершенству”.\n \n ",
    "tags": [
        "sbercloud",
        "sbercloud.advanced",
        "kubernetes",
        "devops",
        "time to market",
        "terraform",
        "huawei",
        "iac",
        "k8s",
        "network security"
    ]
}