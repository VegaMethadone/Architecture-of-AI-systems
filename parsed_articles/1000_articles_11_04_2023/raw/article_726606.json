{
    "article_id": "726606",
    "article_name": "Большие языковые модели как новый инструмент в научной работе",
    "content": "На волне хайпа вокруг ИИ высказываются все и вся, чем-то напоминая мне ситуацию вокруг Биткойна, когда вроде бы уважаемые люди вдруг начали говорить про него прямо противоположные вещи (криптовалюты это полезно - ИИ это полезно / запретить криптовалюты - запретить ИИ). Хочу внести капельку рациональности в этот поток мыслей и рассказать \nкак не нужно\n как можно использовать большие языковые модели на примере ChatGPT версии 4.0 в научной работе. Этот пост основан на \nнаучной статье, которую я опубликовал\n в соавторстве с \nВ.Л. Макаровым\n и \nА.Р. Бахтизиным\n.\nНемного введения\nТо самое GPT из названия модели - это Generative Pre-Trained Transformer. Или, по-русски: \nавторегрессионная генеративная языковая модель на архитектуре трансформер\n.\nТоже по-русски, но ничего непонятно\nЯзыковая модель\n нужна для понимания и генерации контента на естественном языке. Они бывают порождающие (генеративные) и дискриминантные.\nПорождающие модели\n - статистические модели, которые основаны на анализе самих данных и позволяющие создавать новые экземпляры данных. \nДискриминантные модели\n же модели тоже статистические, но решают задачу классификации данных.\nРазвитие глубокого обучения привело к широкому использованию различных нейронных сетей для решения задач \nобработки естественного языка\n (NLP), включая \nсвёрточные нейронные сети\n (CNN), \nрекуррентные нейронные сети\n (RNN), \nнейронные сети на основе графов\n (GNN) и \nмеханизмы внимания\n. Ключевым преимуществом этих нейронных моделей является их способность в некотором роде упростить разработку модели. Традиционные не-нейронные подходы к задаче NLP  зависят от дискретных, вручную создаваемых функций, в то время как нейросетевые методы обычно используют низкоразмерные и \nплотные векторы\n для неявного представления синтаксических или семантических аспектов языка.\nТрансформер\n - архитектура глубоких нейросетей, которые как и RNN, предназначены для обработки текстов на естественном языке, перевода, суммаризации, но не требует обработки текста по порядку. Что открывает прекрасные возможности по распараллеливанию её работы.\nБольшое количество исследований проведённых за последнее время показало, что \nпредварительно обученные\n \nмодели\n (pre-trained models - PTM) на больших корпусах текстов могут обучиться универсальным языковым представлениям, которые полезны для последующих задач NLP и позволяют избежать обучения новой модели с нуля. С развитием вычислительной мощности, появлением глубоких моделей и постоянным совершенствованием навыков обучения архитектура PTM продвинулась от поверхностной к глубокой.\nПоколения PTM моделей\nПервое поколение\n PTM стремилось получить векторное представление слов. Поскольку эти модели не нужны для последующих задач обработки языка, они обычно очень неглубоки с точки зрения вычислительной эффективности. Примерами таких моделей являются \nSkip-Gram\n и \nGloVe\n. Полученные векторы хоть и могут передать семантические значения слов, но не зависят от контекста и не могут уловить более высокоуровневые концепции.\nВторое поколение\n PTM сосредоточено на изучении контекстных векторных представлений слов и улучшении моделей первого поколения. Примерами таких моделей являются \nCoVe\n, \nELMo\n, \nOpenAI GPT\n и \nBERT\n.\nPTM \nтретьего поколения\n основываются на втором поколении, с увеличенной производительностью и снятием некоторых ограничений. Нет чёткого определения этого поколения или списка моделей, однако можно выделить следующие характеристики:\nУлучшенное понимание контекста, захват сложных семантических отношений.\nМультимодальное обучение: могут интегрировать информацию из нескольких источников или модальностей, таких как текст, изображения и аудио.\nМасштабируемость и эффективность: повышении производительности, например, с помощью методов сжатия моделей или более эффективных архитектур.\nБолее сложные задачи предварительного обучения: лучшее улавливание лингвистических и структурных свойств входных данных.\nНовейшим является \nчетвёртое поколение\n моделей PTM. В дополнение к основным достижениям третьего поколения, добавляется следующее:\nБольше данных для обучения и больше параметров позволяет им улавливать более широкий спектр языковых моделей и нюансов.\nУлучшенные возможности понимания и генерации, что приводит к более связному и контекстуально точному созданию текста.\nУсовершенствованная точная настройка и перенос обучения. Можно увеличить производительность под конкретную задачу, например, перевод, реферирование и ответы на вопросы.\nУвеличение масштабируемости и эффективности.\nНа данный момент к четвёртому поколению моделей PTM относится только GPT-4 от компании OpenAI, а наиболее распространёнными моделями третьего поколения являются BERT и LLama.\nДавайте рассмотрим эти модели не просто как универсальный инструмент, а как средство и метод для выполнения определённых задач научной работы. Очевидно, что существуют как серьёзные ограничения применения такого инструмента, так и потрясающие новые возможности помощи учёным и исследователям в разных областях науки.\nВозможности применения ChatGPT в научной работе\nЭта тема сейчас является горячо обсуждаемой в научных кругах. Но в силу инерционности классического процесса публикаций в науке качественных работ в этой области пока ещё не много. В основном преобладают разнонаправленные публикации по медицинской тематике, а также обсуждение проблемы плагиата. Чуть более подробно про это можно почитать в \nопубликованной научной версии статьи\n.\nЯ пользуюсь только четвёртым поколением модели, т.к. GPT-3.5 провалило слишком много моих тестов. Самым провальным на мой взгляд оказался тест на логику из мема ниже, притом в разных вариациях. Например, если 2 машины доехали из Москвы в Петербург за 5 часов, то 4 машины доедут за 2.5 часа, согласно умозаключению GPT-3.5.\nНанимает 9 женщин и думает, что они родят через месяц\nЯ попробовал применить ChatGPT в разных областях науки: медицине, химии, физике, биологии, но наглядно проиллюстрировать хочу примером, который касается области моих научных интересов (\nагентного моделирования\n). Вот, представим, пишу я обзорную статью о больших агент-ориентированных моделях стран, и слышал, что есть такая экономическая модель Швейцарии под названием MIMOSE. Спрашиваю ChatGPT: расскажи в каких научных статьях описывается эта модель для последующей ссылки в своей работе:\nСкажи какую научную статью процитировать, когда пишешь о модели MIMOSE\nВажно упомянуть, что этот вопрос был задан в контексте беседы, которая началась с нескольких вопросов про большие агент-ориентированные модели стран и регионов, и ChatGPT уже самостоятельно предоставил верное описание MIMOSE. Вот полный текст ответа, который выглядит очень убедительно, логично и связанно.\nЕсли вы пишете о модели MIMOSE, то можете рассмотреть следующе статьи ...\nВ первом же предложении ChatGPT представляет данные оригинальной статьи (Bretschger, Smulders 2012), в которой описывается модель MIMOSE. Такая статья действительно существует и имеет такое же название, но, она была опубликована в 2003 году, а не в 2012, и вовсе не в Скандинавском журнале экономики, и вообще, она хоть и является статьей по тематике агент-ориентированного моделирования, но совсем никак не затрагивает модель Швейцарии под названием MIMOSE. Но почитайте, с какой безапеляционностью ChatGPT заявляет об обратном!\nСледующая статья из списка (Bretschger, Valente 2012) тоже существует в реальности, также не имеет отношения к MIMOSE, год публикации указан верно, но опять модель ошиблась с журналом указав другой реально существующий академический журнал Resource and Energy Economics, вместо Journal of Environmental Economics and Management. Статьи за авторством Karydas, Katsikas et al найти вообще не удалось, но даже судя по названию она не соответствует заявленной тематике вопроса. Заключительная ссылка на статью авторов Rutherford, Tarr также является вымыслом системы, хотя такие авторы существуют в реальности и публикуют статьи на схожие тематики.\nВ попытке дать ChatGPT возможность сохранить лицо, попросили её указать на статью, в которой описывается сама модель MIMOSE:\nВопрос был задан в рамках той же беседы с контекстом, и между ними не было никаких дополнительных разговоров. На что был получен вот такой ответ:\nИзвините пжлста, модель в деталях описана в статье...\nChatGPT \nизвиняется за свою ошибку\n, хотя ни в одном запросе не упоминается об ошибочности выданной информации. И снова выдаёт новую вариацию на статью авторов Bretschger et al, утверждая, что в ней даётся исчерпывающий обзор агент-ориентированной модели MIMOSE, особенностей её реализации, структуры модели, включая используемые типы агентов. Ещё раз акцентирую внимание на то, с какой уверенностью подаётся абсолютно ложная информация, даже после уточняющего вопроса.\nКак-то так\nЗаключение\nОсновная ценность состоит не только в умении ChatGPT переписывать, перефразировать и переводить тексты. Первые два пункта вообще только вредят обществу, а с переводом уже давно неплохо справляется Google Translate. Истинная же ценность ChatGPT - в анализе огромнейшего массива информации и поиске в нём той части, которая нужна исследователю, и объяснение её тем «языком», который требуется.\nChatGPT не должен и не может быть автором или соавтором той или иной научной работы! Эта система является инструментом в работе учёного. Таким же, как, например, поисковые системы Google, Яндекс, более продвинутые системы, как Wolfram Alpha, системы цитирования и индексирования РИНЦ, Web of Science и Scopus. Автор всегда должен проверять и брать на себя ответственность за тот материал, который он создаёт, вне зависимости от того инструмента, которым он пользуется.\nЯ специально привёл отрицательные примеры, чтобы предостеречь излишне доверчивых людей к использованию результатов \"как есть\". Да и не все рецензенты скрупулёзно проверяют список публикаций на достоверность.\nС появлением ChatGPT мемчик стал ещё более актуальным\nПоложительные же примеры приводить не имеет смысла - их бесчисленное множество, и каждый из вас (при наличии доступа, разумеется) может сам задать нужные вопросы. При подготовке этой статьи, безусловно, был использован ChatGPT, не только в качестве объекта изучения, но и в качестве инструмента изучения. Но, лишь для уточнения определённых вопросов, получения дополнительной информации, а никак не для написания (или переписывания) текста. Вопрос, можно ли доподлинно отличить текст, написанный ChatGPT и текст, написанный человеком пока остаётся открытым.\n \n ",
    "tags": [
        "chatgpt",
        "gpt",
        "искусственный интеллект"
    ]
}