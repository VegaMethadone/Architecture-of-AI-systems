{
    "article_id": "725612",
    "article_name": "Проверяй и доверяй: упрощаем функциональное API-тестирование в облаке",
    "content": "\r\n\n\r\nВсе больше компаний переводят свои продукты в облака — и сталкиваются со всеми сложностями тестирования в облаке. Это непростой процесс: каждое облако состоит из множества сложных вторичных сервисов с широкой функциональностью, они тесно связаны друг с другом. Нужно думать, как написать тесты так, чтобы они были универсальными, хорошо переносимыми и поставлялись в разные окружения.\n\r\n\n\r\nМеня зовут Павел Балахонов, я старший инженер по автоматизированному тестированию. В этой статье расскажу, как мы упростили и автоматизировали функциональное тестирование в \nPrivate Cloud от VK\n — платформе для построения частного облака в крупных компаниях и госорганизациях, какие решения использовали и что из того, что есть у нас в активе, открыто для общего использования.\n\r\n\n\r\n\nПочему именно функциональное тестирование\n\r\nДля нас важно проверять работоспособность продукта в облаке, и главный инструмент этой проверки — функциональное тестирование. Оно позволяет проверить работу компонентов в контексте всего облака с позиции взаимодействия конечного пользователя. \n\r\n\n\r\nПоэтому в нашей команде приоритетным стало именно функциональное API-тестирование. API-тесты быстрее, чем UI, меньше привязаны к структуре и изменениям в DOM страницы. А еще они позволяют проверить работу функциональности с параметрами, которые невозможно передать с фронтенда из-за специфики интерфейса. Скажем, когда вы создали базу данных в Trove, но не знаете наверняка, реализуется ли бэкап, не «ломаются» ли таблицы после него. \n\r\n\n\r\nВ общем, API-тестирование — ключ к уверенности, что продукт жизнеспособен и работает в облаке. Поэтому первым объектом автоматизации стало именно оно. \n\r\n\n\r\n\nВыбор стека\n\r\nНа этапе выбора стека было три возможных варианта действий:\n\r\n\n\r\n\n\r\n\nВзять классический стек: Pytest (test runner + assertions), Allure (report system) и Requests (http client).\n\r\n\n\r\n\nАдаптировать фреймворки, которые использовали для тестирования в публичном облаке.\n\r\n\n\r\n\nВзять готовый инструмент для написания функциональных API-тестов. \n\r\n\n\r\n\n\r\nПервый вариант отмели сразу по нескольким причинам.\n\r\n\n\r\n\nСложно. \nНесмотря на то что и Pytest, и Allure — самые популярные на рынке решения, нам они не подходили. Самая простая функциональность в этом случае потребовала бы очень много ресурсов. Например, чтобы сделать гибкую авторизацию в облаке, нужно было бы не просто обеспечить заведение всех необходимых ресурсов в Keycloak и IAM, но и озаботиться поддержкой ролевой модели и получения токена авторизации для разных групп пользователей. Конечно, можно было бы сгенерировать пользователей с разными ролями и брать их из фермы, но это увеличило бы время прогона тестов примерно на час. \n\r\n\n\r\n\nНет гибкости.\n Для нас важна возможность запуска тестов с различными ролями и передачи этих ролей. Такую функциональность пришлось бы создавать с нуля, что тоже отняло бы силы и время.\n\r\n\n\r\n\nСложная интеграция\n с IAAS- и PAAS-компонентами облака, для которой нужно было бы добавлять огромное количество REST-клиентов.\n\r\n\n\r\n\nНет системы чистки ресурсов\n, поэтому пришлось бы неизбежно закладывать ресурсы на ее реализацию. \n\r\n\n\r\nВторой вариант казался более жизнеспособным. Но при проверке выяснилось, что большинство фреймворков для публичного облака невозможно или очень сложно адаптировать под частное. В нашем случае три месяца ушло на вычитку кодовой базы, и мы пришли к простому выводу: интеграция фреймворка с публичным облаком была такой тесной, что проще сделать что-то свое. \n\r\n\n\r\nВ результате остановились на третьем варианте: взять готовый инструмент и адаптировать его под свои задачи. Таким инструментом стал Tempest.\n\r\n\n\r\n\nTempest: почему взяли, как адаптировали и что получилось\n\r\nПочему решили остановиться на Tempest:\n\r\n\n\r\n\n\r\n\nOpenstack.\n Фреймворк относится к категории открытого ПО;\n\r\n\n\r\n\nпростая интеграция в конвейеры.\n Tempest написан на Python, как и большинство компонентов частного облака. Это упрощает адаптацию существующих и разработку новых тестов для разработчиков, которые пишут новые сервисы на этом языке;\n\r\n\n\r\n\nинтеграция с IaaS\n серьезно упрощает адаптацию под наше облако;\n\r\n\n\r\n\nмеханизм чистки\n есть из «коробки». \n\r\n\n\r\n\n\r\n\nКак адаптировали Tempest\n\r\nПервым делом пришлось настроить взаимодействие. Tempest «из коробки» заводит пользователей и проекты в Keystone, получает оттуда токен-авторизацию, подписывает все запросы и по умолчанию считает, что этого достаточно для взаимодействия с IaaS- и PaaS-компонентами. Нам этого было мало, поэтому сделали так. Сначала заходим в Keycloak, создаем пользователя в Realm и группу, которая синхронизируется с IAM. После этого создаем проект в IAM и распределяем роли в группе. Обмен токенами для авторизации с Keystone происходит только после всех этих действий — значит, все запросы отправляются под созданным пользователем, только в рамках реально созданного проекта и с теми ролями, которые мы добавили на группу. \n\r\n\n\r\nДалее пришлось решить задачу с валидацией ответов. Сначала решили, что ряд запросов будем валидировать через схемы. Но функциональность может нарушиться из-за смены типа в ответе, причем, возможно, этот тип будет редким или неиспользуемым, но тест из-за этой смены упадет и нам придется тратить ресурс на адаптацию. Вот почему решили избавиться от валидации ответов по схемам и проверять только функциональность.\n\r\n\n\r\nКроме того, решили все PaaS-тесты запускать только под теми проектами, которые заводим в IAM, а IaaS — под пользователем в заданной роли. Роли можем менять, только если в тест-кейсе есть на это прямое указание, во всех других случаях IaaS-функциональность тестируется только под администратором облака.\n\r\n\n\r\nИ наконец, договорились о том, что покрываемую автотестами функциональную единицу не будем закрывать без негативных тестов. Это важно, так как с точки зрения входных данных пользователь сам является генератором случайных данных. Важно иметь подстраховку на случай каких-то спецсимволов в названии виртуальной машины или вообще двух виртуальных машин с одинаковыми названиями. Эта доработка защитила нас от большого количества багов в негативных тест-кейсах.\n\r\n\n\r\n\nТест-дизайн\n\r\nС тест-дизайном, как и со стеком, было несколько возможных вариантов. Первый — написать монолит автоматизации, включающий в себя все тесты для всех компонентов облака. Но в этом случае пришлось бы решать вопрос с заказчиками, у которых различное окружение и потребности. Одному нужна только IaaS, другому — кластеры в облаке, третьему — базы данных в облаке.\n\r\n\n\r\nПоэтому при выборе тест-дизайна решили пойти по пути тестирования компонентов. Каждый репозиторий представляет собой Tempest-плагин, сущность для определения контекста тестирования, и каждый содержит тесты только для своего компонента. Конечно, с точки зрения разработки и поддержки это сложнее: приходится постоянно переключаться между окнами IDE. Зато решается вопрос с предоставлением индивидуального окружения: если инженер приходит к нам за тестированием нейтрона, он получит только необходимые тесты, а не весь монолит в совокупности.\n\r\n\n\r\n\nАрхитектура\n\r\nАрхитектуру решили сделать двухуровневой: SUT, REST-клиенты взаимодействия и тесты. REST-клиенты состоят из базового интерфейса CRUID (create, read, update, insert, delete) и наследуются из родительского REST-клиента Tempest, в котором реализована одна из важных функций — возможность получения различных типов Endpoint для сервиса, например Public endpoint для Manila. На случай, если нужного сервиса в каталоге Endpoint не обнаружится, добавили в REST-клиент фреймворка возможность передачи base url на сервис.\n\r\n\n\r\n\nКонфигурация\n\r\nОдно из важных преимуществ Tempest — простота конфигурирования. Конфигурации можно определять, добавляя и регистрируя категории и опции в config.py, группы и параметры в группе. \n\r\n\n\r\n\nКак строится работа с автотестами.\n Из-за стандартов безопасности автотесты мы разрабатываем только на удаленных машинах в той же сети, в которой работают коллеги, собирающие проекты в Jenkins. В противном случае пришлось бы каждый раз ходить к коллегам из ИБ и просить сделать доступ к порту. \n\r\n\n\r\nСейчас каждый автоматизатор создает машину Dev в облаке, подключается к ней, забирает кодовую базу нужного компонента, адаптирует ее под наше облако и разрабатывает новые автотесты согласно сценариям. С одной стороны, это требует времени, хотя бы для подключения к виртуальной машине через Dev-point. С другой стороны, соблюдаются стандарты безопасности, потому что кодовая база хранится на виртуальных машинах внутри компании. \n\r\n\n\r\nСейчас, помимо автоматизаторов VK, пользоваться нашими тестами могут и сторонние команды — все, кому нужно готовое решение, чтобы протестировать собственные продукты в облаке. Для внешних автоматизаторов мы готовим Docker-образы плагинов для тестирования различных компонентов облака, с помощью которых можно легко запустить автотесты и тестировать отдельные компоненты в любом окружении — публичном или частном облаке, даже в любом «ванильном» OpenStack-сервисе. \n\r\n\n\r\n\nРесурсы, скорость и поиск багов: как повысить доверие к автоматизации\n\r\nСуть автотестов в том, чтобы сэкономить время и ресурсы на тестировании продукта. Но никакой экономии не получится, если тестироваться будут далекие от реальности юзер-кейсы, а сами тесты будут медленными. Чтобы застраховаться от этого, мы доработали Cleanup-сервис Tempest, адаптировав его под нашу коробку. \n\r\n\n\r\nСейчас чистка ресурсов включает в себя два этапа: чистка по слепку с облачной платформы и по Teardown-событиям, запущенным после прогона теста. Важно контролировать ресурсы, созданные после запуска теста, и регистрировать события на их удаление. Это позволит не создавать лишние ресурсы и тестировать в квотах, максимально приближенных к квотам заказчика.\n\r\n\n\r\nЕще один важный момент — поиск багов. Одна из главных химер мира автоматизации — Flaky-тесты, когда один и тот же тест поочередно становится то зеленым, то красным, то опять зеленым. Так что никто до конца не знает, является это багом или просто ошибкой теста. \n\r\n\n\r\nМожно долго спорить о природе Flaky-тестов, но мы решили вопрос проще: исключили нестабильные тесты из окружения. Если тест упал, то смотрим, какие изменения в продукте могли к этому привести, и адаптируем автотест. Как результат, тесты находят реальные баги.\n\r\n \n\r\nПомимо прямого улучшения продукта, этот процесс имеет и приятный побочный эффект: это способствует росту доверия к автоматизации внутри нашей компании и за ее пределами. Репутация автоматизаторов периодически испытывается на прочность: кто-то говорит, что это дорого, сложно и бесполезно. Наши решения опровергают эти утверждения и укрепляют доверие к автоматизации, доказывая, что она может быть быстрой, качественной, стабильной и эффективной для любого бизнеса.\n\r\n\n\r\n\nПосмотреть сами, как работает автоматизация, вы можете у нас в облаках — как в \nчастном\n, так и в \nпубличном\n. Новым пользователям мы начисляем 3000 ₽ на тестирование. Пробуйте и оставляйте обратную связь, мы будем благодарны.\n \n ",
    "tags": [
        "vk cloud",
        "API-тестирование",
        "функциональное тестирование",
        "temptest",
        "flaky-тесты",
        "private cloud"
    ]
}