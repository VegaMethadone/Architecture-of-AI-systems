{
    "article_id": "726654",
    "article_name": "Фортран: пишем параллельные программы",
    "content": "Современный Фортран представляет собой специализированный язык программирования, предназначенный в основном для написания вычислительных программ для векторно-конвейерных и параллельных архитектур. Эволюция стандартов языка Фортран была рассмотрена в предыдущих статьях – \nздесь\n  и \nздесь\n.\nНа данный момент действующим стандартом языка Фортран является стандарт ISO 2018 года \"Fortran 2018\", готовится к принятию стандарт 2023 года. К сожалению, различные компиляторы Фортрана поддерживают требования стандартов в различной степени.\nВ этой статье мы попробуем написать простейшую параллелизуемую программу на языке Фортран, используя для этого методы конвейеризации и симметричной параллелизации и сравним их между собой, применив наиболее популярные компиляторы GNU Fortran и Intel Fortran.\nВ целом, компилятор Intel Fortran гораздо более полно реализует стандарт Fortran 2018. В частности, он поддерживает все имеющиеся в стандарте средства параллельных вычислений, в то время как GNU Fortran реализует только самые базовые из них (чего, впрочем, в ряде случаев более чем достаточно). С другой стороны, Intel Fortran, в отличие от GNU Fortran, не обеспечивает реализацию символьного типа \nCHARACTER (KIND=4)\n с поддержкой кодировки UCS-4, что может затруднить обработку не-ASCII текстов. Бытует мнение, что Intel Fortran обладает более мощным оптимизатором.\nПостановка задачи\nНапишем простейшую программу для реализации классического клеточного автомата игры \"Жизнь\". Не будем сейчас париться с вводом и выводом, исходную конфигурацию зададим в самой программе, а результирующую конфигурацию после заданного числа шагов выведем в файл. Нас будут интересовать сами вычислительные шаги клеточного автомата. Эта задача хороша для нас тем, что она позволяет небольшими усилиями достичь любого наперёд заданного объёма чистых (pure) вычислений с массивами произвольных размеров, не вырождаясь в заведомо излишний код, который оптимизатор мог бы выкинуть, обманув наши метрики производительности.\nДля тестов, чтобы далеко не ходить, используется компьютер Mac mini с процессором Intel Core i3 @ 3.6 GHz с 4 физическими ядрами. Компиляторы GNU Fortran 12.2.0 и Intel Classic Fortran 2021.8.0 20221120.\n0. Последовательная программа\nДля начала напишем программу в чисто последовательном стиле. Напишем всё в одном файле, чтобы оптимизатору было легче работать.\nprogram life\n! чисто последовательный вариант программы\n\nimplicit none\n\n! здесь мы задаём количество байтов\n! для каждой ячейки - вдруг операции над\n! целыми словами окажутся эффективными? (нет)\ninteger, parameter :: matrix_kind = 1\n\ninteger, parameter :: generations = 2 ! автомат рассматривает 2 поколения\ninteger, parameter :: rows = 1000, cols = 1000 ! размеры поля\ninteger, parameter :: steps = 10000 ! количество шагов\n\n! описываем игровое поле. значения элементов могут быть целыми 0 или 1\ninteger (kind=matrix_kind) :: field (0:rows+1, 0:cols+1, generations)\n\ninteger :: thisstep = 1, nextstep =2 ! индексы массива для шагов\n! при желании это можно легко обобщить на автомат с памятью больше 1 шага\n\ninteger :: i ! счётчик шагов\ninteger :: clock_cnt1, clock_cnt2, clock_rate ! для работы с таймером\n\n! инициализируем поле на шаге thisstep начальной конфигурацией\ncall init_matrix (field (:, :, thisstep))\n\n! засечём время\ncall system_clock (count=clock_cnt1)\n\n! вызовем процедуру выполнения шага в цикле для заданного числа шагов\ndo i = 1, steps\n  ! тут мы берём сечение массива по thisstep и преобразовываем в nextstep\n  call process_step (field (:, :, thisstep), field (:, :, nextstep))\n  ! следующий шаг становится текущим\n  thisstep = nextstep\n  ! а для следующего шага снова возвращаемся к другому сечению\n  nextstep = 3 - thisstep\nend do\n\n! узнаем новое значение таймера и его частоту\ncall system_clock (count=clock_cnt2, count_rate=clock_rate)\n\n! напечатаем затраченное время и оценку производительности\nprint *, (clock_cnt2-clock_cnt1)/clock_rate, 'сек, ', & \n  int(rows*cols,8)*steps/(clock_cnt2-clock_cnt1)*clock_rate, 'ячеек/с'\n\n! выведем результирующую конфигурацию в файл для контроля\ncall output_matrix (field (:, :, thisstep))\n\n! разместим подпрограммы тут же, чтобы оптимизатору было проще\ncontains\n\n! проинициализируем, просто воткнув одну \"мигалку\" в чистое поле\npure subroutine init_matrix (m)\n  integer (kind=matrix_kind), intent (out) :: m (0:,0:)\n  m = 0\n  m (50, 50) = 1\n  m (50, 51) = 1\n  m (50, 52) = 1\nend subroutine init_matrix\n\n! выведем матрицу в файл при помощи пробелов, звёздочек и грязного хака\nsubroutine output_matrix (m)\n  integer (kind=matrix_kind), intent (in) :: m (0:,0:)\n  integer :: rows, cols\n  integer :: i, j\n  integer :: outfile\n  rows = size (m, dim=1) - 2\n  cols = size (m, dim=2) - 2\n  open (file = 'life.txt', newunit=outfile)\n  do i = 1, rows\n    ! выводим в каждой позиции строки символ, код которого является\n    ! суммой кода пробела и значения ячейки (0 или 1), умноженного\n    ! на разность между звёздочкой и пробелом\n    write (outfile, '(*(A1))') (char (ichar (' ') + &\n      m(i, j)*(ichar ('*') - ichar (' '))), j=1, cols)\n  end do\n  close (outfile)\nend subroutine output_matrix\n\n! здесь самое интересное – обработка шага\n! для начала простой последовательный алгоритм\n\npure subroutine process_step (m1, m2)\n\n  integer (kind=matrix_kind), intent (in) :: m1 (0:,0:)\n  integer (kind=matrix_kind), intent (out) :: m2 (0:,0:)\n  integer :: rows, cols\n  integer :: i, j, s\n\n  ! восстанавливаем значения rows и cols\n  ! конечно, мы могли бы из просто передать в параметрах, но так культурнее\n  rows = size (m1, dim=1) - 2\n  cols = size (m1, dim=2) - 2\n\n  ! обычные последовательные вложенные циклы\n  ! поскольку в Фортране массивы хранятся по столбцам, то j раньше i\n  do j = 1, cols\n    do i = 1, rows\n\n      ! считаем количество живых соседей\n      s = m1 (i-1, j) + m1 (i+1, j) + m1 (i-1, j-1) + m1 (i+1, j-1) + &\n          m1 (i, j-1) + m1 (i-1, j+1) + m1 (i, j+1) + m1 (i+1, j+1)\n\n      ! присваиваем значение выходной клетке \n      select case (s)\n        case (3)\n          m2 (i, j) = 1\n        case (2)\n          m2 (i, j) = m1 (i, j)\n        case default\n          m2 (i, j) = 0\n      end select\n\n    end do\n  end do\n\n  ! закольцуем игровое поле, используя гало в массиве, \n  ! дублирующее крайние элементы с другой стороны массива\n  m2 (0,:) = m2 (rows, :)\n  m2 (rows+1, :) = m2 (1, :)\n  m2 (:, 0) = m2 (:, cols)\n  m2 (:, cols+1) = m2 (:, 1)\n\nend subroutine process_step\n\nend program life\nОткомпилируем нашу программу при помощи GNU Fortran и Intel Fortran:\n$ gfortran life_seq.f90 -o life_seq_g -O3 -ftree-vectorize -fopt-info-vec -flto\n$ ifort life_seq.f90 -o life_seq -Ofast\nЗапустим:\n$ ./life_seq_g\n 11 сек,    125172000 ячеек/с\n$ ./life_seq\n 14 сек,     94120000 ячеек/с\n125 лямов в секунду у GNU Fortran против 94 лямов у Intel Fortran.\nПопробуем запустить автоматический параллелизатор (спасибо\n@AlexTmp8\nза замечание в комментариях):\n$ gfortran life_seq.f90 -o life_seq_g -O3 -ftree-vectorize -fopt-info-vec -flto -floop-parallelize-all -fopenmp\n$ ifort life_seq.f90 ‑o life_seq ‑Ofast ‑parallel\n$ ./life_seq_g\n          11 сек,    124773000 ячеек/с\n$ ./life_seq\n           4 сек,    340690000 ячеек/с\nIntel Fortran очень серьёзно прибавил в производительности, в три с половиной раза. GNU Fortran добавил самую малость. Это единственный из наших тестов, где ifort показал преимущество перед gfortran, причём весьма заметное. \nДавайте, может, попробуем 32-разрядные целые вместо байтов (с автопараллелизатором)?\ninteger, parameter :: matrix_kind = 4\n$ ./life_seq_g\n 10 сек,    131818000 ячеек/с\n$ ./life_seq\n 6 сек,    212080000 ячеек/с\nКак видим, ничего хорошего нам это не дало.\n1. Матричная программа\nНекоторые люди думают, что, если заменить циклы неявными вычислениями с матрицами, то это невероятно оптимизирует код. Посмотрим, так ли это. Поменяем нашу любимую подпрограмму process_step:\n! обработка шага операциями с матрицами\n\npure subroutine process_step (m1, m2)\n  \n  integer (kind=matrix_kind), intent (in) :: m1 (0:,0:)\n  integer (kind=matrix_kind), intent (out) :: m2 (0:,0:)\n  integer :: rows, cols\n  integer s (0:size(m1,dim=1)-1, 0:size (m1,dim=2))\n    \n  rows = size (m1, dim=1) - 2\n  cols = size (m1, dim=2) - 2\n\n  ! вычислим матрицу s, которая повторяет по форме и размерам матрицу m1\n  ! и содержит в каждом элементе количество живых соседей клетки\n\n  s = m1(0:rows-1,:) + m1(2:rows+1,:) + m1(0:rows-1,0:cols-1) + & \n      m1(2:rows+1,0:cols-1) + m1(:,0:cols-1) + m1(0:rows-1,2:cols+1) + &          \n      m1(:,2:cols+1) + m1(2:rows+1,2:cols+1)\n\n  ! завернём края ещё до вычислений\n\n  s (0,:) = s (rows, :)\n  s (rows+1, :) = s (1, :)\n  s (:, 0) = s (:, cols)  \n  s (:, cols+1) = s (:, 1)\n\n  ! и применим оператор матричной обработки where\n\n  where (s==3 .or. s==2 .and. m1 == 1)\n    m2 = 1\n  elsewhere\n    m2 = 0\n  end where\n\nend subroutine process_step\nВернёмся к \nmatrix_kind = 1\n и проверим мощь матричных операторов (с автопараллелизатором):\n$ ./life_mat_g\n \n12 сек,    115730000 ячеек/с\n$ ./life_mat\n \n7 сек,    184630000 ячеек/с\nКак видим, результат чуть-чуть хуже чисто последовательного алгоритма. Причём если выключить автопараллелизатор, то Intel Fortran почему-то сильно расстраивается:\n$ ./life_mat\n  25 сек, 55580000 ячеек/с\nПри этом надо ещё отметить, что Intel Fortran по умолчанию размещает очень мало памяти для стека, и увеличение размеров игрового поля (а вместе с ним и размещаемой на стеке переменной s в матричном варианте) приводит к выпадению программы в кору. GNU Fortran свободно работает при настройках по умолчанию с огромным размером поля.\nС другой стороны, складывается впечатление, что здесь можно серьёзно соптимизировать матричный алгоритм, чтобы не перебирать одни и те же элементы массива трижды при движении по матрице. Возможно, кто-то из читателей предложит своё решение.\n2. SMP параллелизм через OpenMP\nОбе предыдущие программы были чисто последовательными, хотя компиляторы немножко векторизовали операции. Это неинтересно. Давайте извлечём пользу из наличия нескольких ядер в процессоре, причём сделаем это самым простым и грубым способом – через OpenMP:\n! обратите внимание, что подпрограмма, управляющая внутри себя \n! параллелизмом с помощью директив omp, не может быть объявлена чистой,\n! так как это очевидный побочный эффект. декларация pure привела бы\n! к ошибке компиляции\n\nimpure subroutine process_step (m1, m2)\n\n  integer (kind=matrix_kind), intent (in) :: m1 (0:,0:)\n  integer (kind=matrix_kind), intent (out) :: m2 (0:,0:)\n  integer :: rows, cols\n  integer :: i, j, s\n\n  rows = size (m1, dim=1) - 2\n  cols = size (m1, dim=2) - 2\n\n  ! внешний цикл исполняется параллельно на ядрах SMP.\n  ! переменные i и s свои в каждой параллельной ветке кода\n  \n  !$omp parallel do private (i, s)\n  do j = 1, cols\n    do i = 1, rows\n      s = m1 (i-1, j) + m1 (i+1, j) + m1 (i-1, j-1) + m1 (i+1, j-1) + &\n          m1 (i, j-1) + m1 (i-1, j+1) + m1 (i, j+1) + m1 (i+1, j+1)\n      select case (s)\n        case (3)\n          m2 (i, j) = 1\n        case (2)\n          m2 (i, j) = m1 (i, j)\n        case default\n          m2 (i, j) = 0\n      end select\n    end do\n  end do\n !$end parallel do\n    \n  m2 (0,:) = m2 (rows, :)\n  m2 (rows+1, :) = m2 (1, :)\n  m2 (:, 0) = m2 (:, cols)\n  m2 (:, cols+1) = m2 (:, 1)\n          \nend subroutine process_step\nНе забудем подключить OpenMP при компиляции:\n$ gfortran life_omp.f90 -o life_omp_g -O3 -ftree-vectorize -fopt-info-vec -flto -fopenmp\n$ ifort life_omp.f90 -o life_omp -Ofast -qopenmp\nИ запустим:\n$ ./life_omp_g\n 3 сек,    377022000 ячеек/с\n$ ./life_omp\n 3 сек,    356690000 ячеек/с\nТеперь наш цикл выполняется одновременно на 4 ядрах процессора, за счёт чего выполнение ускорилось в 3 с лишним раза. По-прежнему, однако, GNU Fortran чуть впереди Intel Fortran'а.\n3. SMP параллелизм через DO CONCURRENT\nПопробуем переписать нашу программу стандартными средствами параллельного SMP программирования языка Фортран, без использования внешнего API OpenMP:\n! подпрограмма снова может быть чистой, так как она не управляет нитками\n\npure subroutine process_step (m1, m2)\n  \n  integer (kind=matrix_kind), intent (in) :: m1 (0:,0:)\n  integer (kind=matrix_kind), intent (out) :: m2 (0:,0:)\n  integer :: rows, cols\n  integer :: i, j, s\n  \n  rows = size (m1, dim=1) - 2\n  cols = size (m1, dim=2) - 2\n  \n  ! так выглядит параллельный цикл в стандарте Фортрана\n  ! как и в OpenMP,здесь распараллелен только внешний цикл\n\n  do concurrent (j = 1:cols) local (i, s)\n    do i = 1, rows\n\n      s = m1 (i-1, j) + m1 (i+1, j) + m1 (i-1, j-1) + m1 (i+1, j-1) + &\n          m1 (i, j-1) + m1 (i-1, j+1) + m1 (i, j+1)+ m1 (i+1, j+1)\n \n      select case (s)\n        case (3)\n          m2 (i, j) = 1\n       case (2)\n          m2 (i, j) = m1 (i, j)\n        case default   \n          m2 (i, j) = 0\n      end select\n\n    end do\n  end do  \n  \n  m2 (0,:) = m2 (rows, :)\n  m2 (rows+1, :) = m2 (1, :)\n  m2 (:, 0) = m2 (:, cols)\n  m2 (:, cols+1) = m2 (:, 1)\n\nend subroutine process_step\nЗдесь нас ждёт некоторое разочарование, потому что конструкция \nDO CONCURRENT\n в GNU Fortran реализована мало и плохо. Предложение \nLOCAL\n не может быть оттранслировано этим компилятором. И даже если бы мы как-то вывернулись из этого положения, то GNU Fortran всё равно преобразует \nDO CONCURRENT\n в обычный последовательный цикл \nDO\n (в интернете встречаются утверждения, что иногда GNU Fortran способен распараллелить \nDO CONCURRENT\n, но автору не удалось достичь такого эффекта).\nПоэтому трансляцию этого примера мы можем выполнить только в Intel Fortran (обратите внимание, что компилятору всё равно нужна многонитевая библиотека OpenMP для параллелизации, без неё цикл будет откомпилирован в последовательный код):\n$ ifort life_con2.f90 -o life_con -Ofast -qopenmp\nЗапустим:\n$ ./life_con\n 3 сек,    355890000 ячеек/с\nЭтот результат лучше всего, что мы видели в Intel Fortran, хотя немного не дотягивает до результата GNU Fortran с OpenMP.\n4. Больше SMP параллелизма\nСинтаксис оператора \nDO CONCURRENT\n как бы намекает, что мы можем объединить внутренний и внешний циклы в один параллельный цикл по двум параметрам. Посмотрим, что это даст:\n! подпрограмма снова может быть чистой, так как она не управляет нитками \n! объединяем циклы do в общий do concurrent\n\npure subroutine process_step (m1, m2)\n\n  integer (kind=matrix_kind), intent (in) :: m1 (0:,0:)\n  integer (kind=matrix_kind), intent (out) :: m2 (0:,0:)\n  integer :: rows, cols\n  integer :: i, j, s\n  \n  rows = size (m1, dim=1) - 2\n  cols = size (m1, dim=2) - 2\n  \n  ! так выглядит параллельный цикл в стандарте Фортрана\n  ! здесь распараллелен как внешний, так и внутренний цикл\n  ! в единую параллельную конструкцию, параметризованную по j и i\n  do concurrent (j = 1:cols, i = 1:rows) local (s)\n\n    s = m1 (i-1, j) + m1 (i+1, j) + m1 (i-1, j-1) + m1 (i+1, j-1) + &\n        m1 (i, j-1) + m1 (i-1, j+1) + m1 (i, j+1) + m1 (i+1, j+1)\n\n    select case (s)\n      case (3)\n        m2 (i, j) = 1\n      case (2)\n        m2 (i, j) = m1 (i, j)\n      case default\n        m2 (i, j) = 0\n    end select  \n\n  end do\n  \n  m2 (0,:) = m2 (rows, :)\n  m2 (rows+1, :) = m2 (1, :)\n  m2 (:, 0) = m2 (:, cols)\n  m2 (:, cols+1) = m2 (:, 1)\n\nend subroutine process_step\nЧто же это нам даёт?\n$ ./life_con2\n 4 сек,    308920000 ячеек/с\nКомпилятор увлёкся обилием возможностей и ухудшил результат. Так что параллелить всё же надо с умом.\nВывод\nМы рассмотрели компиляцию простейшей программы на современном Фортране с использованием средств векторизации и симметричных параллельных вычислений. В результате тестов Intel Fortran показал преимущество в поддержке возможностей языка и в автопараллелизации последовательного кода, а GNU Fortran – в скорости работы кода с ручным управлением параллелизацией. При этом, однако, не надо забывать, что Intel Fortran поддерживает мощные методы совместной оптимизации раздельно расположенных в исходных файлах единиц компиляции, поэтому для большой программы сравнительный результат мог бы быть другим.\nПолучается, что компилятор Intel Classic Fortran (ifort) более эффективен тогда, когда нам нужно оттранслировать на SMP много унаследованного последовательного кода, автоматически его распараллелив. GNU Fortran же позволяет генерировать более эффективный  код в абсолютном зачёте, но требует для этого некоторой ручной работы по явному указанию параллелизации.\nВ \nследующей статье \nмы рассматриваем средства поддержки массивно-параллельных архитектур, имеющиеся в современном Фортране, и ещё ускоряем нашу программу.\n \n ",
    "tags": [
        "программирование",
        "fortran",
        "фортран",
        "параллелизация",
        "параллельное программирование"
    ]
}