{
    "article_id": "724776",
    "article_name": "Быстрее, больше, сильнее: фреймворки Python с параллельной обработкой данных",
    "content": "Многие разработчики любят Python за простоту и удобство, но вот быстротой обработки данных этот язык программирования никогда не отличался. Во многом эти ограничения скорости связаны с его эталонной реализацией cPython, которая является однопоточной.\nИ хотя в Python есть встроенный модуль потоковой обработки, его использование даст нам только параллелизм. Это не поможет ускорить несколько задач, каждая из которых требует полной загрузки ЦП.\nЕсть у «змеиного языка» и собственный модуль многопроцессорности, который запускает несколько копий интерпретатора Python на отдельных ядрах и предоставляет примитивы для разделения задач между ядрами. Но для по-настоящему сложных задач, например, обработки больших наборов данных в машинном обучении, даже многопроцессорности недостаточно.\nКогда требуется распределить задания не только между несколькими ядрами, но и между несколькими машинами, в игру вступают специальные библиотеки и фреймворки Python, реализующие параллельную обработку данных. Они позволяют взять существующее приложение Python и распределить нагрузку между несколькими ядрами, несколькими машинами или комбинировать оба варианта.\nRay\nФреймворк \nRay\n, разработанный группой исследователей из Калифорнийского университета в Беркли, лежит в основе ряда популярных распределенных библиотек машинного обучения. Но его применение не ограничивается только задачами машинного обучения. С помощью Ray можно разбить и распределить по системам фактически любые задачи для Python.\nСинтаксис Ray минимален, поэтому распараллелить существующие приложения можно без лишних усилий. Декоратор @ray.remote распределяет эту функцию по любым доступным узлам в кластере Ray с необязательными параметрами, указывающими, сколько процессоров, в том числе графических, нужно использовать. \nРезультаты каждой распределенной функции возвращаются в виде объектов Python, поэтому ими легко управлять и хранить, а объем копирования между узлами или внутри них сведен к минимуму. Последнее будет очень полезно, например, при работе с массивами NumPy.\nОсобенности Ray\nПростые в компоновке примитивы фреймворка, а также богатый набор библиотек параллельного и распределенного вычисления позволяют разработчикам быстро масштабировать существующие приложения с помощью правки всего пары строк кода.\nСобственный встроенный диспетчер кластеров может автоматически запускать ноды по мере необходимости на локальном оборудовании или на популярных облачных платформах.\nДецентрализованный механизм планирования — свой планировщик задач работает на каждой машине.\nRay поддерживает десятки интеграций с популярными ML-проектами, такими как Scikit-Learn, FastAPI, XGBoost, PyTorch и TensorFlow, на протяжении всего жизненного цикла машинного обучения, что позволяет выбирать любимую библиотеку для ускорения и масштабирования.\nУнифицированный и масштабируемый набор инструментов для регулирования рабочих нагрузок машинного обучения в таких областях, как распределенное обучение, настройка гиперпараметров, логические выводы и обслуживание в реальном времени.\nВстроенная библиотека Ray Tune для поиска гиперпараметров и дополнительная tune-sklearn для их распределенной настройки.\nВ Ray нет встроенных примитивов для секционированных данных.\nПоддержка GPU ограничена планированием и резервированием.\nОбласть применения\nRay идеально подходит для легкого масштабирования рабочих нагрузок в приложениях на Python и распределенных системах искусственного интеллекта, включая проекты с машинным обучением (ML), глубоким обучением (DL) и обучением с подкреплением (RL).\nDask\nЭто фреймворк для распределенных параллельных вычислений на Python с собственной системой планирования задач и поддержкой основных ML-проектов Python, включая NumPy, scikit-learn, PyTorch, XGBoost, Xarray, Prefect, RAPIDS.\nDask\n работает с параллельной обработкой данных двумя основными способами. Первый — это собственные компактные структуры данных с параллелизацией. По сути, Dask DataFrame создает свои версии массивов и списков NumPy или датафреймов Pandas, выполнение которых можно автоматически распространить по всему кластеру. \nВторой способ — через низкоуровневые механизмы параллелизации, включая декораторы функций, которые распределяют задания по нодам и возвращают результаты синхронно (режим «immediate»), асинхронно (режим «lazy») или в смешанном режиме.\nОсобенности Dask\nDask может работать полностью асинхронно и взаимодействовать с другими приложениями с высокой степенью многопоточности. Хотя изначально фреймворк был построен на корутинах Tornado, в нем реализован уровень совместимости для сопрограмм AsyncIO.\nФреймворк использует централизованный планировщик, который обрабатывает все задачи для кластера.\nDask поддерживает шифрование и безопасную аутентификацию с использованием сертификатов TLS/SSL.\nПродвинутая функция «Actors» (Actor — указатель на определяемый пользователем объект на удаленном воркере) позволяет фреймворку выполнять сложные распределенные вычисления с отслеживанием состояния в рабочем процессе.\nНет встроенной поддержки графического процессора. Для ускорения GPU использует набор библиотек RAPIDS.\nСлабо реализована коммерческая поддержка.\nОбласть применения\nФреймворк окажет незаменимую помощь при создании собственной системы параллельных вычислений с настраиваемой бизнес-логикой.\nBonobo\nЭто легкий и простой в использовании ETL (Extract-Transform-Load) фреймворк Python, который позволяет быстро разворачивать конвейеры и выполнять параллельное выполнение кода. Bonobo поддерживает широкий спектр источников данных, включая CSV, JSON, XML, XLS и SQL. \nПлатформа \nBonobo\n разбивает каждый шаг ETL-конвейеров на объекты Python и связывает их вместе в графах нод. Атомарный дизайн помогает ограничить область применения каждого модуля и повышает удобство тестирования и обслуживания.\nОсобенности Bonobo\nГлавная и самая привлекательная особенность инструмента — максимальная простота использования. Благодаря этому, Bonobo так популярен у начинающих «пайтонистов».\nФреймворк содержит расширение Docker, которое позволяет запускать задания в контейнерах Docker.\nЕсть встроенный интерфейс командной строки (CLI).\nИнтеграция с пакетом Graphviz для визуализации графов заданий ETL.\nРасширение SQLAlchemy добавляет в фреймворк богатые возможности, связанные с базами данных SQL.\nПлагин Jupyter, входящий в основной пакет фреймворка, позволяет интегрировать его в функциональность Jupyter Notebookt.\nГлавное ограничение платформы Bonobo ETL  — неспособность обрабатывать большие наборы данных, что затрудняет ее использование для более крупных проектов.\nОбласть применения\nBonobo подойдет для написания первого ETL-конвейера во время изучения Python и методов ETL. Также фреймворк будет подспорьем для дата-сайентистов и бэкенд-разработчиков, которые хотят упростить работу по созданию конвейеров данных в небольших ETL-проектах на Python.\nHydra\nЭто среда Python с открытым исходным кодом, упрощающая разработку исследовательских и других сложных приложений. Название «Гидра» происходит от ее способности выполнять несколько одинаковых задач — очень похоже на Гидру с несколькими головами.\nКлючевой особенностью \nHydra\n является возможность динамически создавать иерархическую конфигурацию по композиции и переопределять ее через файлы конфигурации и командную строку. Во фреймворке существует несколько встроенных удобных функций, таких как поддержка ведения журнала, заполнение вкладок командной строки, которое позволяет легко узнать, как изменить конфигурацию вашего приложения в командной строке, и автоматическое сохранение моментального снимка конфигурации приложения в каталоге ведения журнала.\nОсобенности Hydra\nИерархическая конфигурация, компонуемая динамически из нескольких источников.\nКонфигурацию можно указать или переопределить из командной строки.\nПодключаемая архитектура позволяет быстро интегрировать фреймворк в имеющуюся инфраструктуру.\nДинамическое завершение вкладок командной строки.\nФреймворк позволяет запускать приложение как локально, так и удаленно.\nЗапуск нескольких заданий с разными аргументами с помощью одной команды.\nДополнительная система ввода для обнаружения неправильных конфигураций.\nОбласть применения\nФункциональность Hydra охватывает разработку параллельных и распределенных систем, а также реализацию как классических, так и распределенных баз данных. Это позволяет эффективно использовать фреймворк для экспериментов с машинным обучением (ML), особенно в случае задач, связанных с глубоким обучением (DL).\nDispy\nС помощью \nDispy\n можно распределять по кластеру для параллельного выполнения как целые программы на Python, так и их отдельные функции. Фреймворк использует для сетевого взаимодействия многочисленные нативные инструменты, что позволяет работать одинаково быстро и эффективно на машинах с разными операционными системами — Linux, MacOS, Windows.\nСинтаксис Dispy во многом напоминает устройство многопроцессорного приложения,  только здесь, вместо пула процессов, создается кластер, который обрабатывает задания и возвращает результаты. Работу кластера Dispy можно гибко настраивать и четко контролировать. Например, можно возвращать предварительные или частично завершенные результаты, передавать файлы в рамках процесса распределения заданий и использовать SSL шифрование для безопасной передачи данных.\nОсобенности Dispy\nИнструмент создан на основе \npycos\n — независимого фреймворка для асинхронного, параллельного, распределенного сетевого программирования.\nПоддерживается устранение сбоев на фронтеде и на бэкенде.\nВычисления (функции Python или автономные программы) и их зависимости (файлы, функции Python, классы, модули) распределяются по кластеру автоматически.\nВычислительные узлы могут находиться где угодно в сети — локально или удаленно. В целях безопасности можно использовать либо простую аутентификацию на основе хэша, либо SSL шифрование.\nВозможность использовать динамическую доступность узлов — Dispy будет назначать в планировщике задания всякий раз, когда узел будет доступен для вычислений.\nОбласть применения\nDispy хорошо подходит для создания и использования вычислительных кластеров, основанных на архитектурной концепции параллелизма на уровне данных (SIMD).\nPandaral·lel\nPandas — это быстрый, мощный, гибкий и простой в использовании инструмент для анализа и обработки данных с открытым исходным кодом, созданный на основе языка программирования Python. Основным его недостатком является тот факт, что фреймворк использует только одно ядро компьютера, даже если доступно несколько. \nPandaral·lel\n, как следует из названия, — это инструмент, позволяющий параллельно выполнять задания Pandas на нескольких нодах, используя для их запуска несколько ядер на одном компьютере.\nОсновные операционные системы для фреймворка — MacOS и Linux. Хотя Pandaral·lel совместим и с Windows, он будет работать только из сеансов Python, запущенных в подсистеме Windows для Linux. \nОсобенности Pandaral·lel \nДля параллелизации Pandas достаточно изменить одну строчку кода.\nПрогресс каждого процесса отображается визуально с помощью индикаторной шкалы. \nИспользование Pandaral·lel для параллелизации позволяет ускорить выполнение процессов Pandas в 4 раза, по сравнению со стандартными операциями.\nК недостатку инструмента можно отнести вдвое большее потребление оперативной памяти, по сравнению с обычным Pandas.\nОбласть применения\nЭтот простой и эффективный инструмент подходит для параллельной обработки операций Pandas на всех доступных процессорах.\nIpyparallel\nIpyparallel\n (IPython Parallel) — это узкоспециализированная система многопроцессорной обработки и распределения задач, предназначенная для распараллеливания выполнения кода Jupyter Notebook в кластере. Проекты и команды, уже работающие в Jupyter, могут сразу использовать Ipyparallel.\nIpyparallel поддерживает множество подходов к распараллеливанию кода. Самый простой вариант — команда map, которая применяет выбранную функцию к каждому элементу в последовательности и равномерно распределяет задачу по доступным узлам. Для более сложных задач можно настроить отдельные функции так, чтобы они всегда выполнялись удаленно или параллельно.\nОсобенности Ipyparallel\nНачиная с версии 4.0 фреймворк представляет собой отдельный пакет под названием «ipyparallel», а с версии 7 — устанавливаемое/подключаемое расширение для классического Jupyter Notebook и JupyterLab ≥ 3.0.\nПодключить IPython Parallel в Jupyter Notebook можно на вкладке «IPython Clusters» на панели инструментов.\nС помощью установки дополнительного модуля Python библиотеки \nmpi4py\n на Ipyparallel можно запускать код стандарта MPI (Message Passing Interface).\nУ Ipyparallel есть ряд собственных «магических команд», поддерживаемых Jupyter Notebook. Например, перед любым оператором Python можно вставить префикс %px, чтобы автоматически распараллелить команду на весь кластер.\nОбласть применения\nФреймворк предназначен для управления кластерами параллельных процессов IPython, построенных на протоколе Jupyter.\nJoblib\nJoblib\n нацелен на повышение эффективности и решает две основные задачи — параллельное выполнение заданий и устранение ненужных повторных вычислений. Это делает Joblib подходящим для научных экспериментов, где воспроизводимость результатов являются абсолютно необходимым условием.\nСинтаксис Joblib для распараллеливания достаточно прост — он представляет собой декоратор, который можно использовать для разделения заданий между процессорами или для кэширования результатов. Параллельные задания могут использовать потоки или процессы.\nФункциональность Joblib включает хорошо оптимизированный кэш для обработки больших объектов Python, созданных вычислительными заданиями. Это не только помогает избежать повторных вычислений, но также позволяет приостанавливать и возобновлять длительные задания или восстанавливать выполнение задания после сбоя. \nОсобенности Joblib\nПрозрачное и быстрое кэширование выходного значения на диске.\nВспомогательный класс joblib.Parallel сильно упрощает написание параллельных циклов for с использованием многопроцессорной обработки.\nВстроенные методы joblib.dump и joblib.load (аналог формата сериализации объектов pickle) повышают эффективность работы с произвольными объектами Python, содержащими большие данные, в частности с большими массивами NumPy.\nОбласти данных в кэше могут совместно использоваться несколькими процессами в одной системе с помощью метода numpy.memmap.\nОтслеживание потока данных и промежуточных вычислений обеспечивает стабильную воспроизводимость вычислительного эксперимента.\nХорошая документированность с множеством практических примеров использования функций.\nК недостаткам фреймворка относится отсутствие способа распределения заданий между несколькими отдельными компьютерами. \nОбласть применения\nJoblib — набор инструментов для упрощения конвейерной обработки данных в Python. \nФреймворк дает легкий способ добиться повышения производительности и воспроизводимости результатов при работе с большими данными и крупными объемами вычислений в таких областях, как научные исследования.\nPygrametl\nЭтот опенсорсный фреймворк Python, выпущенный под лицензией BSD, который предоставляет универсальный набор функций для разработки приложений ETL (Extract-Transform-Load).\nPygrametl\n содержит несколько классов для заполнения таблиц фактов и измерений (включая таблицы типа Snowflake и SCD), а также классы для извлечения данных из разных источников, классы для опционального определения потока ETL с помощью шагов, классы для распараллеливания и тестирования потоков ETL.\nОсобенности Pygrametl\nPygrametl предлагает новый подход к ETL-разработке, предоставляя структуру, которая абстрагирует доступ к базовым таблицам DW (data warehouse) и позволяет разработчику использовать всю мощь языка Python.\nФреймворк поддерживает как CPython, так и Jython, поэтому в созданной с его помощью ETL-программе можно использовать существующий код Java и драйверы JDBC.\nPygrametl поддерживает выполнение параллельных потоков ETL с использованием CPython только на платформах, которые запускают новые процессы с помощью системного вызова fork(). В CPython способ запуска процесса можно определить с помощью метода multiprocessing.get_start_method(). В Unix-подобных ОС fork() обычно используется по умолчанию или определяется тем же методом.\nВ архитектуре Pygrametl реализована прямая поддержка схем типа Snowflake, SCD (Медленно изменяющихся измерений) и других специализированных функций DW.\nОбласть применения\nPygrametl широко используется в производственных вычислительных системах для таких секторов экономики, как здравоохранение, финансы и транспорт. \nApache Airflow\nЭто фреймворк Python с открытым исходным кодом, который позволяет создавать, планировать и отслеживать параллельно выполняемые рабочие процессы. \nAirflow\n можно использовать для создания проекта ETL или других типов конвейера данных.\nФреймворк основан на концепции направленного или ориентированного ациклического графа — DAG (Directed Acyclic Graph), которая позволяет запускать процессы параллельно, связывая несколько скриптов Python в граф зависимостей.\nОсобенности Apache Airflow\nВсе рабочие процессы в Airflow определены в чистом коде Python. \nДля создания рабочих процессов можно использовать стандартные функции Python, включая форматы даты и времени для планирования и циклы для динамического создания задач.\nИнтерактивный пользовательский интерфейс облегчает отслеживание заданий, визуализируя зависимости, сбои и успешные выполнения рабочих процессов.\nApache Airflow не ограничивает объем конвейеров. Его можно использовать для создания моделей машинного обучения, передачи данных, управления инфраструктурой и многого другого.\nК недостаткам Airflow можно отнести отсутствие версий конвейеров данных. Невозможно повторно развернуть удаленную задачу или DAG. Более того, фреймворк не сохраняет метаданные для удаленных заданий, поэтому отладка и управление данными особенно сложны.\nОбласть применения\nПлатформа Apache Airflow отлично подойдет для команды дата-сайентистов, желающих лучше контролировать оркестровку пакетных рабочих процессов в Python приложениях с помощью написанных вручную сценариев.\nЗаключение\nОбласть применения фреймворков Python с параллельной обработкой данных простирается от теоретических научных изысканий дата-сайенс до практических производственных задач в разных областях экономики. Везде, где нужно соединить удобство использования «змеиного языка» с повышенной производительностью, на помощь приходят многочисленные дополнительные фреймворки и библиотеки, как узкоспециализированные, так и универсальные. \nВыбор подобных фреймворков Python достаточно велик, поэтому в этом обзоре мы привели лишь несколько наиболее ярких примеров таких технологических решений. Наверняка каждый читатель из активно практикующих питонистов сможет дополнить список своим излюбленным инструментом.\n \n ",
    "tags": [
        "python",
        "фреймфорк",
        "паралеллизм",
        "производительность приложений",
        "пайтон"
    ]
}