{
    "article_id": "728404",
    "article_name": "ChatGPT с руками и другие итоги сезона Machine Learning",
    "content": " \nДавным-давно, в далёкой-далёкой галактике \n1 марта Хабр объявил начало сезона «Машинное обучение», и вот настало время подводить итоги. За чтением хардкорных конкурсных текстов месяц пролетел незаметно. Мы узнали много интересного о нейросетях и неочевидных способах взаимодействия с ними, пополнили свою коллекцию туториалов и в очередной раз убедились в актуальности темы Machine Learning для читателей Хабра.\nМы не получили ответ на главный вопрос Вселенной, жизни и всего такого, но зато нам известен лучший автор сезона ML. Впрочем, у него были достойные соперники, их тексты привлекли много внимания и породили холивары в комментариях. Под катом наградим победителя новым макбуком, познакомимся с участниками сезона, пофлудим о Machine Learning и обсудим перспективы этого направления. \nПодводим итоги сезона\nНапомним, что сезон прошёл на хабе «Машинное обучение», который мы ведём совместно с ВТБ. За 6 лет существования хаба здесь опубликовали более 5000 статей, 70 из них имеют рейтинг 100+. Рейтинг самого хаба стремится к 900 (893,21). Некоторые тексты были прочитаны 300 тысяч раз и более. \nПока количество просмотров у публикаций участников сезона несколько скромнее, но всё ещё впереди. Тем более что это отборный хардкор, который априори не может привлечь аудиторию в таком же объёме, как научпоп. \nУчастники, их статьи и вся статистика — под катом. Знакомимся, изучаем — или сохраняем интригу и пропускаем спойлер.\nПод катом таблица со всеми текстами — участниками сезона Machine Learning. Не смотрите в неё, если не хотите заспойлерить себе победившую статью:\nТекст\nавтор\nпросмотры\nрейтинг\nПриделываем руки к ChatGPT: бот, который исполняет код в рантайме\nRai220\n16644\n54\nКак воспитать GPT модель в домашних условиях [LLaMA Update]\nneoflex\n14677\n43\n10 первых ошибок в карьере ML-инженера\nkarpovcourses\n14314\n39\nКак я делаю OCR\nSmallDonkey\n6878\n37\nОтгадай слово: как мы создали игру с элементами машинного обучения и вышли в ноль за 2 месяца\nEgorovM\n6571\n33\nПора забывать GridSearch — встречайте ProgressiveGridSearch. Фракталы в ML, постепенно увеличиваем разрешение\nnstrek\n5050\n31\nКак мы нейросеть в браузер тащили\nDmitriyValetov\n6069\n31\nNeural Network Optimization: океан в капле\nlenant\n4620\n28\nПодробно рассматриваем обратное распространение ошибки для простой нейронной сети. Численный пример\nArs_magna_1308\n3736\n21\nprogressive_plots или ускоряем построение графиков\nnstrek\n1893\n19\nTrue RND или что делать с обученной моделью (опыт чайника)\nykx3hr\n3410\n19\nДиффузионная нейросеть ModelScope text2video 1.7B — создаём видео по текстовому описанию у себя дома\nkabachuha\n7597\n18\nChatGPT: новый инструмент в борьбе с багами. Как можно использовать AI для повышения качества тестирования\nobojealexander\n21839\n18\nML-подходы по поиску похожих изображений\nNewTechAudit\n1762\n16\nКак мы подружили ML и биореакторы\nBIOCAD\n1905\n16\nПервая бесплатная модель перевода с русского на китайский язык и обратно\nUtrobinMV\n3734\n15\nРазработка кросплатформенного приложения на Qt с использованием нейросетей, обученных на tensorflow\nKapping\n5866\n14\nРасчет транспортного потока на основе YOLOv5 и DeepSORT на базе Deepstream\nCodeInsideTeam\n1921\n12\nКак спрогнозировать спрос на самокаты и не захламить город, версия Whoosh\navanmw\n3735\n12\nКак я делаю OCR — Часть 2\nSmallDonkey\n3037\n11\nВсе, что вы хотели знать о задаче определения остаточного ресурса оборудования\nKatser\n3258\n11\nРаспознавание подачи в волейболе с помощью машинного обучения\nStantin\n2058\n10\nОбучение VAE и нижняя вариационная граница\nIvanRodkin\n1497\n10\nУчим нейросеть принимать решения на основе уже известного опыта (на примере Шахмат и загруженного датасета)\nAnatolyBelov\n2744\n10\nYOLOv7 для определения поз людей на видео\nNewTechAudit\n2303\n9\nПрости нас, Джон Коннор, или Как мы научили нейросеть точечно распознавать звуки выстрелов\nlenant\n2550\n9\nNORUAS — домашний Саурон, но это не точно…\nkylikovskix\n2765\n8\nAIGod — распознавание объектов\nkrolaper\n2441\n7\nКак мы улучшаем выделение интентов в наших продуктах\nmurat_apishev\n864\n7\nHalvingSearch: ускорение поиска по сетке (grid search). Библиотека sklearn\nMind08\n1825\n7\nКак решать реальные задачи при помощи ChatGPT\nFriflex_dev\n11054\n6\nПайплайн для создания классификации текстовой информации\nNewTechAudit\n2726\n5\nСнова о распознавании рукописного текста, на этот раз с помощью CRNN\nCyberLympha\n1440\n5\nАнализ подбора гиперпараметров при обучении нейронной сети прямого распространения — FNN (на примере MNIST)\nAnatolyBelov\n1401\n4\nПоиск ошибок в логике работы чат-бота с помощью TF-IDF и DBSCAN\nNewTechAudit\n960\n3\nОбработка естественного языка (NLP). Личный опыт — мой первый запуск BERT\nAnatolyBelov\n2131\n3\nАвтоматический подбор гиперпараметров и архитектур нейронных сетей. Часть 1\nAnatolyBelov\n1862\n2\nВ этом сезоне, как и ожидалось, мы получили большое количество статей, так или иначе связанных с ChatGPT — от использования чата для повышения качества тестирования до особенностей распознавания с его помощью спортивных событий. Намекнём и на то, что текст-победитель также связан с этой хайповой темой.\nОднако не чатом единым: в результате усилий конкурсантов коллекция нашего хаба пополнилась текстами на темы фракталов в ML, подходов по поиску похожих изображений, расчёта транспортного потока на основе YOLOv5 и DeepSORT, подбора гиперпараметров и архитектур нейронных сетей.\nОбожаемый нами отборный технохардкор приятно разбавляли публикации вроде «10 ошибок в карьере ML-инженера». В общем, всё было так, как мы любим. За это мы благодарим авторов и предоставляем им слово.\nСлово участникам сезона\nЗачем писать о Machine Learning, что интересного в этой теме \nМне нравятся сложные задачи и автоматизация. Возможно, что в мире есть задачи, которые могут решить всего несколько человек. Или только один. Именно такие задачи и привлекают.\nMachine Learning — объединение математики и программирования, при котором теоретическая математика и практические вычисления органично дополняют друг друга. Некоторые вопросы, которые довольно затруднительно решаются на уровне теории и формул, могут быть решены достаточно оперативно перебором вариантов и мощными параллельными вычислениями. Возможно, подобное решение формально не будет считаться теоретически обоснованным, но будет реально работать на практике. И наоборот, понимание теории происходящих процессов, таких как, например, градиентный спуск и соответствующая оптимизация, может направить вычислительную мощь в правильное русло. В результате сокращённые и оптимизированные вычисления приведут к решению поставленной задачи.\nНаписание статьи помогает структурировать мысли. По мере написания и проверки вылезают белые пятна. Предполагая критику, неоднократно проверишь, уменьшишь количество ошибок, переформулируешь. А получая комментарии, видишь слабые места, смотришь на ситуацию совершенно другим взглядом. Это сильно прокачивает навыки в той сфере, которой занимаешься.\nВозможно, статья какой-то фразой, предположением, выводом дополнит чей-то пазл и поспособствует решению поставленной задачи. Возможно, чей-то комментарий к статье дополнит мой пазл или чей-то ещё. В любом случае очередная сложная задача, превращающая искусственный интеллект в приятного и полезного помощника, будет решена. Вот почему я пишу на тему Machine Learning.\nАнатолий Белов\nака \n@AnatolyBelov\nКакие области применения машинного обучения наиболее интересны  \nПримеров использования ML с явными эффектами для бизнеса в фармацевтическом производстве множество: выявление отклонений и поиск их корневых причин, видеоаналитика для контроля процессов и персонала, компьютерное зрение для замены ручных операций в лабораториях и на производственных линиях, создание цифровых двойников для сокращения времени на эксперименты и определения оптимальных условий производства биологических препаратов, предиктивное техническое обслуживание оборудования. Всё это — вместе и по отдельности — помогает нам не только оптимизировать и ускорить рабочие процессы, но и увеличить эффективность без потери качества.\nДля нас в BIOCAD это важно, потому что таким образом мы можем повысить доступность инновационной терапии, в которой нуждаются пациенты.\nВасилий Вологдин\nруководитель направления мониторинга и анализа данных информационных систем BIOCAD, спикер \nблога компании\nКакие метрики качества модели машинного обучения наиболее важны \nСоветую как можно раньше пробовать работать руками, набивать свои первые шишки. Учиться можно бесконечно долго: всегда будут курсы, которые вы ещё не прошли, темы, которые не изучили, фреймворки, с которыми не подружились.\nВ каждом из вас будет оставаться то же ощущение страха перед практикой, как на берегу перед первым нырком. Да, холодно. Да, неприятно. Однако чтобы научиться плавать, нужно плавать. Теория — как учебники по плаванию за спиной тонущего.\nОтправьте своё первое решение в текущем соревновании на Kaggle, хотя бы подходящее по формату. Запишитесь на ближайший хакатон и пробейтесь в любую команду, в какую возьмут. Попросите ChatGPT придумать идею для вашего первого pet-проекта — и ему же задавайте вопросы на каждом шагу, на котором будете спотыкаться.\nYou don't have to be great to start. But you have to start to be great\nИван Маричев\nака \n@avanmw\n, \nдата‑сайентист \nWhoosh\nЭто зависит от задачи конкретной машинной модели: регрессивной, классификационной, прогнозирующей, CV и т. д. Важна и структура данных, на которых модель будет обучаться: категории — классы, дискретные числа, неструктурированные типы данных (изображения/тексты). Для задач классификации основные метрики — матрица запутанности и производные, рассчитывающиеся на её основе — Accuracy/Precision/Recall/F-score, для регрессии — R2, RMSE, MAE MAPE.\nНапример, в нашей последней \nисследовательской работе по созданию модели спроса поездок\n для определения качества модели используется преимущественно RMSE и R2 (который в свою очередь объясняет изменчивость спроса за счёт независимых переменных-регрессоров, в нашем случае — погодными метриками). MAPE в данной ситуации не подходит в связи с нерегулярностью спроса на кикшеринг, так как сравнение нуля и дискретного числа равна inf.\nЧто можно посоветовать начинающим в машинном обучении \nkarpov.courses\nШкола \nData Science\nСделайте частью своего досуга просмотр выступлений, лекций и блогов специалистов — находите спикеров/авторов, которые вам нравятся, и следите за выходом их материалов. Если быть внимательным к себе, должно получиться естественное и приятное времяпровождение.\nВсегда пытайтесь заглянуть глубже, чем дано в каком-либо описании метода. Пытайтесь понять, почему сделано так, а не иначе. Какие преимущества у того, что есть, а какие недостатки. Ведите записи — записывайте свои мысли, идеи, выкладки. Хоть на листочках разрозненных, хоть в специальном софте — но записывайте.\nСледует избегать соблазна найти тёплое место и остановиться в нём в развитии. Эта стратегия гарантирует отложенный кризис. Лучше маленький шаг, но каждый день, чем большими шагами быстро дойти, но поломать себя и лёжа ждать урагана. Маленькие, но регулярные вложения дадут неожиданно большой эффект со временем. Делайте в своё удовольствие и по силам.\nНиколай Стрекопытов\nака \n@nstrek\n, Deep Learning Researcher and Developer \nБудущее машинного обучения: какие технологии в этой области могут появиться в ближайшее время \nНа наших глазах машинное обучение меняет профессию аудитора. Если раньше анализ бизнес-процессов компании занимал много времени и сил, то сегодня аудиторы больше времени могут уделять поиску возможностей улучшения работы компании, а для решения рутинных задач использовать инструменты из арсенала ML.\nВ прошлом — начале этого года в развитии машинного обучения произошёл прорыв, от успехов в обработке естественного языка и компьютерном зрении до новых сфер внедрения машинного обучения в продукты компаний. Стандартное программное обеспечение и устройства, которые компании и рядовые потребители используют ежедневно, становятся умнее — и будут становиться ещё умнее с внедрением технологий ИИ. Одновременно с этим приложения, изначально построенные вокруг машинного обучения, будут укреплять свои позиции и продолжат стирать границы между реальностью и научной фантастикой.\nЕсли говорить об отдельных трендах и технологиях, во-первых, продолжится дальнейшая специализация направлений, таких как NLP, CV, мультимодальные модели и т. д., а также появятся новые направления. Во-вторых, дальнейшее развитие получит prompt engineering: появятся новые подходы, prompt-технологии, имитирующие ход мыслей человека. В-третьих, вероятно, в ближайшее время будет наблюдаться дефицит тестовых данных для обучения больших языковых моделей — следовательно, может возникнуть потребность в инструментах аугментации текстовых данных. Но рост моделей будет продолжаться, так как уже обнаружен так называемый emergent ability больших моделей. И последнее: инструменты сжатия нейронных сетей скорее всего продолжат своё развитие.\nNewTechAudit\nПрофессиональное сообщество\nУра победителю сезона!\nВот и он —  \n@Rai220\n победитель нашего ML-сезона, заслуженный обладатель Apple MacBook Air 13 и достойный получатель гранта на 30 000 рублей для подготовки следующей классной статьи.\nЛавры победителя присвоены автору хабрасообществом за \nприделывание рук к ChatGPT\n: в статье подробно описывается бот, который исполняет код в рантайме. Статья, в которой помимо прочего описываются проявления нейросетью способности к метапознанию, набрала 16 тысяч просмотров, 53 плюсика и более сотни комментариев.\nСлово победителю\nНаше блиц-интервью тоже посвятили ChatGPT: как автор познакомился с чатом, как родилась идея конкурсной статьи, о перспективах развития технологии и бесперспективности искусственных попыток ограничить развитие искусственного интеллекта.\nЯ уже несколько лет активно использую продукты \nOpen.ai\n в повседневной работе и для pet-проектов. Первые проблески того, что это не «просто статистика», заметил ещё в GPT-2, но тогда это сложно было продемонстрировать. С появлением ChatGPT я стал уделять работе с ней практически всё свободное время, и вот захотелось поделиться одним из экспериментов с читателями Хабра.\nСама идея заставить бота писать код и сразу его выполнять, по-видимому, лежала на поверхности, так как через несколько дней после выхода статьи \nOpen.ai\n показал точно такое же решение в виде одного из плагинов.\nНикто не знает, что произойдёт дальше. Мы стали свидетелями фазового перехода, когда рост размера сетей вдруг привёл к появлению у них совершенно новых свойств и способностей, которые никто не ожидал, в том числе и сами разработчики. Думаю, никто сегодня не сможет предсказать, ждут ли нас в будущем подобные скачки способностей. Скептики вроде Яна Лекуна не предсказывали тех результатов LLM, которые мы наблюдаем сейчас, так что делать большую ставку на то, что они не ошибутся снова, я бы не стал.\nЧто касается ограничения развития сетей — по-моему, это бесполезно. Всегда найдутся те, кто будет продолжать разработку и эксперименты.\nДумаю, люди будущего назовут 2023-й годом начала технологической сингулярности. Мой прогноз: ChatGPT и им подобные очень быстро проникнут почти во все области деятельности, ведь это практически универсальный инструмент для работы с языком, а язык используется абсолютно везде.\nКонстантин Крестников\nAI RnD и автор канала \nRoboFuture\nВыводы\nСезон завершился, призы раздали, ответ на главный вопрос Вселенной, жизни и всего такого — продолжим искать на хабе. Обязательно пишите, если есть мысли по этому и другим вопросам, связанным с машинным обучением, — в виде комментариев или статью на хаб ML. Сезон подтвердил, что интерес к этой теме есть и будет, так что ждём ваших крутых публикаций.\nА если вы хотите узнать о машинном обучении больше, пообщаться с экспертами — 13-14 апреля приглашаем на конференцию ВТБ по машинному обучению, анализу данных и технологиям ИИ Data Fusion, которую проводит ВТБ. Онлайн-трансляция всех стримов мероприятия будет вестись на \nсайте\n конференции.  \n \n \n \n ",
    "tags": [
        "сезон machine learning",
        "итоги"
    ]
}