{
    "article_id": "728812",
    "article_name": "AI-focused digest: ИИ для удаления шумов с космических фото, генерация изображений на основе фМРТ мозга",
    "content": "Всем привет! \nВ апрельском выпуске AI-focused digest мы расскажем, как можно сократить затраты на обучение больших ML-моделей, как японские ученые научили нейросеть генерировать изображения по фМРТ мозга. Также поговорим о новом CV-алгоритме для улучшения астрономических фото. В заключении порекомендуем исследовательскую статью, которая поможет лучше понять, чего ждать от стремительного развития языковых моделей. \nТочность классификации нейросети можно повысить с помощью нестандартных функций активации \nНейронные сети можно спроектировать так, чтобы уменьшить вероятность неправильной классификации входных данных. К такому выводу пришли ученые из MIT в результате исследования бесконечно широких (количество нейронов в слое) и бесконечно глубоких (количество слоев) нейронных сетей, обученных выполнять задачи классификации. Исследователи обнаружили, что в определенных случаях стандартные функции активации, которые часто используются разработчиками при обучении моделей на практике,— не лучший выбор при увеличении глубины сети. В статье, опубликованной на днях в журнале Proceedings of the National Academy of Sciences, ученые рассказывают, как правильный подбор функций активации помогает разработчикам спроектировать сети, точнее классифицирующие данные. Утверждается, что наиболее эффективными могут быть функции, которые раньше никто не использовал в отличие от ReLU или сигмоида, но они при этом достаточно простые и легки в реализации. Еще один эффект этой работы ученых в том, что она подтверждает важность теоретических доказательств. «Если вы стремитесь к принципиальному пониманию этих моделей, это может фактически привести вас к новым функциям активации, о которых вы никогда бы не подумали», — цитирует сайт MIT News Каролин Улер (Caroline Uhler), соавтора научной статьи. Доступно об исследовании в прямом смысле на кошках и собаках рассказано в\n \nэтой публикации\n на новостном портале института, а научно —\n \nздесь\n.\nВ Японии научили ИИ генерировать изображения на основе фМРТ мозга \nУченые из Университета Осаки в Японии научили нейросеть Stable Diffusion генерировать изображения не только на основе текстового описания, но и руководствуясь записями фМРТ мозга. Для этого потребовалась значительная база записей фМРТ — участникам сканировали мозг в то время, как они просматривали тысячи фотографий разной тематики. Затем текстовые описания этих фотографий были связаны со сканами мозга, сделанными во время их просмотра, и проведено дообучение модели. Как и насколько хорошо нейросеть справляется с задачей, можно узнать в этом\n препринте\n, а подискутировать о вреде и пользе этой технологии — в любой соцсети. Там идут горячие споры по этой теме. \nУченые разработали CV-решение для более точных астрономических изображений \nИсследователи из Северо-Западного университета (США) и Университета Цинхуа (Китай) адаптировали алгоритм компьютерного зрения, повышающий резкость фотографий, для улучшения астрономических изображений с телескопов. Потребовалось это не потому, что ученые хотели получить красивые картинки космоса. Дело в том, что изображения даже с самых лучших наземных телескопов размыты из-за атмосферы Земли, и эти искажения могут привести к ошибкам в измерениях астрономических объектов. Например, атмосферное размытие может исказить форму галактик. Новое решение аккуратно удаляет атмосферные размытия и и делает это быстрее и точнее, чем использующиеся в настоящее время инструменты для этих целей. В качестве обучающего материала выступили безатмосферные снимки космоса с телескопа Хаббл, к которым впоследствии добавлялось атмосферное размытие. ИИ-инструмент изначально создавался, чтобы соответствовать параметрам телескопа Обсерватории им. Веры Рубин, полномасштабный запуск которой ожидается в следующем году.  Дополнительно о проекте можно почитать на портале \nInnovation News Network\n, а код, гайды и результаты тестирования решения выложены на\n GitHub\n.\nЧто важно знать о больших языковых моделях \nДля наилучшего понимания технологии LLM рекомендуем прочитать статью профессора из Университета Нью-Йорка Сэмюэла Боумана (Samuel R. Bowman) «Eight Things to Know about Large Language Models». В ней он приводит восемь более или менее принятых в профессиональном сообществе утверждений о больших языковых моделях и обосновывает их, базируясь на ранее опубликованных научных работах и высказываниях исследователей ИИ. Вот эти утверждения:\nLLM предсказуемо становятся более способными с ростом инвестиций, даже без целенаправленных инноваций.\nМногие важные модели поведения в LLM появляются неожиданно как побочный продукт роста инвестиций.\nLLM часто изучают и используют представления о внешнем мире.\nНе существует надежных методов для управления поведением LLM.\nЭксперты пока не могут интерпретировать внутреннюю работу LLM.\nСпособность выполнять задачи на уровне человека не предел способностей LLM.\nЦенности, выраженные в LLM, не обязательно должны  отражать ценности своих создателей или ценности, закодированные в веб-тексте.\nКратковременные взаимодействия с LLM часто вводят в заблуждение.\nА еще многие найдут весьма любопытной дискуссионную часть этой статьи Боумана. Спойлерить не будем — читайте статью по этой\n ссылке\n.\n \n ",
    "tags": [
        "компьютерное зрение",
        "большие языковые модели",
        "искусственный интеллект",
        "машинное обучение",
        "исследования в ит"
    ]
}