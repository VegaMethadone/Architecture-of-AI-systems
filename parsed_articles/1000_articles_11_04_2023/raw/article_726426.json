{
    "article_id": "726426",
    "article_name": "GRE + IPSec чтобы слушать multicast в облаке",
    "content": "Несмотря на обилие статей про IPsec на linux, каждый раз, когда мне нужно было слушать multicast на виртуальной машине в облаке (на примере AWS), который нужно было там получать через IPSec тоннель, я, сталкиваясь с какими-то проблемами в настройке, жалел, что не сделал никаких заметок в прошлый раз. В этот раз я решил записать пример конфигурации с небольшими пояснениями и поделиться им с общественностью, в надежде, что это кому-то может быть полезным.\nИтак, обычно перед началом конфигурации вы должны договориться с другой стороной (в этой статье это будет условный \nDataCenter\n) о конфигурации IKE (фаза1) и IPSec (фаза2), в частности, согласовать PSK (pre-shared key) фразу, способы и алгоритмы аутентификации и шифрования, используется ли PFS (perfect forward secrecy), ваши публичные IP адреса (peer VPN gateway), ваши локальные подсети, которые вы связываете (interesting traffic), а также адресацию для GRE тоннеля. Обычно это делается совместным заполнением таблички, которую вы пересылаете по почте, в итоге собирается табличка такого вида:\nсборная табличка утвержденных параметров (все адреса вымышлены)\nДальнейшая конфигурация будет производиться на AWS виртуальной машине с \nUbuntu 20.04.3 LTS\n и \nLinux strongSwan U5.8.2/K5.13.0-1028-aws\n.\nКонфигурация \nipsec.conf\n:\nipsec.conf с комментариями\nДля того, чтобы жестко закрепить только один профиль безопасности (аутентификации и шифрования) phase1 или phase2, стоит указать восклицательный знак (\n!\n) после строки с заданной конфигурацией, например так:\nike=aes256-sha256-modp2048! # параметры аутентификации и шифрования IKE     esp=aes256-sha256-modp2048! # параметры аутентификации и шифрования ESP \nДля включения возможности маршрутизировать ipv4 трафик, необходимо включить:\nsysctl net.ipv4.ip_forward=1\nНеобходимо также настроить iptables, чтобы весь трафик (interesting traffic) к DataCenter Remote Address (\n100.15.30.0/24\n) выходил с source IP \n10.45.8.17\n и , как следствие, упаковывался в IPSec туннель службой strongswan:\n \niptables -t nat -A POSTROUTING -d 100.15.30.0/24 -j SNAT --to-source 10.45.8.17\nТакже, чтобы весь трафик к лупбэку GRE Tunnel source DataCenter (\n10.44.7.1\n) выходил с source IP \n10.44.6.1\n:\niptables -t nat -A POSTROUTING -d 10.44.7.1/32 -j SNAT --to-source 10.44.6.1\nДля перезапуска strongswan используйте команду \nipsec restart\n.\nТеперь создадим GRE туннель c MTU 1476 и лупбэк:\n ip tunnel add gre1 local 10.44.6.1 remote 10.44.7.1 mode gre ttl 255\n ip link set gre1 up\n ip addr add 10.44.4.6/30 dev gre1\n ip link set dev gre1 mtu 1476\n ip link set gre1 multicast on\n // должно быть по умолчанию включено, но пусть будет\n ifconfig gre1 pointopoint 10.44.4.5\nСхема GRE тоннеля\nДля того, чтобы linux мог отвечать на \nGRE keepalive\n, нужно либо разрешить следующие параметры:\nsysctl net.ipv4.conf.default.accept_local=1\nsysctl net.ipv4.conf.all.accept_local=1\nЛибо воспользоваться \nболее безопасным reply-only решением\n для ответа на GRE keepalive.\nВ результате, мы должны видеть на локальном сетевом интерфейсе приходящий пакет GRE keepalive от \n10.44.7.1\n к нашему адресу \n10.44.6.1\n , содержащий в себе инкапсулированный обратный пакет от \n10.44.6.1\n к \n10.44.7.1\n:\ntcpdump -n -vv -i eth0 proto 47\n tcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes\n 12:53:20.976489 IP (tos 0xc0, ttl 255, id 38364, offset 0, flags [none], proto GRE (47), length 48)\n 10.44.7.1 > 10.44.6.1: GREv0, Flags [none], length 28\n IP (tos 0xc0, ttl 255, id 34625, offset 0, flags [none], proto GRE (47), length 24)\n 10.44.6.1 > 10.44.7.1: GREv0, Flags [none], length 4\n gre-proto-0x0\nТакже мы должны видеть деинкапсулированный исходящий пакет в дампе трафика на интерфейсе gre1:\ntcpdump -i gre1 -n\n 13:01:30.985542 IP 10.44.6.1 > 10.44.7.1: GREv0, length 4: gre-proto-0x0\nКроме того, стоит проверить, что в разделе \nSecurity Associations\n вывода статуса демона strongswan счетчики входящего и исходящего трафика растут:\nipsec statusall\n - команда проверки статуса ipsec\n...\nSecurity Associations\n (2 up, 0 connecting):\n dc-tun[2]: ESTABLISHED 2 hours ago, 10.1.1.246[222.45.67.1]...177.54.214.20[177.54.214.20]\n dc-tun[2]: IKEv2 SPIs: a62a46f88ff6e9c2_i* 50d27be1188d653d_r, pre-shared key reauthentication in 104 minutes\n dc-tun[2]: IKE proposal: AES_CBC_256/HMAC_SHA2_256_128/PRF_HMAC_SHA2_256/MODP_2048\n dc-tun-gre{9}:  INSTALLED, TUNNEL, reqid 3, ESP in UDP SPIs: c9788976_i 0e1488b7_o\n \ndc-tun-gre\n{9}:  AES_CBC_256/HMAC_SHA2_256_128/MODP_2048, \n13872 bytes_i (221 pkts, 8s ago), 3072 bytes_o (121 pkts, 10s ago)\n, rekeying in 34 minutes\n dc-tun-gre{9}:   10.44.6.1/32 === 10.44.7.1/32\n dc-tun-tcp{10}:  INSTALLED, TUNNEL, reqid 1, ESP in UDP SPIs: cb28899e_i ace88e01_o\n dc-tun-tcp{10}:  AES_CBC_256/HMAC_SHA2_256_128/MODP_2048, 16800 bytes_i (200 pkts, 30s ago), 16800 bytes_o (200 pkts, 30s ago), rekeying in 34 minutes\n dc-tun-tcp{10}:   10.45.8.17/28 === 100.15.30.0/24\nВ результате мы имеем рабочий GRE over IPSec тоннель по которому мы сможем получать multicast сообщения.\nДля подписки на мультикаст с помощью PIM, я использовал python скрипт, в основу которого я взял скрипт из \nэтого замечательного ответа на стаковерфлоу\n.\nДля функции \nsend_dummy_join(group, rp_addr, neighbor_ip)\n для этого примера:\ngroup\n - это адрес мультикаст группы на которую вы хотите подписаться\nrp_addr\n - адрес Multicast Rendezvous point \n100.15.30.253\n, данный нам стороной ДЦ\nneighbor_ip\n - адрес соседа (пира) по GRE тоннелю \n10.44.4.5\nДля маршрутизации мультикаста можно использовать \npimd\n, но его настройка уже не будет описана в этой статье.\nЕсли вы хотите почитать на русском о PIM, то советую \nэту статью\n (Сети для самых маленьких. Часть 9.3. Мультикаст. Протокол PIM).\n \n ",
    "tags": [
        "ipsec/gre",
        "gre",
        "ipsec",
        "multicast"
    ]
}