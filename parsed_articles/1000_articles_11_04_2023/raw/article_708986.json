{
    "article_id": "708986",
    "article_name": "Автоматическое построение плоской панорамы",
    "content": "Введение\nВ этой статье представлен простой алгоритм автоматического сшивания нескольких фотографий в плоское (иногда называют перспективное) панорамное изображение (planar/perspective panoramic image). Статья содержит код на языке\nPython\nс использованием библиотеки\nOpenCV\n.\nПлоское панорамное изображение + исходные фотографии по краям\nДля построения плоской панорамы требуются изображения снятые из одной точки. То есть камеру можно поворачивать вокруг входного зрачка объектива, но нельзя перемещать. На практике небольшие перемещения не страшны, но они дадут небольшие искажения в итоговом изображении.\nПлоская панорама не может охватить область больше \nпо вертикали, горизонтали или другому диаметру (в отличие от панорамных изображений в сферической, цилиндрической и некоторых других проекциях). Но при этом плоская панорама оставляет прямые линии прямыми — мы получим такое изображение, какое получилось бы при съемке с той же точки камерой с бо́льшими углами обзора (меньшим фокусным расстоянием).\nПанорама в сферической (слева) и плоской (справа) проекциях\nТеория\nДля начала, нам понадобится вещественная проективная \n. Проективная плоскость состоит из конечных точек, вида \n и идеальных точек, вида \n. Точка \n не задаёт элемент \n. На \n заданы классы эквивалентности — если домножить однородные координаты на ненулевой множитель, то они будут задавать ту же точку в \n. \nТо есть \n. \nЭлементы проективной плоскости можно воспринимать как конечные точки\nна плоскости \n, дополненные идеальными точками \n — точками на бесконечности в направлении \n. Также элементы проективной плоскости можно воспринимать как линии на плоскости \n. Во всех теоремах о проективной плоскости работает принцип двойственности, когда можно поменять местами точки и линии и получить двойственную теорему. \nПримеры теорем о проективной плоскости (красиво, но не важно для дальнейшего повествования)\nТеорема 1\nПрямая:\nТочка \n лежит на прямой \n.\nДоказательство: \n — точка, подставленная в уравнение прямой.\nДвойственная:\nПрямая \n пересекает точку \n.\nДоказательство: \n — точка, подставленная в уравнение прямой.\nОбратите внимание. Все идеальные точки вида \n лежат на прямой  \n. Её называют прямой на бесконечности.\nТеорема 2\nПрямая:\nЧерез 2 точки \nпроходит прямая \nДоказательство: прямая проходит через обе точки \n(свойства векторного произведения).\nДвойственная:\n2 прямые \nпересекаются в точке \nДоказательство: точка лежит на обоих прямых \n(свойства векторного произведения).\nОбратите внимание. 2 идеальные точки пересекаются в прямой на бесконечности. А 2 параллельные прямые \nпересекаются в идеальной точке \n.\n также можно представить как множество лучей (хотя точнее будет сказать прямых), вложенных в \n и проходящих через начало координат. Лучи, пересекающие плоскость \n, соответствуют конечным точкам \n, а лучи в плоскости \n — идеальным.\nГомография\n (проективное преобразование) — это преобразование \n которое прямые переводит в прямые. Для нас важно, что гомография задаётся умножением однородных координат на обратимую матрицу \n. Обратите внимание, что гомография \n задаёт одно и то же преобразование для всех ненулевых множителей \n.\nДавайте вспомним, как работает \nмодель пинхол камеры\n. Она задаёт то, как 3D-точка \nпроецируется в точку \n на плоскости изображения:\nВ эту же точку \nпроецируются все точки на луче \n. То есть модель камеры сопоставляет 2D-точку в плоскости изображения лучу в 3D пространстве. \nВ \n мы сопоставляем точке \n в плоскости \n луч (прямую) \n. То есть отождествление точки на плоскости с лучём в 3D уже подразумевается и само по себе \"проецирование\" уже произошло. Для того, чтобы соответствовать модели пинхол камеры, осталось сделать растяжение и смещение плоскости. Это можно сделать следующей гомографией:\nДавайте проверим. Пусть у нас задана точка \n. \"Спроецируем\" её на плоскость изображения с помощью гомографии \n. \n. То же самое, что предполагается моделью камеры.\nКроме операции проецирования нам интересна операция поворота в 3D. Поворот в 3D задаётся обратимой матрицей \n. Эта же матрица является матрицей гомографии в \nи работает точно так же. Только теперь уже на элементах \n. То есть вращает не точки в \n, а лучи (прямые).\nПрименение теории к задаче построения плоской панорамы\nУ нас есть \n изображений снятых из одной точки. Будем считать для всех кадров что сьемка велась из начала координат. Матрицы \n задают \nповорот каждой камеры\n. Матрицы \n задают операцию проецирования \nкаждой камеры\n. Эти матрицы нам неизвестны.\nРассмотрим произвольную точку \nнашей 3D-сцены и два кадра \n и \n. Обратите внимание, когда мы воспринимаем точку, как элемент \n, мы работаем с лучом. То есть теряем информацию о положении точки вдоль луча.\nВ кадрах \n и \n проекция точки \n будет в точках \n и \n. Так как матрицы гомографии обратимы, мы можем выразить точку (луч) \n из первого уравнения: \nИ подставить во второе:\nОбозначим \nи получим \n. То есть проекции 3D-точки \n в кадрах \n и \n связаны некоторой гомографией \n. Так как мы брали точку \n произвольно, для этих двух изображений эта связь будет работать для всех 3D-точек сцены.\nЕсли мы сможем в кадрах \n и \n найти набор 2D-2D соответствий (то есть пары 2D-точек, которые соответствуют одной 3D-точке), то у нас получится набор линейных уравнений вида\n, где \n— матрица из 9 неизвестных чисел (с точностью до ненулевого множителя). Это можно сделать с помощью алгоритма \nDLT\n. Таким образом мы получим гомографию, которая переводит точки изображения \n в точки изображения \n.\nПосле того, как для пары изображений посчитана гомография, переводящая точки одного изображения в точки другого, мы можем применить её ко всему изображению. Таким образом мы переведём одно изображение в плоскость другого.\nОбщий алгоритм\nДля построения плоской панорамы нам нужно объединить все исходные изображения в одной плоскости. Для упрощения нашего алгоритма будем использовать плоскость первого изображения.\nРаботать будем с этими тремя изображениями. Первое изображение слева.\nПервое изображение можно преобразовать само в себя с помощью identity гомографии \n. Для каждого из остальных изображений требуется найти гомографию \n, которая переводит изображение \n в плоскость первого изображения. Это не всегда получится сделать. В худшем случае наша панорама будет состоять только из первого изображения.\nПосле нахождения гомографий, когда у нас есть набор изображений и соответствующие им матрицы гомографии, мы можем вычислить границы панорамного изображения и объединить исходные фотографии в одно изображение.\nКод\nimport cv2\nimport numpy as np\nfrom typing import Tuple, List, Optional\n\n# for type hints\nRgbImg = np.array                   # shape = (h, w, 3)\nPoint2dList = np.array              # shape = (N, 2)\nDescriptorsList = np.array          # shape = (N, DESCRIPTOR_SIZE)\nHMat = np.array                     # shape = (3, 3)\nBBox = Tuple[int, int, int, int]    # BoundingBox(x, y, right, top)\n\n\ndef build_panoramic_image(imgs: List[RgbImg]) -> RgbImg:\n    used_imgs: List[Tuple[RgbImg, HMat]] = _find_all_homography(imgs)\n    result_bbox: BBox = _get_result_panorama_bbox(used_imgs)\n    return _join_panoramic_image(used_imgs, result_bbox)\nФункция \n_find_all_homography\n для каждого из исходных изображений пытается найти матрицу гомографии \n. Список\nused_imgs\nсодержит как минимум один элемент (первое изображение).\nФункция \n_get_result_panorama_bbox\n находит прямоугольник, ограничивающий результирующую плоскую панораму.\nФункция \n_join_panoramic_image\n объединяет все изображения в одно с помощью найденных матриц гомографии.\nПоиск 2D-2D соответствий\nДля вычисления гомографии между двумя изображениями нам требуется найти 2D-2D соответствия между ними. То есть набор из пар 2D-точек из первого и второго изображения, таких что каждая пара, как мы предполагаем, соответствуют какой-то 3D-точке сцены, изображенной на фотографиях.\nСуществует много способов получить 2D-2D соответствия. Здесь мы будем использовать детектор локальных особенностей SIFT. Детекторы локальных особенностей принимают на вход изображение и возвращают набор из найденных ключевых точек и их дескрипторов. В случае SIFT дескриптором будет вектор из 128 чисел типа float.\nПосле того как ключевые точки и дескрипторы найдены на обоих изображениях, между ними ищутся соответствия. Это делается с использованием дескрипторов. Если дескрипторы двух точек на разных изображениях близки (по расстоянию), то они, вероятно, соответствуют одной и той же 3D-точке сцены.\nВ простой реализации можно для каждого дескриптора первого изображения искать ближайший (по расстоянию) дескриптор из второго изображения. Этот алгоритм называется Nearest Neighbour (NN). Мы будем использовать чуть более сложный алгоритм — First-to-Second NN Ratio Check (SNN). Он чуть сложнее, но показывает заметно лучшие результаты. В нём для каждого дескриптора первого изображения ищутся два ближайших дескриптора из второго изображения и проверяется соотношение расстояний до них. Если оно близко к единице (то есть второй ближайший дескриптор второго изображения находится примерно на таком же расстоянии от дескриптора первого изображения как первый), то это соответствие считается плохим. Если соотношение меньше \n, то это соответствие можно использовать.\nЧасть 2D-2D соответствий, полученных с помощью SIFT и First-to-Second NN Ratio Check.\nМожно заметить большое количество неправильных соответствий.\nКод\ndef _detect_sift_points_and_descriptors(img: RgbImg) -> \\\n        Tuple[Point2dList, DescriptorsList]:\n    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    sift = cv2.SIFT_create()\n    keypoints, descriptors = sift.detectAndCompute(img_gray, None)\n    return np.array([kp.pt for kp in keypoints]), descriptors\n\n\ndef _snn_matching(query_descriptors: DescriptorsList,\n                  train_descriptors: DescriptorsList) -> List[cv2.DMatch]:\n    matcher = cv2.BFMatcher_create(cv2.NORM_L2, False)\n    matches_all = matcher.knnMatch(query_descriptors, train_descriptors, 2)\n    return [m1 for m1, m2 in matches_all if m1.distance < 0.8 * m2.distance]\n\n\ndef _find_matches(points1: Point2dList, descriptors1: DescriptorsList,\n                  points2: Point2dList, descriptors2: DescriptorsList) -> \\\n        Tuple[Point2dList, Point2dList]:\n    matches = _snn_matching(descriptors1, descriptors2)\n    return np.array([points1[m.queryIdx] for m in matches]), \\\n           np.array([points2[m.trainIdx] for m in matches])\nФункция \n_detect_sift_points_and_descriptors\n находит на изображении 2D-точки и соответствующие им дескрипторы.\nФункция \n_snn_matching\n реализует алгоритм поиска соответствий по дескрипторам First-to-Second NN Ratio Check (SNN).\nФункция \n_find_matches\n ищет 2D-2D соответствия среди заданных 2D-точек и дескрипторов двух изображений.\nВычисление матриц гомографии\nПо найденным 2D-2D соответствиям можно найти матрицу гомографии. Для этого используется алгоритм Direct Linear Transform (DLT). \nНе все 2D-2D соответствия являются верными. Часть из них (обычно бо́льшая часть) — выбросы, которые будут \"тянуть\" решение в неправильную сторону, если считать матрицу гомографии напрямую по всем 2D-2D соответствиям. Для отсеивания выбросов можно использовать алгоритм \nRANSAC\n. К счастью, алгоритм поиска матрицы гомографии, использующий RANSAC, уже реализован в библиотеке OpenCV. \n2D-2D соответствия, по которым была найдена матрица гомографии.\nRANSAC успешно справился с отсеиванием неправильных соответствий.\nВ результате мы найдём матрицу гомографии, которая переводит плоскость изображения 2 в плоскость изображения 1. Если 2D-2D соответствий недостаточно, то вернём \nNone\n и проигнорируем это изображение. В более сложных алгоритмах можно сопоставлять локальные особенности между всеми изображениями, а не только с первым. Такой подход поможет использовать изображения, не пересекающиеся с первым и повысить качество. Для простого алгоритма построения панорамы нашей реализации будет достаточно.\nИзображение 2 (светлее) нарисовано поверх изображения 1 (темнее) с помощью найденной матрицы гомографии. В данном случае мы использовали только ту часть изображения 2, которая пересекается с изображением 1.\nКод\ndef _find_homography(points1: Point2dList, points2: Point2dList) -> \\\n        Optional[HMat]:\n    _MIN_MATCHES, _MIN_INLIERS = 100, 30\n    if len(points1) < _MIN_MATCHES:\n        return None\n    hmat, inliers_mask = cv2.findHomography(points2, points1, cv2.RANSAC)\n    return hmat if np.sum(inliers_mask) >= _MIN_INLIERS else None\n\n\ndef _find_all_homography(imgs: List[RgbImg]) -> List[Tuple[RgbImg, HMat]]:\n    first_img = imgs[0]\n    result = [(first_img, np.eye(3))]\n    points1, descriptors1 = _detect_sift_points_and_descriptors(first_img)\n    for img in imgs[1:]:\n        points, descriptors = _detect_sift_points_and_descriptors(img)\n        matches = _find_matches(points1, descriptors1, points, descriptors)\n        hmat = _find_homography(matches[0], matches[1])\n        if hmat is not None:\n            result.append((img, hmat))\n    return result\nФункция \n_find_homography\n пытается найти матрицу гомографии, которая переводит точки\npoints2\n в точки\npoints1\n. Не будем пытаться считать гомографию, если точек меньше 100. И будем считать что гомография найдена, если количество точек-инлаеров по которым она была посчитана не менее 30.\nФункция\n_find_all_homography\nнаходит 2D ключевые точки и их дескрипторы для всех изображений, ищет 2D-2D соответствия для изображений \nи \nи пытается найти матрицы гомографий \n.\nВычисление границ панорамного изображения\nПеред тем как объединять все изображения в одно, нам нужно узнать размер итогового изображения.\nУ нас есть набор изображений и набор матриц гомографии, которые переводят все изображения в одну плоскость. Давайте найдём прямоугольник, ограничивающий все изображения в результирующей плоскости.\nТак как изображение это прямоугольник, а гомография все линии переводит в линии, то в целевой плоскости изображение превратится в четырёхугольник. Соответственно, мы можем применить гомографию ко всем углам всех изображений и посчитать ограничивающий их прямоугольник.\nЧетырёхугольники, ограничивающие разные изображения после их перевода в плоскость первого изображения.\nТакой алгоритм будет работать во всех случаях, кроме тех, когда какая то из точек изображения переводится в бесконечность. Это может произойти, если в каком то из направлений (относительно оптического центра панорамы) угловой размер превысит \n. Проигнорируем этот случай в нашем алгоритме.\nЕщё одна важная деталь. Даже если до бесконечности мы не дошли, всё равно итоговый размер панорамы может получиться сколь угодно большим. Давайте ограничим его некоторой константой. Например, пусть размер панорамы будет не больше нескольких диаметров первого изображения.\nКод\ndef _get_transformed_img_bbox(img: RgbImg, hmat: HMat) -> BBox:\n    h, w = img.shape[:2]\n    corners = np.float32([[0, 0], [0, h], [w, h], [w, 0]]).reshape(-1, 1, 2)\n    corners = cv2.perspectiveTransform(corners, hmat).reshape(-1, 2)\n    return np.min(corners[:, 0]), np.min(corners[:, 1]), \\\n           np.max(corners[:, 0]), np.max(corners[:, 1])\n\n\ndef _max_panoramic_image_bbox(first_image: RgbImg) -> BBox:\n    _MAX_SIZE_DIAMETERS = 2.0\n    h, w = first_image.shape[:2]\n    sz = int(_MAX_SIZE_DIAMETERS * np.linalg.norm((w, h)))\n    return -sz, -sz, w + sz, h + sz\n\n\ndef _get_result_panorama_bbox(used_imgs: List[Tuple[RgbImg, HMat]]) -> BBox:\n    x, y, r, t = 0.0, 0.0, 0.0, 0.0\n    for img, hmat in used_imgs:\n        i_x, i_y, i_r, i_t = _get_transformed_img_bbox(img, hmat)\n        x, y, r, t = min(x, i_x), min(y, i_y), max(r, i_r), max(t, i_t)\n    x, y, r, t = int(x), int(y), int(r), int(t)\n\n    min_x, min_y, max_r, max_t = _max_panoramic_image_bbox(used_imgs[0][0])\n    return max(x, min_x), max(y, min_y), min(r, max_r), min(t, max_t)\nФункция \n_get_transformed_img_bbox\n находит четырёхугольних, ограничивающий изображение после применения матрицы гомографии. И возвращает ограничивающий прямоугольник для этого четырёхугольника. Функция \nperspectiveTransform\n применяет гомографию \nк точкам \n и возвращает точки\n, где \n.\nФункция \n_max_panoramic_image_bbox\n возвращает ограничивающий прямоугольник для максимального размера итоговой панорамы. В данном случае мы ограничиваем размер панорамы размером исходного изображения плюс два диаметра первого изображения.\nФункция \n_get_result_panorama_bbox\n объединяет ограничивающие прямоугольники всех изображений, после применения матрицы гомографии, и пересекает с прямоугольником, обозначающим максимальный размер панорамы.\nСшивание плоской панорамы\nТеперь дело за малым — нужно объединить все изображения в одно. Для того, чтобы применить гомографию ко всему изображению, можно воспользоваться функцией \nwarpPerspective\n из OpenCV. Она делает тоже самое, что мы делали для углов изображения, но для всех пикселей и с интерполяцией.\nВ самой простой реализации можно применить гомографии ко всем изображениям, чтобы получить изображения в одной плоскости. И потом усреднить все цвета. Этот алгоритм даёт не лучшие результаты, но для наших целей он подойдёт.\nРезультат построения плоского панорамного изображения с помощью реализованного алгоритма.\nКод\ndef _join_panoramic_image(used_imgs: List[Tuple[RgbImg, HMat]],\n                          result_bbox: BBox) -> RgbImg:\n    offset_hmat = np.array([[1, 0, -result_bbox[0]],\n                            [0, 1, -result_bbox[1]],\n                            [0, 0, 1]])\n\n    result_w = result_bbox[2] - result_bbox[0]\n    result_h = result_bbox[3] - result_bbox[1]\n\n    sum_rgb = np.zeros((result_h, result_w, 3))\n    sum_mask = np.zeros((result_h, result_w))\n    for img, hmat in used_imgs:\n        warped_img = cv2.warpPerspective(\n            img, offset_hmat @ hmat, (result_w, result_h))\n        mask = np.sum(warped_img, axis=2) != 0\n        mask = cv2.erode(mask.astype(sum_mask.dtype), np.ones((3, 3)))\n        sum_rgb[mask != 0] += warped_img[mask != 0]\n        sum_mask += mask\n\n    sum_rgb[sum_mask != 0] /= sum_mask[sum_mask != 0][:, None]\n    return sum_rgb.astype(np.uint8)\nФункция \n_join_panoramic_image\n объединяет все изображения в одно, размером \nresult_bbox\n.\nОбратите внимание. Координата \n первого изображения будет находиться в координате \n(-result_bbox[0], -result_bbox[1])\n итогового изображения. Для того чтобы сдвинуть все изображения на этот вектор мы используем гомографию \noffset_hmat\n и применяем её после \nhmat\n для каждого изображения. То есть матрица гомографии \noffset_hmat @ hmat\n сначала переводит изображение в плоскость первого изображения, а потом плоскость первого изображения переводит в плоскость итоговой панорамы.\nОбратите внимание. Мы используем \ncv2.erode\n и исключаем граничные пиксели трансформированных изображений из результата. Это убирает артефакты на границе после \ncv2.warpPerspective\n.\nЗаключение\nМы разобрали простой алгоритм автоматического построения плоского панорамного изображения. В процессе мы затронули большое количество разных алгоритмов и терминов, использующихся в компьютерном зрении.\nПредставленный алгоритм не рекомендуется использовать на практике. Но он достаточно компактен и подходит для изучения и экспериментов с детекторами локальных особенностей, матрицами гомографий и т.д.\nЧто используется в полноценных решениях, чего в нашем простом алгоритме нет?\nЕсть много вещей, которые могли бы улучшить решение. Например, компенсация дисторсии в исходных изображениях, более интеллектуальный поиск 2D-2D соответствий (например, построение графа из изображений) или использование более продвинутых алгоритмов слияния изображений (например Multiband blending).\nСамое главное отличие нашего алгоритма от более продвинутых — в них поиск матриц гомографии лишь один из этапов. После чего происходит восстановление матриц поворота \n и проекции \n для каждого изображения (матрицы проекции часто считаются одинаковыми для всех камер или, даже, известными). Такой подход позволяет строить любую панораму, а не только плоскую. Если для камеры известны \n, то для каждой точки изображения известен соответствующий ей луч. И всё изображение можно спроецировать изнутри на цилиндр, чтобы получить цилиндрическую панораму, сферу, для сферической панорамы, и т.д. Даже для плоской панорамы такой подход тоже имеет свои плюсы. Можно вычислить направление вокруг которого сосредоточено максимальное количество данных изображений, и центрировать плоскость относительно него. Да и матрицы гомографии получаются точнее, при восстановлении их из \n вместо поиска в произвольном виде. Например, при известных параметрах камеры, каждая гомография задаётся матрицей поворота. Это 3 степени свободы вместо 8 в общем случае.\nИнтерфейс программы Hugin для сшивания панорамных изображений.\nОбратите внимание на доступные варианты проекций. Сейчас выбрана плоская (прямолинейная) проекция.\nМатериалы\nMultiple View Geometry in Computer Vision. Richard Hartley and Andrew Zisserman — одна из фундаментальных книг классического компьютерного зрения. Содержит всю теорию, использовавшуюся в данной статье;\nАвтоматическое построение плоской панорамы\n — исходный код реализованного в статье алгоритма;\nМодель камеры\n — подробная статья о модели пинхол камеры;\nHugin\n — инструмент для сшивания панорамных изображений с открытым исходным кодом;\nImage Composite Editor\n — бесплатный инструмент для сшивания панорамных изображений от Microsoft.\n \n ",
    "tags": [
        "компьютерное зрение",
        "3d computer vision",
        "computer vision",
        "opencv",
        "panorama",
        "панорамное фото",
        "python",
        "математика",
        "обработка изображений"
    ]
}