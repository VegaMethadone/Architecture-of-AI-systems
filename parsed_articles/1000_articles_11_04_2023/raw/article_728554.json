{
    "article_id": "728554",
    "article_name": "Нейронные сети и Android: как их создавать и использовать в мобильных приложениях",
    "content": "Маски в Snapchat и Запрещёноgram, категоризация фотографий в галерее, улучшение качества фотографий в Google Camera — все эти фичи в приложениях используют нейронные сети. Будущее мобильных устройств тесно связано с развитием нейронных сетей и их интеграцией в различные приложения: нейросети помогают усовершенствовать пользовательский опыт и повысить эффективность работы приложений.\nМеня зовут Артём Пустовой, я Android-разработчик \nв Surf\n. Мы, как и весь мир, тоже поймали тренд на нейросети и встраиваем их в наш рабочий процесс. Расскажу, как создавать свои модели и как их использовать в Android-приложении. Разберём, как использовать в приложениях нейросети с аппаратным ускорением локально, без подключения к сети. \nПриходите 14 апреля 2023-го, в пятницу, на прямой эфир «Что нового в Android и чем нам помогут нейросети». Начало в 17:00 мск. Подробности — \nв тг-канале Surf Android Team >>\nКакие виды нейронных сетей существуют\nНейронные сети — инструмент машинного обучения, который может решать сложные задачи. Например, распознавать образы, классифицировать данные. Видов нейросетей огромное множество. Ниже я перечислю основные. \nЗачем это нужно знать в статье про Android? Если вы хотите создавать и обучать нейросети, а не берёте готовую модель, важно знать, какой тип сети подходит для решения конкретной задачи, и понимать её принцип работы.\nПрямые нейронные сети\n. Самые простые: информация передается только в одном направлении, от входных данных к выходным. Используются для классификации и регрессии. \nСвёрточные нейронные сети\n. Оптимизированы для обработки изображений: используют слои для выделения признаков изображения, и например, снижения веса и разрешения изображения. \nСвёрточные нейросети\nРекуррентные нейронные сети\n. Нужны для обработки естественного языка, генерации текста.\nРекуррентные нейросети\nГлубокие нейронные сети\n. Наиболее сложный и мощный вид нейронных сетей: у них есть скрытые слои, которых может быть огромное количество. Нужны для обработки сложных исходных данных. Могут использоваться, например, для обработки изображений, в прогнозировании.\nГлубокие нейросети\nРекурсивные\n. Нужны для обработки деревьев или графа. Пример: обработка естественного языка, генерация текста. Применяются везде, где данные имеют иерархию.\nSelf-Organizing Maps (SOM)\n для кластеризации данных и визуализации высокоразмерных данных.\nЧтобы глубже познакомиться с нейронными сетями, рекомендую: \n* Цикл статей на Хабре «\nНейронные сети для начинающих\n»\n* Книгу «Создаем нейронную сеть» Тарика Рашида \nИнструменты для внедрения нейронок в Android\nДля создания и внедрения нейронных сетей в Android приложение можно применять различные инструменты. Рассмотрим наиболее популярные.\nИнструменты для Android\nTensorFlow Lite\n. Библиотека специально разработана для работы с мобильными устройствами. Обеспечивает высокую производительность и компактный размер моделей. Поддерживает интеграцию с NNAPI: помогает ускорить выполнение на аппаратном уровне.\nKeras и PyTorch\n. Обе библиотеки обладают богатым набором инструментов для обучения нейронных сетей и поддерживают экспорт моделей в формат TensorFlow Lite. Если вы хотите создать сложную нейронную сеть с нестандартной архитектурой, можно использовать эти библиотеки.\nML Kit\n. Сервис предоставляет готовые решения для ряда задач: например, распознавание изображений и звука, анализ текста и так далее. Но при использовании ML Kit вы можете ограничены в возможностях настройки моделей.\nNNAPI (Neural Networks API)\n — это API, разработанное компанией Google. Позволяет использовать аппаратное ускорение для выполнения вычислений нейронных сетей на устройствах с операционной системой Android.\nNNAPI: остановимся подробнее\nПочему мы решили рассказать чуть подробнее именно о NNAPI? На Android-устройствах этот инструмент может сильно ускорить выполнение операций при работе с нейронными сетями. \nЧем полезен NNAPI при работе с нейронками на Android\nМожет увеличить скорость работы приложений и уменьшить нагрузку на процессор\n. Использует аппаратную ускоренную обработку: это позволяет повысить производительность выполнения операций нейронных сетей.\nОбеспечивает высокую оптимизацию и эффективность выполнения операций для нейронной сети. \nСмартфоны от разных производителей могут иметь разные аппаратные возможности и спецификации, включая процессоры и графические ускорители. Использование NNAPI позволяет разработчикам мобильных приложений использовать аппаратные ресурсы устройства наилучшим образом.\nNNAPI поддерживают разные библиотеки\n, включая TensorFlow Lite.\nПриложение становится энергоэффективным\n: повышается скорость, уменьшается потребление.\nОфициальная информация от Google: NNAPI в 3 раза ускоряет время ожидания и в 3,7 раза снижает потребление заряда\nПодробности про «внутренности» NNAPI, архитектуру и принцип работы хорошо описаны \nв документации\n. \nNNAPI практически никогда не используется самостоятельно. Есть более высокоуровневые и удобные инструменты, которые умеют использовать эту библиотеку. Мы же будем использовать Tensorflow Litе с поддержкой NNAPI.\nСочетание TensorFlow Lite и NNAPI может быть хорошим выбором в ситуациях, когда требуется максимально эффективное использование аппаратных ресурсов для запуска нейронных сетей на устройствах Android.\nНо прежде чем встраивать нейронную сеть в Android-приложение, необходима сама нейронная сеть. Давайте разберем, как нам создать модель, которую мы сможем использовать с Tensorflow LIte.\nКак создать собственную модель\nНемного теории — без неё не обойтись\nДля начала рассмотрим, что такое нейрон. Простыми словами это нечто, которое принимает входные данные, выполняет некоторые вычисления и передает данные дальше. \nНейрон состоит из трёх элементов: \nвходы, \nвеса, \nфункция активации.\nВес — это величина, которая показывает важность каждого входа. Оптимальные значения весов могут помочь нейронной сети достичь высокой точности в выполнении задач, для которых она была обучена. Изначально эти параметры случайны и в процессе обучения корректируются. В алгоритмах линейной регрессии обычно будет диапазон (0, 1), если функция активации — сигмоида. \nФункция активации — это математическая функция, которая определяет, какой выходной сигнал будет передан из нейрона в следующий слой нейронной сети. Функция активации применяется к выходу нейрона после того, как входные данные умножаются на соответствующие им веса. Она может добавлять нелинейность к выходу: это позволяет нейронной сети лучше обрабатывать сложные данные.\nРазные функции активации\nСхема нейронной сети:\nСигнал в нейронной сети распространяется от входных нейронов к выходным нейронам через слои нейронов.\nВходные данные передаются входным нейронам. Они передают сигнал следующему слою нейронов. Каждый нейрон в слое принимает сигналы от предыдущего слоя, умножает их на соответствующие веса и передает результат следующему нейрону. Таким образом, каждый нейрон в слое обрабатывает информацию от предыдущего слоя и передаёт результат следующему.\nВот и всё. По сути у нас есть какие-то входные данные, которые мы умножаем на веса и суммируем. После передаём в функцию активации и далее — в следующий нейрон.\nНо у нас может возникнуть вопрос. Если веса случайны, как нейронная сеть будет выдавать нужный результат? Для этого её необходимо обучить, и учиться она будет на своих ошибках. \nЧтобы нейронная сеть могла обучаться, необходимо подготовить размеченные данные: входные данные и ожидаемый результат. Например, для функции \ny = 2x-1\n входные данные — это \nx\n, а ожидаемый результат — \ny\n.\nПрогоняем сеть через входные данные, считаем ошибку и корректируем веса каждого нейрона. \nДля тех, кому интересно, как считается ошибка и как корректируются нейроны, рекомендую всё то же:\n* Цикл статей на Хабре «\nНейронные сети для начинающих\n»\n* Книгу «Создаем нейронную сеть» Тарика Рашида\nПриступим к созданию собственной модели\nДля своей модели будем подсчитывать ошибку среднеквадратичной функцией, а обучать сеть методом градиентного спуска. \nЧтобы сделать простую модель, понадобится немного Python. Также нам нужны будут две библиотеки: TensorFlow и NumPy.\nДобавляем зависимости:\nimport tensorflow as tf\n\nimport numpy as np\nСоздадим сетку, которая будет считать функцию \n2*x - 1\n. У нас будет один вход и один выход.\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=(1,), name='input'),\n    tf.keras.layers.Dense(units=1, activation='linear', name='output')\n])\n\nВ этом примере определяем модель, которая состоит из одного входного слоя (Input) и одного выходного слоя (Dense) с единственным выходным узлом. Используем класс \nSequential\n. Входной слой имеет форму \n(shape) (1,)\n, то есть он принимает одномерный вектор с одним значением.\nМы выбрали линейную функцию активации для выходного слоя, потому что решали задачу регрессии. Цель регрессии — предсказать непрерывную целевую переменную (в данном случае, значение \ny\n) на основе входных данных (в данном случае, значение \nx\n).\nДалее надо скомпилировать модель. Мы выбрали градиентный спуск, потому что это один из самых популярных методов оптимизации в глубоком обучении. Градиентный спуск оптимизирует веса модели на основе градиента функции потерь по отношению к весам. \nДля подсчета ошибок используем среднеквадратичную функцию. Функция потерь показывает, насколько сильно предсказанные значения отклоняются от реальных значений.\nmodel.compile(optimizer=tf.keras.optimizers.SGD(lr=0.01), loss='mean_squared_error')\nКонечно, существуют другие методы оптимизации и функции потерь, которые могут быть применены в различных ситуациях. В нашем примере мы использовали градиентный спуск и среднеквадратичную функцию, потому что они обычно демонстрируют хорошие результаты в задачах регрессии.\nОбучаем модель на наборе данных, состоящем из пяти пар входных и выходных значений. Входные значения хранятся в массиве \nx_train\n, а соответствующие выходные значения — в массиве \ny_train\n. Обучение выполняется на протяжении 500 эпох — то есть проходов через обучающий набор данных. Величина эта эмпирическая — зависит от количества данных и степени точности, которая требуется от модели. \nx_train = np.array([-1.0, 0.0, 1.0, 2.0, 3.0])\n\ny_train = np.array([-3.0, -1.0, 1.0, 3.0, 5.0])\n\nmodel.fit(x_train, y_train, epochs=500)\nПосле запуска видно, как величина ошибки уменьшается.\nПротестируем нашу модель. Как видим ниже, она верно считает результат.\nДалее форматируем модель в формат .tflite и сохраняем её.\nКонечно, для более сложных задач требуется больше навыков и знаний. Также после вашу модель нужно будет обучить на большом количестве размеченных данных. Поэтому для начала стоит поискать, может быть уже есть готовое решение, которое подойдет под ваш случай. Например, \nв TensorFlow Hub\n есть модели для классификации изображения, для определения звука и так далее. \nКак использовать готовую модель с аппаратным ускорением NNAPI\nДавайте для примера сделаем фичу, которая должна будет распознать, что изображено на картинке. \nПри выборе модели нужно учитывать:\nРазмер модели\n: она должна быть достаточно маленькой, чтобы поместиться на устройстве и быстро загружаться.\nТочность\n должна быть достаточно высокой для решения поставленной задачи.\nКак мы далее убедимся, точность выбранной нами модели будет невысокой, если пытаться ей скормить фотографии собаки. Поэтому нужно внимательно выбирать модель под конкретную задачу.\nВыбираем модель \nиз TensorFlow Hub\n. Кидаем её в assets и запрещаем в gradle сжатие. Если файл модели сжать, размер изменится и приложение может не смочь правильно загрузить модель. Это приведёт к ошибкам в работе модели и, в конечном итоге, к сбоям приложения.\nandroidResources {\n   noCompress 'tflite'\n}\nВставляем зависимости. \nimplementation 'org.tensorflow:tensorflow-lite-task-vision:0.4.0'\nimplementation 'org.tensorflow:tensorflow-lite-gpu-delegate-plugin:0.4.0'\nimplementation 'org.tensorflow:tensorflow-lite-gpu:2.9.0'\nNNAPI уже входит в одну из них.\nСоздаём image classifier: он устанавливает порог оценки для результатов классификации изображения.\nprivate fun setupImageClassifier() {\n   val threshold: Float = 0.5f\n   val maxResults: Int = 3\n   val numThreads: Int = 2\n   val optionsBuilder = ImageClassifier.ImageClassifierOptions.builder()\n       .setScoreThreshold(threshold)\n       .setMaxResults(maxResults)\n\n   val baseOptionsBuilder = BaseOptions.builder().setNumThreads(numThreads)\n   baseOptionsBuilder.useNnapi()\n   optionsBuilder.setBaseOptions(baseOptionsBuilder.build())\n\n   val modelName = \"model.tflite\"\n\n   try {\n       imageClassifier =\n           ImageClassifier.createFromFileAndOptions(context, modelName, optionsBuilder.build())\n   } catch (e: IllegalStateException) {\n       Log.e(\"TF\", \"TFLite failed to load model with error: \" + e.message)\n   }\n}\n\nПолучился image-классификатор с уже обученной моделью. Можем выполнять код. \nНа вход подаём bitmap — его надо получить из картинки. Картинку прогоняем через image-процессор и получаем выходной результат.\n// Create preprocessor for the image.\nval imageProcessor = ImageProcessor.Builder()\n   .build()\n\n// Preprocess the image and convert it into a TensorImage for classification.\nval tensorImage = imageProcessor.process(TensorImage.fromBitmap(image))\n\nval imageProcessingOptions = ImageProcessingOptions.builder()\n   .setOrientation(getOrientationFromRotation(rotation))\n   .build()\n\nval results = imageClassifier?.classify(tensorImage, imageProcessingOptions)\n\nРезультаты:\nИспользование локальной модели нейронной сети может значительно ускорить работу приложения и повысить его функциональность, особенно в тех случаях, когда необходимо обрабатывать данные быстро и без интернет-соединения. \nВместо создания своей собственной модели нейронной сети можно использовать уже обученную модель, что позволит избежать сложностей при обучении и получить более точные результаты. Локальные вычисления на устройстве, хоть и редко используются, могут быть полезны в специфических случаях, когда необходима быстрая обработка данных без ожидания ответа от сервера, например, в случае, когда нужно классифицировать изображение с камеры.\nПриходите на прямой эфир в эту пятницу: расскажем про нейросети больше\nОбсудим нововведения Android 14 и использование нейросетей в нативной разработке в прямом эфире. У микрофона:\n— Алексей Рябков, Surf Android TeamLead\n— Герман Прошунин, Surf Android Developer\n— Максим Кругликов, Surf Android Developer\n— Кирилл Розов, Tinkoff Staff Engineer, автор YouTube-канала \nAndroid Broadcast\nКогда и где\n14 апреля, пятница, 17:00 мск\nСледите за анонсами \nв телеграм-канале Surf Android Team\n \n ",
    "tags": [
        "surf",
        "nnapi",
        "tensorflow",
        "tensorflow-lite",
        "нейросети",
        "разработка под android",
        "мобильная разработка",
        "нейронные сети"
    ]
}