{
    "article_id": "727498",
    "article_name": "Разворачиваем Apache Kafka",
    "content": "В \nпредыдущей статье\n мы достаточно подробно рассмотрели архитектуру Apache Kafka, из каких компонентов состоит данное решение, что для чего предназначено. И в этой статье мы рассмотрим процесс развертывания данного решения.\nДля запуска Kafka можно использовать решения для управления кластером, такие как ZooKeeper или KRaft. В статье мы рассмотрим работу с ZooKeeper. Zookeper это распределенное приложение для управления кластером, состоящим из большого количества узлов. \nПеред установкой Zookeeper не забудьте поставить Java, например вот так:\napt -y install openjdk-8-jre\nДля установки zookeeper сначала перейдем на официальную страницу данного решения \nhttps://zookeeper.apache.org/releases.html\n и выберем последнюю версию.\nЗагрузим данную версию с помощью wget:\nwget https://dlcdn.apache.org/zookeeper/zookeeper-3.8.1/apache-zookeeper-3.8.1-bin.tar.gz\nДалее создадим каталог и распакуем в него архив:\nmkdir /opt/zookeeper\ntar zxvf apache-zookeeper-3.8.1.tar.gz -C /opt/zookeeper --strip-components=1\nДля работы нам также потребуются дополнительные каталоги:\nmkdir -p /opt/zookeeper/data /var/log/zookeeper\nДалее мы переходим к конфигурированию системы. Для этого нам потребуется файл /opt/zookeeper/conf/zoo.cfg.\nЭтот файл необходимо наполнить следующим содержимым:\ntickTime = 2000\nmaxSessionTimeout = 50000\nsyncLimit = 5\ninitLimit = 300\nautopurge.purgeInterval = 1\nautopurge.snapRetainCount = 5\nsnapCount = 200000\nclientPort = 2181\nmaxClientCnxns = 100\n4lw.commands.whitelist=stat\ndataDir = /opt/zookeeper/data\ndataLogDir = /var/log/zookeeper\nМы не будем в этой статье подробно останавливаться на значении каждого из параметров, так как это несколько выходит за рамки статьи. \nДалее мы настроим запуск приложения в качестве сервиса. Для этого создадим специальную учетку, настроим ей права и создадим файл юнита в systemd.\nuseradd -r -c 'Zookeeper service' zookeeper\nchown -R zookeeper:zookeeper /opt/zookeeper /var/log/zookeeper\nФайл юнита /etc/systemd/system/zookeeper.service будет иметь следующую структуру:\n[Unit]\nDescription=ZooKeeper Service\nDocumentation=https://zookeeper.apache.org/\nRequires=network.target\nAfter=network.target\n \n[Service]\nType=forking\nUser=zookeeper\nGroup=zookeeper\nWorkingDirectory=/opt/zookeeper\nExecStart=/opt/zookeeper/bin/zkServer.sh start\nExecStop=/opt/zookeeper/bin/zkServer.sh stop\nExecReload=/opt/zookeeperbin/zkServer.sh restart\nTimeoutSec=30\nRestart=on-failure\n \n[Install]\nWantedBy=default.target\nЗатем нам необходимо просто перезапустить system и запустить zookeper:\nsystemctl daemon-reload\nsystemctl enable zookeeper --now\nПроверим статус zookepeer:\nsystemctl status zookeeper\nБазовые настройки Zookeeper мы выполнили. Настройка управления отдельными узлами кластера опять таки не входит в тему данной статьи, поэтому далее мы перейдем к установке Kafka.\nСтавим Кафку\nДля начала нам потребуется загрузить последнюю версию продукта. Далее распаковываем архив и переходим в созданный каталог. \n$ tar -xzf kafka_2.13-3.4.0.tgz\n$ cd kafka_2.13-3.4.0\nДалее нам необходимо запустить Zookeper с настройками, необходимыми для работы Kafka.\n$ bin/zookeeper-server-start.sh config/zookeeper.properties\nПри успешном запуске мы получим примерно такую \"портянку\".\nДалее откроем еще одну SSH сессию в которой собственно запустим Kafka\n# Start the Kafka broker service\n$ bin/kafka-server-start.sh config/server.properties\nЗдесь нас никакой особой псевдографикой не порадовали, так что просто смотрим вывод на предмет ошибок.\nКак видно, мы создали базовую конфигурацию для работы Kafka. Для того, чтобы не плодить окна командной строки или SSH сессии я бы посоветовал перезапустить две последние команды в фоновом режиме, т.е. добавить &.\nСоздаем топик\nНапомню из материалов предыдущей статьи, что Kafka - это платформа распределенной потоковой передачи событий, которая позволяет вам читать, записывать, хранить и обрабатывать сообщения на многих узлах.\nДля начала в качестве примера создадим топик quickstart-events с помощью команды:\n$ bin/kafka-topics.sh --create --topic quickstart-events --bootstrap-server localhost:9092\nДавайте посмотрим статистику по созданному топику:\n$ bin/kafka-topics.sh --describe --topic quickstart-events --bootstrap-server localhost:9092\nКак видно, пока наш топик пуст и самое время начать записывать в него сообщения. Для записи сообщений в топик quickstart-events воспользуемся следующей командой:\n$ bin/kafka-console-producer.sh --topic quickstart-events --bootstrap-server localhost:9092\nПосле запуска в интерактивном режиме вводим строки (Ctrl+C для завершения):\nКак видите, я не переключил кодировку в первой строке и отправил строку на кириллице. Посмотрим как ее сохранит Kafka.\nДля чтения событий из топика quickstart-events применим команду:\n$ bin/kafka-console-consumer.sh --topic quickstart-events --from-beginning --bootstrap-server localhost:9092\nКак видите кириллица нормально сохранилась и прочиталась, это говорит о том, что у нас не должно быть проблем при использовании различных кодировок в сообщениях. Сообщения будут храниться в Kafka столько времени, сколько потребуется. При повторных подключениях мы можем прочитать текущий поток сообщений, а также добавлять новые.\nПодключаем источники\nЕстественно, представленный вариант работы с сообщениями “вручную” на практике мало применим. Гораздо интереснее попробовать в автоматическом режиме прочитать сообщения из источника и поместить их в топик Kafka. В качестве примера мы импортируем данные из файла в раздел Kafka и затем экспортируем данные из раздела Kafka в файл.\nДля этого нам потребуется указать в свойствах plugin.path файла config/connect-standalone.properties файл connect-file-3.4.0.jar. Откроем это файл и добавим в него строку:\nplugin.path=libs/connect-file-3.4.0.jar\nСобственно все, далее создаем текстовый файл с сообщениями, которые мы будем читать:\necho -e \"event1\\nevent2\\nevent3\" > test.txt\nДалее нам необходимо запустить коннектор, который будет читать сообщения из этого файла и коннектор, который будет сохранять сообщения в sink файле. В наборе файлов, идущих вместе с Kafka есть файлы config/connect-file-source.properties и config/connect-file-sink.properties. В первом файле указаны настройки для считывания файла test txt, а втором настройки для файла хранения сообщений test.sink.txt. Когда команда ниже будет выполнена коннектор, считывающий сообщения из исходного файла test.txt будет загружать их в топик connect-test (который также есть в конфигурационных файлах), а sink коннектор начнет читать сообщения из топика connect-test и запишет их в файл test.sink.txt.\nbin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties\nУбедиться в работе коннектора можно с помощью просмотра содержимого test.sink.txt:\nЗаключение\nНа этом, я полагаю сегодняшнюю статью можно завершить. Мы развернули Apache Kafka и Zookeeper, посмотрели как можно вручную создавать топики, добавлять и читать сообщения, а также развернули коннектор, читающий данные из текстового файла. В следующей статье мы продолжим изучение практических аспектов работы с Kafka. А сейчас хочу пригласить вас на\n бесплатный урок\n, в рамках которого рассмотрим как в приложениях на Spring Boot можно работать с Kafka. Узнаем, что предоставляет платформа Spring для ускоренной разработки приложений, работающих с Kafka. Посмотрим, какие есть настройки, как это все конфигурируется. Проведем границу между \"родным функционалом\" Kafka api и \"добавками\" от Spring Boot.\nЗарегистрироваться на бесплатный урок\n \n ",
    "tags": [
        "kafka",
        "zookeeper"
    ]
}