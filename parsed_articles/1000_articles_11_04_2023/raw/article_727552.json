{
    "article_id": "727552",
    "article_name": "Обеспечение безопасности в Apache Kafka",
    "content": "В \nпредыдущих статьях\n мы рассмотрели архитектуру решения Apache Kafka, развернули продукт и разобрались с отправкой и получением сообщений. Можно было бы, конечно, дальше погрузиться в тему использования данного решения, но в Интернете есть множество различных публикаций с примерами использования Kafka для различных задач и различных сред разработки. Поэтому данная статья будет целиком и полностью посвящена такой важной теме, как обеспечение безопасности Apache Kafka.\nПо своему предназначению Kafka является посредником между различными системами при их обмене сообщениями. Для этого, как мы помним, есть топики и разделы. Но проблема заключается в том, что при стандартной настройке Kafka по умолчанию, любой пользователь или приложение может писать любые сообщения в любой топик, а также считывать данные из любых топиков. Естественно, для сколько-нибудь промышленного применения системы такой подход недопустим. Например, в случае, когда несколько приложений используют один и тот же кластер Kafka, или когда кластер используется в качестве облачного сервиса для сторонних приложений, ну и естественно, когда в Kafka начинает обрабатываться конфиденциальная информация.\nВ статье мы будем говорить о встроенных в Kafka механизмах защиты и не будем касаться использования каких-либо наложенных средств. Начиная с версии 0.9.0.0 в продукт были добавлены ряд функций, которые позволяют повысить уровень защищенности Kafka. Вот основные функции:\nАутентификация подключений к брокерам от клиентов (продьюсеров и консьюмеров), других брокеров и приложениями, использующими SSL или SASL (Kerberos).\nАутентификация подключений от брокеров к ZooKeeper.\nШифрование данных, передаваемых между брокерами и клиентами, между брокерами или между брокерами и инструментами, с использованием SSL (обратите внимание, что при включении SSL происходит снижение производительности, величина которого зависит от типа процессора и реализации JVM).\nАвторизация операций чтения/записи, выполняемых клиентами.\nАвторизация подключаема и поддерживается интеграция с внешними службами авторизации.\nДалее в статье я не буду уделять слишком много внимания “матчасти”, то есть описанию работы тех или иных широко распространенных механизмов защиты, таких как SSL. При необходимости читатель может найти всю необходимую информацию в Интернете. Вместо этого мы уделим больше внимания непосредственно настройке защитных механизмов в Kafka.\nРаботаем с SSL\nSSL (secure sockets layer) представляет собой криптографический протокол для безопасной связи. В Kafka по умолчанию этот протокол отключен. Но мы можем в любой момент включить SSL. \nРабота с SSL как и в большинстве других систем, в Kafka начинается с создания сертификата. Когда мы устанавливали Zookeeper и Kafka, то предварительно была развернута Java, в состав которой входит утилита keytool. Далее мы сгенерируем ключ во временном хранилище ключей, чтобы позже экспортировать и подписать его с центром сертификации  \nkeytool -keystore server.keystore.jks -alias localhost -validity {validity} -genkey\nВ моем примере был сгенерирован такой ключ. Обратите внимание на необходимость обязательного указания пароля.\nПараметр keystroke указывает в каком файле хранить ключ, а validity это период действия сертификата в днях. Помните про то, что для корректной работы сертификатов необходима правильная настройка DNS, позволяющая корректно разрешать имена узлов. \nПриведенные выше действия по генерации ключей необходимо проделать на всех узлах кластера. \nСейчас у нас имеются сертификаты, но они являются самоподписанными, то есть злоумышленник может при желании тоже сгенерировать свой сертификат, и обменявшись открытыми ключами с парой легальных участников читать и модифицировать весь их трафик (атака Man in the Middle).  Поэтому важно предотвратить подделку сертификатов, подписав их для каждой машины в кластере. Для решения этой задачи необходим центр сертификации (CA), который отвечает за подписание сертификатов. Центр сертификации подписывает сертификаты, и криптография гарантирует, что подписанный сертификат сложно подделать с вычислительной точки зрения. Таким образом, пока центр сертификации является подлинным и заслуживающим доверия органом, клиенты могут быть уверены в том, что они подключаются к подлинным машинам.\nДалее мы сгенерируем пару открытых и закрытых ключей и сертификат, которым мы собственно и будем подписывать другие сертификаты. Затем мы добавим сгенерированный сертификат ЦС в доверенное хранилище клиентов, чтобы клиенты могли ему доверять.\nopenssl req -new -x509 -keyout ca-key -out ca-cert -days 365\nkeytool -keystore server.truststore.jks -alias CARoot -import -file ca-cert\nВ нашем хранилище доверия хранятся все сертификаты клиента, которым он должен доверять. Импорт сертификата в свое доверенное хранилище также означает доверие всем сертификатам, подписанным этим сертификатом. Этот атрибут называется цепочкой доверия, и он особенно полезен при развертывании SSL в большом кластере Kafka. Вы можете подписать все сертификаты в кластере с помощью одного центра сертификации, и все компьютеры будут использовать одно и то же хранилище доверия, которое доверяет центру сертификации. \nТеперь нам необходимо подписать наш сгенерированный сертификат сертификатом ЦС. Для этого мы сначала экспортируем сертификат из хранилища, а затем подпишем его сертификатом ЦС и импортируем оба сертификата в свое хранилище:\nkeytool -keystore server.keystore.jks -alias CARoot -import -file ca-cert\nkeytool -keystore server.keystore.jks -alias localhost -import -file cert-signed\nНастройка брокеров\nНастройка брокеров начинается с указания списка портов, ка которых мы будем принимать соединения. Так как мы используем соединение по SSL, то на стороне брокера необходимо выполнить следующие настройки:\nssl.keystore.location=/var/private/ssl/kafka.server.keystore.jks\n        ssl.keystore.password=…\n        ssl.key.password=…\n        ssl.truststore.location=/var/private/ssl/kafka.server.truststore.jks\n        ssl.truststore.password=…\nДля проверки корректности работы выполненных настроек, вы можете выполнить следующие команды:\nopenssl s_client -debug -connect localhost:9093 -tls1\nНастраиваем SASL\nSASL (Simple Authentication and Security Layer) — это платформа для аутентификации и защиты данных в интернет-протоколах. Он направлен на то, чтобы отделить интернет-протоколы от конкретных механизмов аутентификации. Рассмотрим принципы работы SASL.\nПри подключении сервер отправляет запрос клиенту со списком возможных механизмов аутентификации, а клиент отправляет ответ на основе информации из запроса. Запрос и ответ представляют собой массивы байтов произвольной длины и, следовательно, могут содержать любые данные, относящиеся к конкретному механизму.\n \nЭтот обмен данными может продолжаться в течение нескольких итераций и, наконец, заканчивается, когда сервер больше не выдает никаких вызовов. Главное, что необходимо понять о работе SASL, это то, что данный механизм аутентификации предоставляет только структуру для обмена данными о вызовах и ответах. В нем ничего не упоминается о самих данных или о том, как они обмениваются. Данные задачи должны выполнять приложения, использующие SASL.\nВернемся к настройке Kafka. Для настройки аутентификации нам потребуется протокол Kerberos, то есть мы можем использовать для аутентификации Active Directory. Если в вашей сети нет AD, то необходимо будет развернуть сторонний сервер Kerberos. Так или иначе вам необходимо создать записи (принципалы) в вашем каталоге AD или другой системе для каждого брокера Kafka в вашем кластере. \nВ каталоге с конфигурациями брокера создадим файл \nkafka_server_jaas.conf\n следующего содержания:\nЗатем нам необходимо указать Kafka пути к конфигурационным файлам:\n    \n-Djava.security.krb5.conf=/etc/kafka/krb5.conf\n    -Djava.security.auth.login.config=/etc/kafka/kafka_server_jaas.conf\nДобавим порты, которые система должна слушать:\nlisteners=SASL_PLAINTEXT://host.name:port\nЕсли используется SASL_SSL, то также необходимо настроить SSL. Если вы настраиваете только порт SASL (или если вы хотите, чтобы брокеры Kafka аутентифицировали друг друга с помощью SASL), то убедитесь, что вы установили один и тот же протокол SASL для взаимодействия между брокерами:\nsecurity.inter.broker.protocol=SASL_PLAINTEXT\nМы также должны настроить имя службы в server.properties, которое должно соответствовать основному имени брокеров kafka. В приведенном выше примере принципалом является \"\nkafka/kafka1.hostname.com@EXAMPLE.com\n\", так что:\nsasl.kerberos.service.name=kafka\nПодключаем клиентов\nКлиенты нашего кластера Kafka будут проходить аутентификацию в кластере с помощью своего собственного аккаунта (обычно с тем же именем, что и у пользователя, запускающего клиент). Для каждого клиента нам потребуется создать файл JAAS аналогично тому, как мы это делали выше. Ниже приведен пример конфигурации для клиента, использующего \nkeytab\n:\nKafkaClient {\n\n        com.sun.security.auth.module.Krb5LoginModule required\n        useKeyTab=true\n        storeKey=true\n        keyTab=\"/etc/security/keytabs/kafka_client.keytab\"\n        principal=\"kafka-client-1@EXAMPLE.COM\";\n  \n    };\nВ разделе Kafka Client описано, как клиенты, такие как продьюсеры и консьюмеры, могут подключаться к Kafka Broker. Далее передадим системе пути к конфигурационным файлам также, как мы это делали выше.\n    \n-Djava.security.krb5.conf=/etc/kafka/krb5.conf\n    -Djava.security.auth.login.config=/etc/kafka/kafka_client_jaas.conf\nИ в завершение нам необходимо настроить на наших продьюсерах и консьюмерах следующие свойства в producer.properties или consumer.properties\nsecurity.protocol=SASL_PLAINTEXT (or SASL_SSL)\n    sasl.kerberos.service.name=kafka\nПро ACL\nВ заключении темы безопасности Kafka рассмотрим возможности по работе со списками доступа ACL. По умолчанию, если какой-либо ресурс не связан с ACL, то никто, кроме суперпользователя не получит к нему доступ. Изменить эти настройки можно с помощью правок в файле broker.properties.\nallow.everyone.if.no.acl.found=true\nЕсли же мы хотим добавить каких-либо пользователей в группу суперпользователей, то необходимо перечислить их (обратите внимание, что разделителем является точка с запятой, поскольку имена пользователей SSL могут содержать запятую).\nsuper.users=User:Bob;User:Alice\nЗаключение\nНа этом тему базовой настройки безопасности в Apache Kafka можно считать завершенной. Мы рассмотрели работу с SSL, SASL аутентификацию и соответствующие настройки на клиентах.  А прямо сейчас хочу пригласить вас на \nбесплатный вебинар\n, в рамках которого рассмотрим как в приложениях на Spring Boot можно работать с Kafka. Узнаем, что предоставляет платформа Spring для ускоренной разработки приложений, работающих с Kafka. Посмотрим, какие есть настройки, как это все конфигурируется. Проведем границу между \"родным функционалом\" Kafka api и \"добавками\" от Spring Boot. \nЗарегистрироваться на бесплатный вебинар\n \n ",
    "tags": [
        "kafka",
        "security"
    ]
}