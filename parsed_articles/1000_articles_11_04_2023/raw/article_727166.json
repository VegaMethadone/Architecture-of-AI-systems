{
    "article_id": "727166",
    "article_name": "Стриминговая аналитика с применением Apache Pulsar и структурированные потоки Spark",
    "content": "\r\n\n\r\n\nЭта статья написана в соавторстве Даниэлем и \nДжианнисом Полизосом\n, который ещё в 2017 году был одним из первых студентов Rock the JVM. Сейчас Джианнис – старший разработчик и контрибьютор Apache Pulsar, многообещающего нового инструментария для передачи распределённых сообщений и потоковых данных. В этой статье сочетаются два наших любимых технических инструмента: Apache Pulsar и Apache Spark.\n\r\n\n\r\nПотоковая обработка – важный и необходимый аспект современных инфраструктур данных. Сегодня компании стремятся поставить себе на службу потоковую передачу и аналитику данных в реальном времени, чтобы быстрее предоставлять пользователям результаты, повышать удобство работы с ресурсом и, соответственно, поднимать его бизнес-ценность.\n\r\n\n\r\nПримеров такого рода сколько угодно: представьте себе онлайн-сервис, предоставляющий пользователю рекомендации на основе того, какие действия пользователь совершает на веб-странице. Ещё можно представить IoT-компанию, желающую отслеживать показания сенсоров и своевременно реагировать на потенциальные сбои. К этой же категории относятся системы компьютерного зрения, которые должны в режиме реального времени анализировать видеозаписи или обнаруживать случаи мошенничества в банковских системах; этот список можно продолжать и продолжать.\n\r\n\n\r\nКак правило, в конвейерах для потоковой обработки данных требуется уровень хранения потоков, например, Apache Pulsar или Apache Kafka. Далее для выполнения более тонких задач по обработке потоков нам потребуется движок потоковых вычислений, например, Apache Flink или Spark Structured Streaming.\n\r\n\n\r\nКогда требуется обеспечить унифицированную пакетную обработку и работу с потоками в системах, развёрнутых в облаке, Apache Pulsar отлично подходит для полной технической поддержки таких вычислительных движков. Apache Pulsar предназначен для работы с облачной (cloud-native) инфраструктурой, а также сделан в расчёте на стратегии унифицированной пакетной обработки данных и работу с потоками.\n\r\n\n\r\n\n❯\n \n1. Роль Apache Pulsar в конвейеризации потоковых данных\n\r\n\nApache Pulsar превосходно справляется с хранением потоков событий и с выполнением легковесных вычислительных задач, связанных с обработкой потоков. Он замечательно подходит для долгосрочного хранения данных, а также может применяться для сохранения результатов в каких-нибудь приложениях, расположенных ниже в конвейере.\n\r\n\n\r\nДвижок для унифицированной пакетной обработки требует поддержки со стороны унифицированного уровня хранилища для пакетных и потоковых операций – только так все возможности могут быть реализованы в полном объёме.\n\r\n\n\r\nИными словами, потоковая система должна не только перемещать данные в конвейерах, но и подолгу хранить данные в потоковой форме и служить единым источником истины для обрабатывающего движка.\n\r\n\n\r\nВ том хранилище с многоуровневой архитектурой, что применяется в Apache Pulsar, данные в потоковой форме можно хранить неопределённо долго.\n\r\n\n\r\nPulsar отлично подходит для долговременного хранения данных и может применяться для сохранения результатов в каком-либо приложении, расположенном ниже по конвейеру.\n\r\n\n\r\nApache Pulsar – это распределённый журнал, рассчитанный только на запись и легко поддающийся горизонтальному масштабированию. Топики или их сегменты можно распределять по множеству брокеров, поддерживая высокую пропускную способность благодаря параллельному чтению топиков на множестве машин и по множеству сегментов.\n\r\n\n\r\nВ топиках Pulsar также применяется архитектура, выстроенная на основе сегментов — то есть, в каждом из таких топиков также содержится последовательность сегментов, в которой отдельные сегменты периодически закрываются и становятся неизменяемыми.\n\r\n\n\r\nЭти сегменты хранятся в особом механизме, поверх которого расположен Apache BookKeeper, но также могут выгружаться и в долгосрочные недорогие хранилища, например, в Amazon S3 – при этом активно используется многоуровневое хранилище Pulsar.\n\r\n\n\r\nБлагодаря такой гибкости, та архитектура хранилища данных, поверх которой расположен Pulsar, идеально подходит для пакетного доступа. Механизм пакетного доступа применим для доступа к архивным данным на выделенном уровне, а над этим уровнем расположится слой для должной потоковой обработки. Pulsar предлагает потоковые API, обеспечивающие как низкие задержки, так и высокую пропускную способность. В свою очередь, архитектура Pulsar приспособлена к поддержке современных инфраструктур данных и призвана унифицировать пакетную и потоковую обработку. Pulsar Functions – это легковесный фреймворк для бессерверной обработки потоков. Здесь обратите особое внимание на термин \nлегковесный\n.\n\r\n\n\r\nИтак, Apache Pulsar не относится к продвинутым движкам для потоковой обработки, но наделяет вас гибкостью, позволяющей реализовать много распространённых случаев потоковой обработки. Давайте немного пристальнее к ним присмотримся.\n\r\n\n\r\nPulsar Functions позволяет реализовать распространённые случаи работы с потоковыми данными, например:\n\r\n\n\r\n\nПростые варианты агрегации данных, напр., счётчики.\n\r\n\nПаттерны маршрутизации:\n\r\n\n\r\n\nДинамическая маршрутизация или маршрутизация на основе содержимого;\n\r\n\nПаттерн «Разветвитель» (Splitter).\n\r\n\n\r\n\nПреобразование сообщений:\n\r\n\n\r\n\nМаскировка данных по соображениям безопасности;\n\r\n\nНасыщение данных из внешних систем;\n\r\n\nВалидация полезной нагрузки данных;\n\r\n\nФильтрация содержимого.\n\r\n\n\r\n\nРазвёртывание и оценка моделей машинного обучения в режиме реального времени. \n\r\n\n\r\n«Легковесность» Apache Pulsar также подразумевает, что он отлично подходит для \nграничной аналитики\n — в условиях ограниченности ресурсов такой фреймворк может быть очень полезен для работы с устройствами, а подобные аналитические возможности позволяют перейти прямо к сбору данных для решения простых аналитических задач – например, для одновариантного/многовариантного анализа временных рядов.\n\r\n\n\r\nНо в тех практических случаях, когда требуются более замысловатые вычисления, например,\n\r\n\n\r\n\n\r\n\nГруппирование агрегатов\n\r\n\nОбъединение различных потоков данных\n\r\n\nПродвинутая работа с временными окнами для выполнения вычислений \n\r\n\nПоддержка продвинутых водяных знаков для обработки запаздывающих событий \n\r\n\nОбработка больших объёмов состояния\n\r\n\n\r\nприходится опираться на непростые движки для поддержки потоковых вычислений, например, Spark Structured Streaming и Apache Flink. Pulsar призван обеспечить отличную интеграцию с ними, так, чтобы можно было в полной мере использовать их продвинутые возможности.\n\r\n\n\r\n\n❯\n \n2. Разбор практического случая: вовлечение пользователя в реальном времени\n\r\nТеперь давайте подробнее (на примере) разберём, каковы роли всех этих различных компонентов в конвейере для потоковой обработки данных.\n\r\nПредставьте себе популярный интернет-магазин. Пользователь щёлкает мышью по различным товарам, добавляет позиции себе в корзину и (желательно) оформляет покупку тех или иных товаров. С точки зрения бизнеса, основанного на данных, можно представить несколько вещей, достижимых при активном использовании потоковой обработки:\n\r\n\n\r\n\n\r\n\nЕсли пользователь – это клиент-подписчик, собирающий баллы по программе лояльности. При совершении новой покупки мы, возможно, захотим рассчитать в режиме реального времени, сколько баллов лояльности собрал пользователь, а потом предложим ему большую скидку на следующую покупку.\n\r\n\nЕсли пользователь добавил в корзину несколько элементов, щёлкнул по корзине, но оформление заказа так и не завершил – то в ответ мы хотели бы послать электронное сообщение (может быть, с купоном на небольшую скидку, если данный пользователь не зарегистрирован) – и напомнить, что оформление заказа нужно завершить.\n\r\n\n\r\nВот примерное наглядное представление этого конвейера с данными:\n\r\n\n\r\n\n\r\n\n\r\nУ нас есть события, генерируемые на сайте в процессе работы, в том числе, информация о пользователе, информация о товаре, а также информация о пользовательских щелчках (соответствующих событиях). Обратите внимание, что топики с информацией о пользователе и о товаре компактифицируются. Это означает, что мы указываем ключ для топика, и такой ключ служит уникальным идентификатором каждого пользователя (или товара).\n\r\n\n\r\nНас интересуют только самые последние значения из этих записей, и именно это мы получаем из компактифицированного топика: последнее обновление для каждой записи, извлекаемое по ключу.\n\r\n\n\r\n\nРассмотрим задание Spark, объединяющее множество потоков данных. Теперь на секунду вообразите, что данные о пользователе или товаре мы будем хранить не в топиках Pulsar, а во внешней базе данных, например, в MySQL.\n\r\n\n\r\nВ таком сценарии, возможно, было бы целесообразнее применить Pulsar Function, которая читала бы записи и подыскивала во внешней системе необходимую информацию о пользователе и товаре, а затем подхватывала бы её.\n\r\n\n\r\n\n❯\n \n3. Сочленение Apache Pulsar/Spark\n\r\nВернёмся к разбору нашего примера и подробнее рассмотрим реализацию корзины заказов, где пользователь забросил оформление покупки. При этом нам потребуется скомбинировать Apache Pulsar и Spark Structured Streaming.\n\r\n\n\r\nЧтобы интегрировать Apache Pulsar и Apache Spark, воспользуемся библиотекой \npulsar-spark connector\n, которую разработала и поддерживает StreamNative.\n\r\n\n\r\nПервым делом мы должны настроить зависимости в рамках нашего проекта – так что давайте добавим в наш файл \nbuild.sbt\n следующий код:\n\r\n\n\r\n\nlazy val sparkVersion       = \"3.2.0\"\nlazy val circeVersion       = \"0.14.1\"\nlazy val pulsar4sVersion    = \"2.8.1\"\nlazy val pulsarSparkVersion = \"3.1.1.3\"\n\nval ingestionDependencies = Seq(\n  \"com.clever-cloud.pulsar4s\" % \"pulsar4s-core_2.12\"  % pulsar4sVersion,\n  \"com.clever-cloud.pulsar4s\" % \"pulsar4s-circe_2.12\" % pulsar4sVersion\n)\n\nval analysisDependencies = Seq(\n  \"io.circe\"                    %%  \"circe-core\"                  %   circeVersion,\n  \"io.circe\"                    %%  \"circe-generic\"               %   circeVersion,\n  \"io.circe\"                    %%  \"circe-parser\"                %   circeVersion,\n  \"org.apache.spark\"            %%  \"spark-sql\"                   % sparkVersion,\n  \"io.streamnative.connectors\"  %   \"pulsar-spark-connector_2.12\" % pulsarSparkVersion\n)\n\nlibraryDependencies ++= ingestionDependencies ++ analysisDependencies\n\r\nДопустим, внутри Pulsar у нас будут следующие события, связанные с щелчками мыши (для данного примера они сгенерированы синтетически):\n\r\n\n\r\n\n----- got message -----\nkey:[536638900], properties:[], content:{\"eventTime\":1572559255,\"eventType\":\"view\",\"productId\":1307519,\"categoryId\":2053013558920217191,\"categoryCode\":\"computers.notebook\",\"brand\":\"acer\",\"price\":\"1209.55\",\"userId\":536638900,\"userSession\":\"e1e8125d-da26-49ee-a6fa-78b3ff8dc341\"}\n----- got message -----\nkey:[532364121], properties:[], content:{\"eventTime\":1572559256,\"eventType\":\"view\",\"productId\":12708937,\"categoryId\":2053013553559896355,\"categoryCode\":\"\",\"brand\":\"michelin\",\"price\":\"72.72\",\"userId\":532364121,\"userSession\":\"0a899268-31eb-46de-898d-09b2da950b24\"}\n----- got message -----\nkey:[513998949], properties:[], content:{\"eventTime\":1572559256,\"eventType\":\"view\",\"productId\":50600085,\"categoryId\":2134905044833666047,\"categoryCode\":\"auto.accessories.compressor\",\"brand\":\"laston\",\"price\":\"113.93\",\"userId\":513998949,\"userSession\":\"a7b196d9-afe5-4dc8-9648-d578fef55abf\"}\n----- got message -----\nkey:[544501248], properties:[], content:{\"eventTime\":1572559256,\"eventType\":\"view\",\"productId\":1003316,\"categoryId\":2053013555631882655,\"categoryCode\":\"electronics.smartphone\",\"brand\":\"apple\",\"price\":\"928.38\",\"userId\":544501248,\"userSession\":\"e330d051-37ad-4dc3-b1ee-ff16a28b7998\"}\n----- got message -----\nkey:[515240495], properties:[], content:{\"eventTime\":1572559256,\"eventType\":\"view\",\"productId\":30000218,\"categoryId\":2127425436764865054,\"categoryCode\":\"construction.tools.welding\",\"brand\":\"magnetta\",\"price\":\"254.78\",\"userId\":515240495,\"userSession\":\"0253151d-5c84-4809-ba02-38ac405494e1\"}\n----- got message -----\nkey:[566280567], properties:[], content:{\"eventTime\":1572559258,\"eventType\":\"view\",\"productId\":1004322,\"categoryId\":2053013555631882655,\"categoryCode\":\"electronics.smartphone\",\"brand\":\"huawei\",\"price\":\"334.37\",\"userId\":566280567,\"userSession\":\"8cd74350-34e7-423b-ab02-53108a89354b\"}\n----- got message -----\nkey:[559033632], properties:[], content:{\"eventTime\":1572559258,\"eventType\":\"view\",\"productId\":22700084,\"categoryId\":2053013556168753601,\"categoryCode\":\"\",\"brand\":\"force\",\"price\":\"244.28\",\"userId\":559033632,\"userSession\":\"fe9544f7-0c09-4c85-a2f7-1d978a2710be\"}\n----- got message -----\nkey:[531148230], properties:[], content:{\"eventTime\":1572559259,\"eventType\":\"view\",\"productId\":1004767,\"categoryId\":2053013555631882655,\"categoryCode\":\"electronics.smartphone\",\"brand\":\"samsung\",\"price\":\"242.63\",\"userId\":531148230,\"userSession\":\"57a91bce-a1fb-4609-bb26-d53430dc6618\"}\n\r\nНа Scala это можно смоделировать в виде событий в следующей форме:\n\r\n\n\r\n\ncase class Event(userid: String,\n                 eventTime: Long,\n                 eventType: String,\n                 productId: String,\n                 categoryId: String,\n                 categoryCode: String,\n                 brand: String,\n                 price: Double,\n                 userSession: String)\n\nobject Event {\n  def empty(): Event = Event(\"\", 0L, \"\" , \"\", \"\", \"\", \"\", 0.0, \"\")\n}\n\n\r\nВ нашей простой реализации, приводимой для примера, считаем, что процесс оформления заказа \nзаброшен\n, если в рамках пользовательского сеанса у нас есть события cart, но нет событий \npurchase\n. Мы собираемся проталкивать события в Pulsar, а затем считывать и анализировать их при помощи.\n\r\n\n\r\nДавайте разберём их по очереди.\n\r\n\n\r\n\n3.1. Продьюсер: Pulsar\n\r\nСымитируем эти события так, как описано в следующей \nвводной статье\n по Pulsar. Сначала обустроим контейнер Docker, в котором будет выполняться Pulsar:\n\r\n\n\r\n\ndocker run -it \\\n  -p 6650:6650 \\\n  -p 8080:8080 \\\n  --name pulsar \\\n  apachepulsar/pulsar:2.8.0 \\\n  bin/pulsar standalone\n\r\n\n\r\nА в другом окне терминала создадим топик events, который будет принимать наши значения:\n\r\n\n\r\n\ndocker exec -it pulsar bash\nbin/pulsar-admin topics create events \n\r\nТеперь в нашем приложении на Scala нужно настроить продьюсер Pulsar. Исходя из того, что \nмы сможем без труда выполнить синтаксический разбор наших данных\n (в данном случае – из файла с рандомизированными реалистичными данными), требуется предусмотреть необходимую обвязку для Pulsar:\n\r\n\n\r\n\nimport com.sksamuel.pulsar4s.{DefaultProducerMessage, EventTime, MessageId, ProducerConfig, PulsarClient, Topic}\nimport com.sksamuel.pulsar4s.circe._\nimport io.circe.generic.auto._\nimport io.circe.{Decoder, Encoder, Json, Printer}\nimport org.apache.pulsar.client.api.Schema\nimport org.apache.pulsar.common.schema.{SchemaInfo, SchemaType}\n\nlazy val topicName      = \"events\"\nlazy val eventsFilePath = \"src/main/resources/events.csv\"\nlazy val serviceUrl     = \"pulsar://localhost:6650\"\nlazy val adminUrl       = \"http://localhost:8080\"\nlazy val producerName   = \"event-producer\"\nlazy val threadPoolSize = 4\n\n// events parsed elsewhere\nval events: List[Event] = loadEvents(eventsFilePath, withHeader = true)\n\nval pulsarClient = PulsarClient(serviceUrl)\nval topic = Topic(topicName)\n\nval eventProducer = pulsarClient.producer[Event](\n  ProducerConfig(\n    topic,\n    producerName = Some(producerName),\n    enableBatching = Some(true),\n    blockIfQueueFull = Some(true)\n  )\n)\n\n\r\nПосле этого нам потребуется обработать все события из списка, асинхронно отправив их в Pulsar. Ниже в общих чертах показано, как примерно это будет выглядеть:\n\r\n\n\r\n\nval messageIdFutures: Seq[Future[MessageId]] = events.map { event =>\n  Thread.sleep(10)\n  \n  // marshal an event for Pulsar\n  val message: DefaultProducerMessage[Event] = DefaultProducerMessage[Event](\n    Some(event.userid),\n    event,\n    eventTime = Some(EventTime(event.eventTime)))\n  \n  //send it\n  val messageIdFuture = eventProducer.sendAsync(message)\n\n  // being quite verbose to track messages\n  messageIdFuture.onComplete {\n    case Success(id) => println(s\"Ack received for message with id '$id'.\")\n    case Failure(exception) => println(s\"Failed to sent message - Reason: $exception\")\n  }\n\n  // keep the Future for analysis at the source, e.g. check message IDs\n  messageIdFuture\n}\n\n\r\nЗатем можно воспользоваться полученными в результате Futures для отслеживания ID сообщений и для проверки того, успешно ли прошла отправка, т. д. В данном демо-примере мы просто закроем приложение, как только эта работа будет завершена.\n\r\n\n\r\n\nFuture.sequence(messageIdFutures) // turn the Seq[Future[...]] into Future[Seq[...]]\n  .andThen {\n    case Success(_) => println(\"Producer finished sending event records.\")\n    case Failure(e) => println(s\"A failure occurred. Check the logs and the stack trace: $e\")\n  }\n  .andThen { \n    case _ => eventProducer.close()\n  }\n\r\n\n3.2. Потребитель: Spark Structured Streaming\n\r\nSpark Structured Streaming — это движок для потоковых вычислений, предоставляющий более продвинутые возможности, которые пригодятся нам в нашем практическом случае:\n\r\n\n\r\n\n\r\n\nПоддержка сеансовых окон – можно создавать сеансовые окна, основываясь на идентификаторах eventTime и userSession.\n\r\n\nПоддержка агрегирования groupBy – мы хотим агрегировать eventTypes в пользовательских сеансовых окнах.\n\r\n\nПоддержка водяных знаков – позволяет обрабатывать запаздывающие события.\n\r\n\nФильтрация по сложным типам данных – фильтруем строки в зависимости от фильтрационного предиката, выставленного для списка.\n\r\n\n\r\nКогда все зависимости будут на месте, давайте сначала подключимся к Pulsar и начнём считывать события из топика events.\n\r\n\n\r\n\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.streaming.OutputMode\n\nval clickEventsDF = spark\n        .readStream\n        .format(\"pulsar\")\n        .option(\"service.url\", \"pulsar://localhost:6650\")\n        .option(\"admin.url\", \"http://localhost:8080\")\n        .option(\"topic\", \"events\")\n        // the following two configs are optional for this demo but important if you're doing authenticated data access\n        .option(\"pulsar.client.authPluginClassName\",\"org.apache.pulsar.client.impl.auth.AuthenticationToken\")\n        .option(\"pulsar.client.authParams\",\"token:you-token<>\")\n        .load()\n\r\nМожно с лёгкостью подключиться к Pulsar при помощи Spark через соединительные URL, имя входного топика, а также воспользовавшись безопасным методом на ваш выбор, если активирован механизм безопасности. Полный список доступных конфигурационных опций приводится в Github \nконнектора Pulsar\n.\n\r\n\n\r\nКогда соединение установлено, преобразуем данные в такой пользовательский тип, который удобно анализировать:\n\r\n\n\r\n\ncase class AnalysisEvent(userSession: String, userId: String, eventTime: Timestamp, eventType: String)\n\nimport spark.implicits._\n\nval parsedEvents = clickEventsDF\n  .selectExpr(\"CAST(value AS STRING)\").as[String]\n  .map { line =>\n    val event = io.circe.parser.decode[Event](line).getOrElse(Event.empty())\n    AnalysisEvent(event.userSession, event.userid, new Timestamp(event.eventTime), event.eventType)\n  }.as[AnalysisEvent]\n\r\nИмея такой Dataset, теперь можно примерно набросать, как будет выглядеть реализация:\n\r\n\n\r\n\n\r\n\nОтбрасываем события старше 30 минут\n\r\n\nИспользуем сеансовые окна длительностью по 80 минут,\n в Spark 3.2\n такая возможность предоставляется автоматически\n\r\n\nАгрегируем события по их типу\n\r\n\nИщем события, связанные с использованием корзины заказов\n\r\n\n\r\n\nval checkoutEvents = parsedEvents\n  .withWatermark(\"eventTime\", \"30 minutes\")\n  .groupBy(col(\"userSession\"), col(\"userId\"),  session_window(col(\"eventTime\"), \"80 minutes\"))\n  .agg(collect_list(\"eventType\").as(\"eventTypes\"))\n  .filter(array_contains(col(\"eventTypes\"),\"cart\"))\n  .select(\n    col(\"session_window.start\").as(\"sessionWindowStart\"),\n    col(\"session_window.end\").as(\"sessionWindowEnd\"),\n    col(\"userId\"),\n    col(\"userSession\"),\n    col(\"eventTypes\")\n  )\n\n\r\nВывод должен выглядеть примерно так:\n\r\n\n\r\n\n+-------------------+-------------------+---------+------------------------------------+------------------------------------------------------------------------------------------------------------------------------+\n|sessionWindowStart |sessionWindowEnd   |userId   |userSession                         |eventTypes                                                                                                                    |\n+-------------------+-------------------+---------+------------------------------------+------------------------------------------------------------------------------------------------------------------------------+\n|2019-11-01 02:21:03|2019-11-01 02:56:28|564133858|ef95cac1-6580-44f0-a10b-c7e836982154|[view, view, cart, cart, purchase, view, view, view, cart, view]                                                    |\n|2019-11-01 00:59:55|2019-11-01 01:34:27|566286947|b86c0313-d0cd-4222-888f-2ed03a1d697f|[view, view, view, cart, purchase, view]                                                                                      |\n|2019-11-01 02:22:39|2019-11-01 02:54:45|528271890|b425dd2d-dae4-4915-8e8f-b1d4d2717471|[view, cart, view, view]                                                                                                      |\n|2019-11-01 01:49:20|2019-11-01 02:21:31|553414803|5006939e-fbe7-4e1c-809c-ffa3b16eb20c|[view, view, view, cart, view]                                                                                                |\n|2019-11-01 01:54:59|2019-11-01 02:29:24|556325945|ad789442-8756-41d7-b05a-11b90124032d|[view, view, view, cart, purchase, view, cart, cart, cart, cart, cart, cart, cart, cart, cart, cart, cart]                    |\n|2019-11-01 00:37:42|2019-11-01 01:14:30|549630515|8847ab0c-1f0b-42fb-9ff4-f44b9f523b4b|[view, view, view, view, view, cart, view, view, view, view, cart, view, view, view]                                          |\n|2019-11-01 00:13:32|2019-11-01 00:44:49|563558500|e0729b6c-eafe-4b0f-9d66-6ee777d08488|[view, cart, view, view, view, view, view]                                                                                    |\n|2019-11-01 02:15:30|2019-11-01 02:49:24|512411198|64a9195f-e4ee-448f-9241-9b4d23467f5d|[view, cart, view, view, cart, view]                                                                                          |\n|2019-11-01 01:44:05|2019-11-01 02:15:30|515742799|ca33e1b9-ecf5-4b50-ba76-007248bad43d|[view, cart, cart, cart, cart, view]                                                                                          |\n|2019-11-01 00:41:39|2019-11-01 01:12:36|557332447|70c0ccdf-9452-49cc-bfa5-568096d64680|[view, cart, view]                                                                                                            |\n|2019-11-01 01:40:47|2019-11-01 02:34:50|520761071|6dad05da-a718-4f05-92bc-1ed9796404cd|[view, view, view, view, view, view, view, view, view, view, view, cart, purchase]                                            |\n|2019-11-01 00:37:04|2019-11-01 01:08:52|562200921|ca5a71f1-33c8-4fcd-b793-5fcea6f260c0|[view, cart, purchase, view]                                                                                                  |\n|2019-11-01 00:10:07|2019-11-01 00:46:10|516426931|ef4867dd-b922-4d92-abec-9a75acb2b769|[view, view, view, cart, purchase, view, cart, cart, view, view]                                                    |\n|2019-11-01 02:07:33|2019-11-01 02:45:30|554459781|c43b43dd-dc54-4d1c-bfd8-3bcbdfb94870|[view, cart, purchase, view, view]                                                                                            |\n|2019-11-01 02:11:34|2019-11-01 02:52:13|539100846|365b1088-8a4f-47e4-a6e9-e66d56b1b998|[view, cart, cart, cart, view, cart, view, view, view, view, view]                                                            |\n|2019-11-01 01:34:14|2019-11-01 02:08:51|519456951|f2136bd5-a50d-4e05-8a90-27b288065459|[view, cart, cart, purchase]                                                                                                  |\n|2019-11-01 01:47:49|2019-11-01 02:26:31|515561413|98a12974-b589-48fe-b6f5-a55cd844cdd8|[view, view, view, view, cart, view]                                                                                          |\n|2019-11-01 01:29:06|2019-11-01 02:00:39|518913698|afa1ad69-55bb-4ef8-9d02-6648596ca5ec|[view, cart, purchase, view]                                                                                                  |\n|2019-11-01 01:53:53|2019-11-01 02:36:26|556601011|45658f52-9e11-45fa-a8d6-9414d349aa4d|[view, view, view, view, view, view, cart, cart, view, view, view, view, view, view, view, view, view, view, view, view, view]|\n|2019-11-01 01:01:28|2019-11-01 01:34:04|538178630|9cf447dc-7aa8-47f2-8c3b-44318cf5608a|[view, view, view, cart, cart, cart, purchase, view]                                                                          |\n+-------------------+-------------------+---------+------------------------------------+------------------------------------------------------------------------------------------------------------------------------+\n\r\nНекоторые замечания по поводу сеансовых окон:\n\r\n\n\r\n\n\r\n\nРазмер сеансового окна подбирается автоматически в зависимости от длины окна, которая коррелирует с длиной вводимой информации.\n\r\n\nСеансовое окно запускается с началом ввода и расширяется в случае, если в пределах заданного промежутка в него поступает новый ввод.\n\r\n\nКогда такой промежуток задан статически, сеансовое окно закрывается, если заданный промежуток времени истёк, а нового ввода (с момента получения последнего ввода) так и не поступило.\n\r\n\n\r\nПри использовании сеансовых окон и группировании их по пользовательским сеансам, можно без труда проверить, есть ли у конкретного пользователя события работы с корзиной заказов при отсутствии событий покупки. Так можно легко отфильтровать события, трактуемые нами как \nнезавершенная работа с корзиной\n и перенаправить их в нижележащий топик для дальнейшей обработки. Приводя пример действия, которое здесь было бы уместно, допустим, что пользователю можно было бы направить сообщение с напоминанием (например, через мобильное сообщение, если таковое уместно, или по электронной почте) – по истечении некоторого времени, например, через час.\n\r\n\n\r\n\n3.3. Синтаксический разбор событий\n\r\nЭтот фрагмент определённо находится на периферии статьи, так как статья посвящена Pulsar и Spark, поэтому для вашего удобства привожу следующий простой код. С его помощью были разобраны события, сведённые в \nэтом csv-файле\n.\n\r\n\n\r\n\nimport java.sql.Timestamp\nimport java.util.concurrent.{ExecutorService, Executors}\nimport scala.concurrent.{ExecutionContext, Future}\nimport scala.io.BufferedSource\nimport scala.util.{Failure, Success, Try}\n\ndef loadEvents(path: String, withHeader: Boolean = false): List[Event] = {\n  val r = Try(scala.io.Source.fromFile(path))\n    .map(source => sourceHandler(source, withHeader))\n    .fold(_ => List.empty, identity)\n\n  val result = Try(scala.io.Source.fromFile(path)) match {\n    case Success(source) =>\n      Some(sourceHandler(source, withHeader))\n    case Failure(exception) =>\n      println(s\"Failed to read file '$path' - Reason: $exception\")\n      None\n  }\n\n  result.getOrElse(List.empty)\n}\n\nprivate def sourceHandler(source: BufferedSource, withHeader: Boolean): List[Event] = {\n  val events: List[Event] = source.getLines()\n    .map(toEvent)\n    .toList\n\n  if (withHeader) events.drop(1) else events\n}\n\nprivate def toEvent(line: String): Event = {\n  Try {\n    val tokens = line.split(\",\")\n    val eventTime = Timestamp.valueOf(tokens(0).replace(\" UTC\", \"\"))\n\n    Event(\n      tokens(7),\n      eventTime.getTime,\n      tokens(1),\n      tokens(2),\n      tokens(3),\n      tokens(4),\n      tokens(5),\n      tokens(6).toDouble,\n      tokens(8)\n    )\n  }.getOrElse(Event.empty())\n}\n\n\r\n\n❯\n \n4. Заключение\n\r\nВ этой статье мы рассмотрели Apache Pulsar в качестве «хребта» современной инфраструктуры данных, разобрали, какие варианты работы с потоковыми данными может поддерживать Pulsar, а также как его можно использовать в сочетании со Spark Structured Streaming для реализации сравнительно сложных вариантов потоковой обработки, требующих привлечения.\n\r\nНаконец, мы разобрали реалистичный практический случай, в котором представили образец конвейера потоковых данных и поговорили о том, какие роли в этом конвейере играют Apache Pulsar и Spark Structured Streaming.\n\r\n\n\r\n\n \n ",
    "tags": [
        "timeweb_статьи_перевод",
        "Apache Pulsar",
        "IoT",
        "Apache Kafka",
        "Apache Flink",
        "Spark Structured Streaming",
        "Apache BookKeeper",
        "Amazon S3",
        "API",
        "фреймворк",
        "MySQL",
        "StreamNative"
    ]
}