{
    "article_id": "727222",
    "article_name": "Полезные методы работы с данными в Pandas. Часть 1",
    "content": "Автор статьи: Роман Козлов\nРуководитель курса BI-аналитика  \nВведение\nСегодня анализ данных стал неотъемлемой частью многих сфер деятельности, от науки до бизнеса. Python является одним из самых популярных инструментов для работы с данными, благодаря своей гибкости и обширному спектру доступных библиотек. Одной из таких библиотек является Pandas, предоставляющая удобные структуры данных и множество функций для анализа и обработки информации.\nВ этих статьях (их будет несколько и их количество зависит от заинтересованности читателя) мы сосредоточимся на изучении некоторых полезных, но менее известных методов работы с данными в Pandas, которые могут значительно повысить вашу эффективность при анализе и обработке данных. Мы рассмотрим различные функции и техники для таких задач, как разделение данных на интервалы, квантильное разделение, применение скользящих окон для вычислений, смещение данных для временных рядов, преобразование вложенных структур данных, нормализация сложных JSON-структур и управление многоуровневыми индексами при работе с DataFrame и Series.\nИзучение этих методов расширит ваш инструментарий и позволит справляться с более сложными и специфическими задачами, связанными с обработкой и анализом данных. Вместе мы углубимся в эти методы и рассмотрим конкретные примеры их использования, чтобы вы могли применять их на практике и улучшить свои навыки в области анализа данных с помощью Pandas.\nМетод cut(). Разделение данных на интервалы в рамках RFM-анализа\nЕсли вы, как и я, часто работали с различными пользовательскими базами, то обратили внимание на то, что одной из распространенных проблем является разделение пользователей на кластеры или группы с целью определения их поведенческих особенностей, предпочтений и лояльности. Этот подход может дать возможность более эффективно управлять коммуникацией с каждой группой, а также принимать более обоснованные решения по развитию бизнеса, учитывая различия в потребностях и интересах пользователей. Кроме того, кластеризация пользователей может помочь обнаружить скрытые зависимости между различными группами пользователей, что может привести к появлению новых идей и возможностей для улучшения продукта или услуги.\nМетодика RFM-анализа (Recency, Frequency, Monetary) является одним из инструментов, позволяющих решить эту проблему. RFM-анализ разделяет пользователей на кластеры на основе трех параметров:\nRecency (R) — время с последней покупки (активности) пользователя,\nFrequency (F) — частота покупок (активности) пользователя,\nMonetary (M) — денежные траты (или доходы) пользователя.\nRFM-анализ может быть особенно полезным в случае, когда вы не знаете заранее, какие признаки наиболее важны для разделения пользователей на группы. Он позволяет определить наиболее важные параметры, которые влияют на поведение пользователей, и на основе этого провести кластерный анализ.\nКроме того, RFM-анализ может быть более прозрачным и понятным, чем многие методы машинного обучения, что позволяет даже людям без специализированного образования в области анализа данных легче понимать полученные результаты. Это делает RFM-анализ доступным для большей аудитории, что может быть особенно полезно для малых и средних предприятий, где нет возможности привлекать специалистов в области анализа данных.\nМетод \ncut()\n в Pandas может быть полезным при проведении RFM-анализа для категоризации пользователей на основе каждого из этих параметров. Основные аргументы метода \ncut()\n \n: \nx\n \n: Массив, серия или одномерный массив данных для разделения на интервалы. \nbins\n \n: Число интервалов, список границ интервалов или индекс для определения границ. \nlabels\n \n: Список меток для категорий.   \nМетод \ncut()\nв библиотеке Pandas предназначен для разделения данных на интервалы, особенно полезен при категоризации числовых данных. Этот метод позволяет создать дискретные категории из непрерывных значений, что может быть полезно в различных ситуациях анализа данных, таких как создание гистограмм, агрегация данных по группам или сегментация пользователей.\nПредположим, что у нас есть следующие данные о пользователях:\nimport pandas as pd \n\ndata = pd.DataFrame({\n  'user_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n  'recency': [5, 30, 7, 22, 45, 10, 60, 4, 11, 29],\n  'frequency': [15, 5, 25, 12, 4, 19, 3, 10, 7, 22],\n  'monetary': [100, 80, 250, 120, 50, 175, 40, 110, 60, 210]\n})\nЭти данные, безусловно, являются «игрушечными», но на них будет легче понять принцип проведения такого рода аналитики. Наша задача — из непрерывных значений показателей Recency, Monetary и Frequency получить дискретные категории \n1\n \n, \n2\n \n, и \n3\n .\n \nРазделим данные на категории с помощью метода \ncut()\n :\n   \ndata['R'] = pd.cut(data['recency'], bins=3, labels=['3', '2', '1'])\ndata['F'] = pd.cut(data['frequency'], bins=3, labels=['1', '2', '3'])\ndata['M'] = pd.cut(data['monetary'], bins=3, labels=['1', '2', '3'])\nПрисваивание меток 3, 2 и 1 при проведении RFM-анализа имеет следующий смысл:\nМетка \n3\n обозначает высокий показатель для данного параметра, то есть пользователь относится к верхней группе по данному показателю.\nМетка \n2\n обозначает средний показатель, то есть пользователь относится к средней группе по данному показателю.\nМетка \n1\n обозначает низкий показатель, то есть пользователь относится к нижней группе по данному показателю.\nКластеры пользователей, на которые мы разделяем их с помощью RFM-анализа, основаны на комбинациях этих меток для каждого из параметров Recency, Frequency и Monetary.\nНапример, пользователь с RFM-кодом \n333\n относится к самому ценному кластеру, так как этот пользователь имеет недавнюю активность (высокий Recency), высокую частоту активности (Frequency) и высокий объем денежных трат или доходов (Monetary).\nПользователь с RFM-кодом \n111\n, наоборот, будет являться менее ценным для бизнеса, так как он имеет давнюю активность, низкую частоту активности и низкий объем трат или доходов. \nВы заметили важный момент? Для показателя Recency метки идут в обратном порядке, потому что этот параметр оценивает время с последней активности пользователя, и меньшее значение Recency означает более недавнюю активность, что является положительным показателем.\nВ случае с Frequency и Monetary, большие значения означают высокую частоту активности и большие денежные траты, что также положительно, и поэтому метки идут в прямом порядке (1 — низкий, 2 — средний, 3 — высокий).\nВозвратимся к нашему коду и создадим RFM-сегменты путем объединения R, F и M меток:\ndata['RFM'] = data['R'].astype(str) + data['F'].astype(str) + data['M'].astype(str) \n\nprint(data)\n Теперь наши данные выглядят следующим образом:\nТеперь у нас есть 10 пользователей с разными значениями Recency, Frequency и Monetary. Метод \ncut()\n \nразделил эти параметры на 3 категории, и мы получили несколько RFM-сегментов пользователей, объединяя полученные метки.\nВ рамках RFM-анализа выделяются различные кластеры (сегменты) пользователей, основанные на комбинации меток R, F и M. Некоторые из наиболее общих сегментов включают:\nЦенные пользователи ( \n333\n \n): это пользователи с наиболее недавней активностью, высокой частотой и высокими денежными тратами. Они представляют особый интерес для бизнеса и должны получать больше внимания и лучшие предложения. \nНовые пользователи с потенциалом ( \n313\n \nили \n3x3\n \n): эти пользователи недавно активировались и уже потратили приличную сумму денег, но их частота активности все еще низкая. Их стоит стимулировать совершать больше активностей. \nУгасающие пользователи ( \n1x1\n \n): это пользователи с давней активностью, низкой частотой и низкими денежными тратами. Они представляют наименьший интерес для бизнеса, и с ними стоит работать только в рамках общих маркетинговых кампаний. \nВернувшиеся пользователи ( \n13x\n \n): эти пользователи имели давнюю активность, но недавно вернулись и проявили высокую активность и/или денежные траты. Им следует предложить специальные акции или скидки, чтобы удержать их и превратить в лояльных пользователей. \nЛояльные пользователи ( \nx3x\n \n): пользователи с высокой частотой активности, независимо от их недавности и денежных трат. Им стоит предложить программы лояльности или специальные акции, чтобы поддерживать их интерес. \nБольшие траты ( \nxx3\n \n): пользователи с высокими денежными тратами, независимо от их недавности и частоты активности. Их можно мотивировать с помощью персонализированных предложений, скидок на основе суммы покупок или эксклюзивных продуктов.\nСпящие пользователи ( \n1x3\n \n): пользователи с высокими денежными тратами и частотой активности в прошлом, но давней активностью. Для их возвращения можно использовать реактивационные кампании, напоминающие о преимуществах и предложениях компании. \nДля разделения полученных данных с показателем RFM на описанные выше сегменты, сначала добавим новую колонку \nSegment\n в наш DataFrame \ndata\n \n. \nЗатем присвоим каждой строке значение сегмента на основе соответствующих условий.\ndef assign_segment(row): \n    rfm = row['RFM']\n    if rfm == '333':\n        return 'Ценные пользователи' \n    elif rfm[0] == '3' and rfm[2] == '3':\n        return 'Новые пользователи с потенциалом' \n    elif rfm == '111':\n        return 'Угасающие пользователи' \n    elif rfm[0] == '1' and rfm[1] == '3':\n        return 'Вернувшиеся пользователи' \n    elif rfm[1] == '3':\n        return 'Лояльные пользователи' \n    elif rfm[2] == '3':\n        return 'Большие траты'\n    elif rfm[0] == '1' and rfm[1] == '3': \n        return 'Спящие пользователи'\n    else:\n        return 'Другие'\n\ndata['Segment'] = data.apply(assign_segment, axis=1) \n\nprint(data)\nПосле выполнения этого кода, в DataFrame \ndata\n \nпоявится новая колонка \nSegment\n \n, содержащая сегменты пользователей на основе их показателя RFM. \nОбратите внимание, что мы также включили сегмент «Другие» для пользователей, которые не попадают ни в один из описанных выше сегментов. Это позволяет учесть все возможные комбинации меток RFM и гарантирует, что каждый пользователь будет отнесен к определенному сегменту.\nСегмент «Другие» может быть дополнительно уточнен путем введения более точных правил сегментации, которые учитывают специфические особенности бизнеса и пользовательской базы. Вместо того, чтобы использовать обобщенный сегмент «Другие», можно определить новые сегменты, основанные на комбинациях показателей RFM, которые наиболее актуальны для конкретной отрасли или организации.\nКроме того, названия сегментов могут различаться и выбираются аналитиком, исходя из конкретных особенностей анализируемых данных и целей анализа. Главное выбирать названия сегментов, которые точно отражают их характеристики, и могут быть легко поняты и интерпретированы заказчиками и другими членами команды.\nМетод qcut(). Квантильное разделение данных\nПри использовании метода \ncut()\n для разделения данных на интервалы можно заметить, что данные могут быть разделены неравномерно. Это происходит потому, что метод \ncut()\n \nразбивает данные на равные интервалы на основе значений показателей, не учитывая их распределение. Если в данных присутствуют выбросы или они имеют неравномерное распределение, это может привести к несбалансированному количеству пользователей в каждом интервале. \nЭто можно заменить, если применить метод \nvalue_counts() \nк каждому из показателей Recency, Frequency и Monetary:\ndata['R'].value_counts(),data['F'].value_counts(),data['M'].value_counts()\nЧтобы добиться более равномерного распределения сегментов, можно воспользоваться методом \nqcut()\n \n. Вместо разделения данных на равные интервалы по значениям, \nqcut()\nразделяет данные на квантили, гарантируя равное количество пользователей в каждом интервале.\ndata['R_qcut'] = pd.qcut(data['recency'], q=3, labels=['3', '2', '1'])\ndata['F_qcut'] = pd.qcut(data['frequency'], q=3, labels=['1', '2', '3'])\ndata['M_qcut'] = pd.qcut(data['monetary'], q=3, labels=['1', '2', '3'])\nВ данном случае, мы применяем метод \nqcut()\n \nдля разделения данных на три квантиля (\nq=3\n) по каждому из показателей: Recency, Frequency и Monetary. \nЗатем, мы присваиваем метки \n['3', '2', '1']\n \nдля обозначения высоких, средних и низких значений соответственно. \nКвантили — это статистические показатели, которые разделяют набор данных на равные части. Квантили включают квартили (25%, 50% и 75%), децили (каждые 10%) и процентили (каждые 1%). В данном случае, мы разделили показатели на 3 равных отрезка с границами приблизительно находящимися на отметках 33,3% и 66,7%.\nМожно посмотреть на границы квантилей с помощью функции \nquantile()\n \n: \nrecency_quantiles = data['recency'].quantile([1/3, 2/3]) \nfrequency_quantiles = data['frequency'].quantile([1/3, 2/3]) \nmonetary_quantiles = data['monetary'].quantile([1/3, 2/3])\n\nprint(\"Recency quantiles:\", recency_quantiles) \nprint(\"Frequency quantiles:\", frequency_quantiles) \nprint(\"Monetary quantiles:\", monetary_quantiles)\nНа примере показателя Recency, видим, что граница находящаяся на отметке 33,3% делит наши данные на те, что больше или меньше 10, а граница на отметке 66,7% — больше или меньше 29.\nЕсли мы повторно воспользуемся \nvalue_counts ()\n, то увидим, что теперь распределение данных между показателями Recency, Frequency, Monetary стало равномерным:\ndata['R_qcut'].value_counts(),data['F_qcut'].value_counts(),data['M_qcut'].value_counts()\n \nИспользование методов \ncut()\n \nи \nqcut()\n для сегментации пользователей имеет свои преимущества и недостатки, и выбор между ними зависит от конкретных целей исследования и качества сами данных в пользовательской базе.\nМетод\ncut()\nхорошо подходит для равномерно распределенных данных и может обеспечить хорошую сегментацию пользователей. Данные при этом будут разделены на равные интервалы, что удобно для интерпретации и визуализации данных.\nМетод \nqcut()\n \nпредпочтительнее, когда важно обеспечить равномерное распределение данных по сегментам, особенно для неравномерно распределенных данных или данных с выбросами. Однако, интервалы, созданные с помощью \nqcut()\n, могут быть непостоянными и сложными для интерпретации, особенно если данные имеют сложную структуру.   \nЗаключение\nИспользование методов \ncut() \nи \nqcut()\nможет быть полезно для сегментации пользовательских баз в рамках RFM-анализа, поскольку эти методы позволяют быстро и эффективно группировать пользователей на основе важных показателей, таких как Recency, Frequency и Monetary. Они просты в применении, легко интерпретируются и не требуют сложных вычислений или знаний в области машинного обучения.\nВ сравнении c построением моделей машинного обучения, методы \ncut()\n и \nqcut()\n могут предложить более непосредственный и интуитивно понятный способ сегментации пользователей. Модели машинного обучения, такие как кластеризация, могут быть сложными и требовательными к ресурсам, а также могут потребовать дополнительных данных или предварительной обработки. В то время как \ncut()\n и\nqcut()\nпозволяют сегментировать пользователей на основе их поведения, не требуя обучения модели или настройки гиперпараметров.\nОднако стоит отметить, что методы \ncut()\n и \nqcut()\nне всегда могут заменить модели машинного обучения, особенно когда имеется сложная структура данных или требуется более глубокий анализ. В этих случаях модели машинного обучения могут быть более точными и прогностически эффективными. Тем не менее, для быстрой и простой сегментации пользователей в рамках RFM-анализа методы  \ncut()\n и \nqcut()\n представляют собой прекрасный инструмент, который может быть полезным для многих аналитиков и маркетологов.\nВ следующей статье мы подробно рассмотрим применение скользящих окон для вычислений и смещение данных для анализа временных рядов.\nСкользящие окна позволяют проводить агрегированные вычисления на подмножествах данных, что может быть полезно для определения трендов, сезонности и аномалий во временных рядах. Мы также изучим использование смещения данных для создания лаговых переменных и их применение в различных задачах прогнозирования. Эти методы являются важными инструментами для аналитиков и помогут лучше понять и предсказать динамику каких-либо процессов или явлений.\nВ заключение порекомендую \nоткрытый урок\n «Как начать учить SQL с нуля и не разочароваться», который пройдет в OTUS и будет особенно полезным для тех, кто хотя бы раз задумывался о переходе в сферу дата-аналитики. На этом уроке участники рассмотрят азы теории, познакомятся с доступными тренажерами и инструментами, а также напишут свои первые SQL-запросы. Записаться на занятие можно \nна странице онлайн-курса «Аналитик данных».\n \n ",
    "tags": [
        "анализ данных",
        "pandas",
        "sql",
        "работа с данными"
    ]
}