{
    "article_id": "726454",
    "article_name": "Titanic Survivors Data Research",
    "content": "Предисловие автора\nДанную статью я решил написать в качестве своей первой основательной работы по анализу данных и созданию предиктивной модели на базе нейронных сетей. Все упоминающиеся в тексте файлы можно найти в \nрепозитории этой работы на GitHub\n.\nВ данной статье исследованы данные пассажиров Титаника (предоставленные в рамках ML-соревнования на \nkaggle.com\n [1]), сделаны и проверены предположения о влиянии определённых факторов на вероятность человека выжить в той катастрофе. Анализ данных сопровождается примерами кода на Python, с использованием пакета Pandas. Построена и обучена модель нейронной сети, предсказывающая вероятность человека выжить в катастрофе с точностью 0.78 на тестовых данных из [1]. Модель построена на базе фреймворка pyTorch.\nСодержание\nВведение\nАнализ данных\n \nИсходные данные\nФакторы, влияющие на шансы выжить\nПол и класс каюты\nВозраст\nИмена и возраст\nНомер каюты\nРодственники на борту\nБилеты и порт отправления\nПостроение модели\n \nФормирование признаков (features)\nData preprocessing\nСтруктура нейронной сети\nОбучение\nЗаключение\nСписок источников\nВведение \n15 апреля 1912 года произошло крушение парохода «Титаник», став одной из самых значимых катастроф в истории человечества. За сто лет с момента затопления лайнера, в мире накопилось множество данных и работ по этой теме. На сайте \nKaggle.com\n существует соревнование [1], в основе которого лежат данные о пассажирах с Титаника. Катастрофа сложилась так, что некоторые пассажиры выживали с большим шансом, чем другие, и это отражено в данных, полученых в рамках соревнования.\nЦелью данной работы является создание предиктивной модели, которая на основе данных о пассажире сможет предсказать, выжил он после крушения Титаника или нет. В первом разделе будет рассмотрен разведовательный анализ исходных данных пассажиров, а также проектирование признаков для последующего использования в модели машинного обучения. Второй раздел включает в себя подготовку данных, описание структуры используемой модели, результаты обучения модели.\nАнализ данных \nЦелью раздела \"Анализ данных\" является разведовательный анализ данных, выявление и проверка гипотез, инжиниринг признаков (feature engineering) для модели машинного обучения.\nВсе примеры кода и графика продублированы из файла \nData_Investigation.ipynb\n.\nИсходные данные \nИсходные данные представлены в виде .csv файла, образующего таблицу (891 строка, 12 столбцов), представленную на рисунке 1 ниже. Мы можем наблюдать следующие данные для каждого из пассажиров: класс, полное имя, пол, возраст, количество родственников супруг+братья\\сестры, количество родственников родители+дети, номер билета, стоимость билета, номер каюты, порт отправления, выжил пассажир или нет.\nimport pandas as pd\n\n# Считаем файл с данными\ndf = pd.read_csv('train.csv')\n# Взглянем на данные!\ndf\n\nРисунок 1 - Исходные данные\nСразу отметим следующие особенности этих данных (виузализацию см. в файле \nData_Investigation.ipynb\n):\nПропущено около 20% данных о возрасте пассажиров.\nПропущено около 80% данных о каютах пассажиров.\nУ 15 пассажиров нулевая стоимость билетов.\nУ 2 пассажиров отсутствует порт отправления.\nУ 4 пассажиров нет номеров билетов.\nФакторы, влияющие на шансы выжить \nЗа более чем сто лет с момента катастрофы, было проведено множество исследований, в том числе статистических. В [2] и [3] описаны ключевые моменты, влияющие на выживаемость пассажиров:\nПол\n (выжило 75% женщин и 16% мужчин [2]).\nВозраст\n (выжило 52% детей [2]).\nКласс каюты\n (выжило из 1 класса 62%, из 2 - 41%, из 3 - 25% [2]).\nПервое и второе обусловлено тем, как проводилась эвакуация пассажиров. По приказу капитана в первую очередь в шлюпки сажали женщин и детей [4, 5].\nВлияние класса на выживаемость выражалось в общей привелегированности 1 класса над вторым и третьим, и второго класса над третьим [2]. Конкретно стоить отметить, что:\nКаюты 1 класса располагались ближе всего к палубе [2].\nПервый класс обслуживали 2 лифта, второй класс - 1 лифт, третий класс лифты не обслуживали вообще [2].\nНа пароходе не было системы оповещения, поэтому о необходимости эвакуироваться людям сообщали стюарды. Причем в 1 классе на одного стюарда приходилось всего несколько кают, а во 2 и 3 - много больше [7]. В первом классе стюарды имели возможность лично помочь и выпроводить каждого пассажира [7], а в третьем классе стюарды просто выбивали двери в каюты [6], и сообщали о том, что нужно выбираться на палубу.\nДалее рассмотрено влияние отдельных факторов на выживаемость в рамках исследуемых данных.\nПол и класс каюты \nПосчитаем общее количество и количество выживших для мужчин и женщин, визуализируем на диаграмме.\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Посчитаем общее количество мужчин и женщин, а также количество выживших\nmales_total = len(df.loc[(df['Sex'] == 'male')])\nfemales_total = len(df.loc[(df['Sex'] == 'female')])\nmales_survived = len(df.loc[((df['Sex'] == 'male') & (df['Survived'] == 1))])\nfemales_survived = len(df.loc[((df['Sex'] == 'female') & (df['Survived'] == 1))])\n\n#Визуализируем\nsurvivors_counts = {\n    'Выжили': [males_survived, females_survived],\n    'Погибли': [males_total-males_survived, females_total-females_survived]\n}\n\nfig, ax = plt.subplots()\nbottom = np.zeros(2)\n\nfor key, count in survivors_counts.items():\n    p = ax.bar(('Мужчины', 'Женщины'), count, width=0.6, label=key, bottom=bottom)\n    bottom += count\n    ax.bar_label(p, label_type='center')\n\nax.set_title('Распределение выживших в зависимости от пола')\nax.set_ylabel('Количество человек')\nax.legend()\nplt.show()\n\nРисунок 2 - Распределение выживших в зависимости от пола\nВ процентном соотношении получаем числа, аналогичные упомянутым ранее [2, 3]:\nВыжило мужчин: 18.89%\nВыжило женщин: 74.2%\nПостроим аналогичную диаграмму для различных классов каюты (код см. в файле \nData_Investigation.ipynb\n).\n \nРисунок 3 - Распределение выживших в зависимости от класса каюты\nВ процентном соотношении:\nВыжило из 1 класса: 62.96%\nВыжило из 2 класса: 47.28%\nВыжило из 3 класса: 24.24%\nТаким образом, пол и класс каюты будут одними из ключевых факторов (и признаков для модели), влияющих на вероятность выжить.\nВозраст \nРассмотрим распределение пассажиров по возрастам, а также распределение выживших, мужчин и женщин по возрастам.\nfrom collections import Counter\n\n#Выберем списки пассжиров в отдельные группы\nsurvivors = df.loc[(df['Survived'] == 1)]\nmale_survivors = df.loc[((df['Sex'] == 'male') & (df['Survived'] == 1))]\nfemale_survivors = df.loc[((df['Sex'] == 'female') & (df['Survived'] == 1))]\n\n#Число возрастов\nnum_of_ages = len(dict(Counter(survivors['Age'])).keys())\n\n#Визуализируем\nfig, axs = plt.subplots(2,2)\nfig.set_figwidth(20)\nfig.set_figheight(10)\nnames = [['Все пассажиры', 'Выжившие'], ['Выжившие мужчины', 'Выжившие женщины']]\nfor i, surv in enumerate([[df, survivors], [male_survivors, female_survivors]]):\n    for j, subsurv in enumerate(surv):\n        axs[i][j].hist(subsurv['Age'], bins=num_of_ages)\n        axs[i][j].set_title(names[i][j])\n        axs[i][j].set_xlabel('Возраст, лет')\n        axs[i][j].set_ylabel('Количество человек')\n        axs[i][j].set_ylim(0,30)\n        axs[i][j].set_xlim(0,70)\nplt.show()\n\nРисунок 4 - Распределение пассажиров по возрастам\nНа каждой диаграмме можно заметить 2 характерные моды: одна соответствует детям, а другая людям с возрастом 20-30 лет. Причем на всех диаграммах распределение сохраняет свой характер, хоть при этом и смещается μ, падают амплитуды. Видно, что в зависимости от возраста количество выживших значительно разнится, поэтому возраст будет важным признаком при построении модели.\n Попробуем также убедиться, что большая часть детей спаслись.\nimport numpy as np\n\nchildren = df.loc[((df['Age'] < np.float64(18.0)) & (df['Age'] > 0))]\nsurvivors_children = df.loc[((df['Age'] < np.float64(18.0)) & (df['Survived'] == 1) & (df['Age'] > 0))]\nprint(f'Пасажиров до 18 лет спаслось {round(len(survivors_children)*100/len(children), 2)}%')\n\nПасажиров до 18 лет спаслось 53.98%.\\\nДействительно, более половины детей спаслось. Причём, если мы еще раз посмотрим на диаграммы, то видно, что больше всего спаслось детей до 5 лет.\ndf.loc[((df['Survived'] == 1) & (df['Age'] > 0) & (df['Age'] < 18))].Age.hist()\n\nРисунок 5 - Распределение выживших среди детей\nИмена и возраст \nИмена пассажиров содержат характерные для 1912 годп приставки, такие как \"Mr\", \"Mrs\", \"Miss\", \"Sir\", \"Master\" и другие. Эти приставки отражают информацию о возрасте и статусе человека [8]. Автор [9] в ходе своего анализа данных пассажиров \"Титаника\" подтвердил, что статус человека, отражённый в имени, тесно коррелирует с возрастом, и эту взаимосвязь можно использовать для определения возраста пассажиров, возраст которых в исходных данных пропущен. Отобразим зависимость возраста от титула в виде набора коробчатых диаграмм.\n#Перечень титулов\ntitles = (\"Capt.\",\"Col.\",\"Major.\",\"Sir.\",\"Lady.\",\"Rev.\",\"Dr.\",\"Don.\",\"Jonkheer.\",\"Countess.\",\"Mrs.\",\"Ms.\",\"Mr.\",\"Mme.\",\"Mlle.\",\"Miss.\",\"Master.\")\n\n#Создадим список титулов для каждого пассажира\ntitled_names = []\nfor name in df.Name:\n    for title in titles:\n        if title in name.split(' '):\n            titled_names.append(title)\n            break\n\n\n#Добавим в датафрейм новый столбец - Титул\ndf.insert(12, 'Title', titled_names)\n\n#Создадим словарь с парами \"титул: список возрастов\"\nages = dict.fromkeys(titles, [])\nfor i, title in enumerate(df.Title):\n    if not pd.isna(df.Age[i]):\n        ages[title] = ages[title] + [df.Age[i]]\n\n#Визуализируем\nfig, ax = plt.subplots(figsize=(15,5))\nax.boxplot(ages.values(), labels=titles, vert=True)\nax.set_ylabel('Возраст')\nplt.show()\n\nРисунок 6 - Распределение по возрастам для каждого титула\nПрежде, чем восстанавливать отсутствующие возраста, рассмотрим отдельно пассажиров без указания возраста. Возраст людей может быть неизвестен не только потому, что они его изначально не сообщили, но и потому что погибли и не смогли сообщить его после катастрофы. Посмотрим на соотношение погибших и выживших среди этих пассажиров, а также на соотношение мужчин и женщин среди пассажиров без возраста.\nnoage = df.loc[(pd.isna(df['Age']))]\nfig, ax = plt.subplots(1, 2, figsize=(10,5))\nax[0].hist(noage.Survived, bins=2, cumulative=-1)\nax[1].hist(noage.Sex, bins=2)\nax[0].set_ylabel('Кол-вол выживших')\n\nРисунок 7 - Соотношение погибших и выживших среди людей без указания возраста\nМожно увидеть, что среди пассажиров без возраста больше погибших потому, что среди них больше мужчин. Однако разумно будет добавить в данные признак \nhave_age\n, отражающий наличие\\отсутствие указания возраста пассажира, поскольку у мужчины без указания возраста шансы погибнуть будут еще больше, чем просто у мужчины, это должно прибавить точности модели.\nВосстановим возраста, используя медиану среди пассажиров с соответствующим титулом.\nfor i, age in enumerate(df.Age):\n    if pd.isna(age):\n        df.Age[i] = np.median(ages[df.Title[i]])\n\nВыживаемость в зависимости от титула\n Автор [9] также предложил распределить титулы в 5 групп: Aristocratic, Mr, Mrs, Miss и Master (объединяя вместе родственные [8] группы), а затем посмотреть на выживаемость среди пассажиров с разным титулом.\n# Группы для объединения\naristocratic = (\"Capt.\", \"Col.\", \"Don.\", \"Dr.\",\n                \"Jonkheer.\", \"Lady.\", \"Major.\",\n                \"Rev.\", \"Sir.\", \"Countess.\")\nmrs = (\"Ms.\")\nmiss = (\"Mlle.\", 'Mme.')\n\n# Объединяем титулы\nfor i, title in enumerate(df.Title):\n    if title in aristocratic:\n        df.Title[i] = 'Aristocratic.'\n    elif title in miss:\n        df.Title[i] = 'Miss.'\n    elif title in mrs:\n        df.Title[i] = 'Mrs.'\n\n# В данном случае будет удобно посмотреть на долю выживших, так как количество людей в каждом из титулов значительно разнится\ntitle_survive_percent = dict.fromkeys(set(df.Title), None)\nfor title in title_survive_percent.keys():\n    title_survive_percent[title] = len(df.loc[((df['Title'] == title) & (df['Survived'] == 1))]) / len(df.loc[(df['Title'] == title)])\n\n#Визуализируем\nfig, ax = plt.subplots()\nax.bar(title_survive_percent.keys(), title_survive_percent.values())\nax.set_ylabel('Доля выживших')\nax.set_title('Выживаемость в зависимости от титула пассажира')\nplt.show()\n\nРисунок 8 - Доля выживших в зависимости от титула\nВидно, что титул даёт информацию о вероятности выжить, так что он будет иметь значение при построении модели.\nНомер каюты \nСреди номеров каюты пропущены данные для 80% пассажиров. Восстановить эти данные не представляется возможным. Для тех же пассажиров, для которых номер каюты известен, можно было бы извлечь номер палубы и на каком борту была каюта (буква в номере соответствует палубе, нечетные номера соответствуют левому борту [7]). Однако, учитывая малое количество данных, это существенно не повлияет на точность модели [9].\nСведения о каютах пассажиров стали известны благодаря списку, найденному на теле погибшего стюарта Герберта Кейва, причем в список были включены только пассажиры первого класса [10]. Это означает, что значение может иметь само наличие или отсутствие данных о каюте пассажира.\n# Выделим пассажиров в группы\nhave_cabin = df.loc[(pd.notna(df['Cabin']))]\nhave_cabin_survived = df.loc[((pd.notna(df['Cabin'])) & (df['Survived'] == 1))]\nno_cabin = df.loc[(pd.isna(df['Cabin']))]\nno_cabin_survived = df.loc[((pd.isna(df['Cabin'])) & (df['Survived'] == 1))]\n\n# Визуализируем долю выживших\nfig, ax = plt.subplots()\nax.bar(('Есть номер', 'Нет номера'), (len(have_cabin_survived)/len(have_cabin), len(no_cabin_survived)/len(no_cabin)))\nax.set_ylabel('Доля выживших')\nax.set_title('Выживаемость в зависимости от наличия каюты')\nplt.show()\n\nРисунок 9 - Доля выживших в зависимости от наличия номера кабины\nДействительно, видим, что наличие номера кабины у пассажира влияет на выживаемость. В [9] автор также рассматривает этот признак в разрезе по полу и классу каюты, и значимость признака подтверждается.\nРодственники на борту \nРазличные авторы сходятся на том, что признаки \"Родители+дети\" и \"Супруг+братья\\сестры\" стоит объединить в один признак \"Семья\", а также добавить признак \"Пассажир путешествовал один\" [9, 11, 12, 13, 14]. Чтобы составить собственное представление о влиянии этих признаков на выживаемость, построим диаграммы выживаемости для каждого из таких признаков, а затем взглянем на них через призму таблицы корреляции.\n# Добавим признак family\n#df.insert(13, 'Family', np.array(df.SibSp, int) + np.array(df.Parch, int))\n\n\nsibsp_total = dict(Counter(df.SibSp))\nparch_total = dict(Counter(df.Parch))\nfamily_total = dict(Counter(df.Family))\nsibsp_survived = dict(Counter(df.loc[(df['Survived'] == 1)].SibSp))\nparch_survived = dict(Counter(df.loc[(df['Survived'] == 1)].Parch))\nfamily_survived = dict(Counter(df.loc[(df['Survived'] == 1)].Family))\nrelatives = (family_total, sibsp_total, parch_total)\nrelatives_survived = (family_survived, sibsp_survived, parch_survived)\n\nfig, axs = plt.subplots(1, 3, figsize=(15,5))\nxlabs = ('Полное число родственников', 'Супруг+братья\\сестры', 'Родители+дети')\n\nfor i in range(3):\n    probs = []\n    for rel, amount in relatives_survived[i].items():\n        probs.append(amount / relatives[i][rel])\n    axs[i].bar(relatives_survived[i].keys(), probs)\n    axs[i].set_ylabel('Доля выживших')\n    axs[i].set_xlabel(xlabs[i])\nplt.show()\n\nРисунок 10 - Доля выживших для пассажиров с разным количеством родственников\nimport seaborn as sns\n\n# Добавим признак is_alone\nis_alone = []\nfor fam in df.Family:\n    if fam == 0:\n        is_alone.append(1)\n    else:\n        is_alone.append(0)\ndf.insert(14, 'is_alone', is_alone)\n\n# Correlation heatmap\nsns.heatmap(df[['Survived', 'SibSp', 'Parch', 'Family', 'is_alone']].corr(), annot=True, vmin=-1, vmax=1, cmap=sns.diverging_palette(0, 500, as_cmap=True))\n\nРисунок 11 - Таблица корреляции \"семейных\" параметров и выживаемости\nКак видно из гистограмм и таблицы выше, количество родственников хоть и влияет на выживаемость, но по отдельности коррелируют слабо. Будет разумно оставить только признак 'Family' и 'is_alone'.\nБилеты и порт отправления \nСтоимость билета, очевидно, будет коррелировать с классом каюты, а следовательно, влиять на вероятность выжить. Построим таблицу корреляции.\nsns.heatmap(df[['Survived', 'Fare', 'Pclass']].corr(), annot=True, vmin=-1, vmax=1)\n\nРисунок 12 - Корреляция выживаемости, класса каюты, стоимости билета\nСтоимость билета оказывается хорошим признаком, влияющим на выживаемость. В дальнейшем также очистим этот признак от выбросов. А теперь построим диаграмму с распределением по стоимости билетов для каждого класса.\nfare = dict.fromkeys((1,2,3), [])\nfor i, price in enumerate(df.Fare):\n    fare[df.Pclass[i]] = fare[df.Pclass[i]] + [price]\n\n\nfig, ax = plt.subplots(figsize=(15,5))\nax.boxplot(fare.values(), labels=(1,2,3), vert=True)\nax.set_ylabel('Стоимость билета')\nax.set_xlabel('Класс каюты')\nax.set_ylim(-5, 250)\nplt.show()\n\nРисунок 13 - Распределение стоимости билетов для разных классов каюты\nИз коробчатых диаграмм видно, что для каждого из классов есть своё характерное распределение по стоимости. Заменим билеты с нулевой стоимостью на медианную стоимость для соответствующего класса.\nfor i, fare in enumerate(df.Fare):\n    if np.isclose(fare, .0):\n        df.Fare[i] = np.median(fares[df.Pclass[i]])\n\n«Здесь и ранее - идея заменять пропущенные значения какими-то усредненными величинами обосновывается стремлением оставить распределение данных примерно таким же, и не генерировать граничных/экстремальных значений, т.к. подобные выбросы могли бы увести алгоритмы прогнозирования в сторону от реального решения, давая не существующие ориентиры [14].»\nНомер билета не несёт информации, способствующей предсказанию выживаемости, поэтому формировать какие-либо признаки на его основе не будем.\nПропущенные два значения порта отправления заменим на средние, тем более, что номер билета подсказывает такое же значение порта.\nfor i, emb in enumerate(df.Embarked):\n    if pd.isna(emb): df.Embarked[i] = 'S'\n\nПостроение модели \nФормирование признаков (features) \nПол, класс каюты, возраст, наличие возраста, титул, наличие номера кабины, количество членов семьи, один ли пассажир, стоимость билета, порт отправления\nВ ходе анализа были отобраны качественные признаки для модели. Такими стали: Sex, Pclass, Age, Have_Age, Title(векторизованно), Have_Cabin, Family, Is_Alone, Fare, Embarked(векторизованно).\nСледующий код конвертирует исходные данные в датасет признаков для тренировочного и тестового наборов.\nimport pandas as pd\nimport numpy as np\n\nTITLES = (\"Capt.\",\"Col.\",\"Major.\",\"Sir.\",\"Lady.\",\"Rev.\",\"Dr.\",\"Don.\",\"Jonkheer.\",\"Countess.\",\"Mrs.\",\"Ms.\",\"Mr.\",\"Mme.\",\"Mlle.\",\"Miss.\",\"Master.\", \"Dona.\")\nARISTOCRATIC = (\"Capt.\", \"Col.\", \"Don.\", \"Dr.\",\n                \"Jonkheer.\", \"Lady.\", \"Major.\",\n                \"Rev.\", \"Sir.\", \"Countess.\", 'Dona')\nMRS = (\"Ms.\")\nMISS = (\"Mlle.\", 'Mme.')\n\nfor file in ('train', 'test'):\n\n    # Считываем файл\n    dataset = pd.read_csv(f'{file}.csv')\n\n    # Кодируем пол\n    dataset = dataset.replace({'female' : 1, 'male': 0})\n\n    # Восстанавливаем стоимость билетов\n    dataset.Fare.fillna(0, inplace = True)\n    fares = dict.fromkeys((1,2,3), [])\n    for i, price in enumerate(dataset.Fare):\n        fares[dataset.Pclass[i]] = fares[dataset.Pclass[i]] + [price]\n    for i, fare in enumerate(dataset.Fare):\n        if np.isclose(fare, .0):\n            dataset.loc[i, 'Fare'] = np.median(fares[dataset.Pclass[i]])\n\n    #Создадим список титулов для каждого пассажира\n    titled_names = []\n    for name in dataset.loc[:, 'Name']:\n        for title in TITLES:\n            if title in name.split(' '):\n                titled_names.append(title)\n                break\n\n    # Вставляем в датасет столбец Title\n    dataset.insert(1, 'Title', titled_names)\n\n    #Создадим словарь с парами \"титул: список возрастов\"\n    ages = dict.fromkeys(TITLES, [])\n    for i, title in enumerate(dataset.Title):\n        if not pd.isna(dataset.Age[i]):\n            ages[title] = ages[title] + [dataset.Age[i]]\n            \n    # Создаем признак Семья\n    dataset['Family'] = dataset.Parch + dataset.SibSp\n\n    # Кодируем бинарные признаки\n    dataset['Is_Alone'] = dataset.Family == 0\n    dataset['Have_Cabin'] = pd.notna(dataset.Cabin)\n    dataset['Have_age'] = pd.notna(dataset.Age)\n    dataset = dataset.replace({True: 1, False: 0})\n\n    # Восстанавливаем пропущенные возраста\n    for i, age in enumerate(dataset.loc[:, 'Age']):\n        if pd.isna(age):\n            dataset.loc[i, 'Age'] = np.median(ages[dataset.Title[i]])\n\n    # Объединяем титулы\n    for i, title in enumerate(dataset.Title):\n        if title in ARISTOCRATIC:\n            dataset.loc[i, 'Title'] = 'Aristocratic.'\n        elif title in MISS:\n            dataset.loc[i, 'Title'] = 'Miss.'\n        elif title in MRS:\n            dataset.loc[i, 'Title'] = 'Mrs.'\n\n    # Восстанавливаем порт отправления\n    dataset.Embarked.fillna(dataset.Embarked.mode()[0], inplace = True)\n\n    # Кодируем порт и титулы\n    dataset = dataset.join(pd.get_dummies(dataset.Embarked, prefix='Emb'))\n    dataset = dataset.join(pd.get_dummies(dataset.Title, prefix='Title'))\n\n    # Чистим от лишних столбцов\n    dataset = dataset.drop(columns=['Ticket', 'Name', 'SibSp', 'Parch', 'Cabin', 'Title', 'Embarked'])\n\n    # Перемещаем столбец Survived в конец\n    try:\n        dataset.insert(dataset.shape[1] - 1, 'Survived', dataset.pop('Survived'))\n    except KeyError:\n        ...\n\n    dataset.to_csv(f'clear_{file}.csv', index=False)\n\nПостроим таблицу корреляции всех отобранных признаков.\ntrain_set = pd.read_csv('clear_train.csv')\n\nfig, ax = plt.subplots(figsize=(15,15))\nsns.heatmap(train_set.corr(), annot=True, vmin=-1, vmax=1, ax=ax)\n\nРисунок 14 - Таблица корреляции отобранных признаков\nData preprocessing \nДля того, чтобы изначально повысить эффективность обучения, нормализуем данные. Для этого объединим тренировочный и тестовый набор в один датафрейм и используем следующую формулу для преобразования ячеек в каждом столбце.\nРисунок 15 - Формула для нормализации данных\nНормализация реализована в файле \ndata_functions.py\n в виде следующей функции.\ndef normalize_data(train_vector: np.ndarray, test_vector: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n\n    train_arr, test_arr = train_vector, test_vector\n    united_arr = np.concatenate((train_arr, test_arr))\n\n    mean = np.mean(united_arr, axis=0)\n    std_deviation = np.std(united_arr, axis=0)\n\n    train_X = (train_arr - mean) / std_deviation\n    test_X = (test_arr - mean) / std_deviation\n\n    return train_X, test_X\n\nДля загрузки данных в модель создадим класс на основе структуры Dataset из pyTorch (см. файл \ndata_functions.py\n).\nСтруктура нейронной сети \nСтруктура выбранной сети выглядит следующим образом:\nВходной слой: 16 нейронов (соответствует размерности входных данных).\nПервый скрытый слой: 512 нейронов (с применением функции активации ReLU).\nБатч-нормализация с 512 признаками.\nDropout-слой с вероятностью исключения нейронов 0.3 (30%).\nВторой скрытый слой: 2048 нейронов (с применением функции активации ReLU).\nDropout-слой с вероятностью исключения нейронов 0.3 (30%).\nТретий скрытый слой: 512 нейронов (с применением функции активации ReLU).\nDropout-слой с вероятностью исключения нейронов 0.3 (30%).\nВыходной слой: 2 нейрона (с применением функции активации Softmax).\nВ коде эта нейросеть описана следующим образом (файл \nnetworks.py\n):\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n\n        self.layer_1 = nn.Linear(16, 512)\n        self.b_norm = nn.BatchNorm1d(512)\n        self.layer_2 = nn.Linear(512, 2048)\n        self.layer_3 = nn.Linear(2048, 512)\n        self.layer_4 = nn.Linear(512, 2)\n\n        self.dropout = nn.Dropout(0.3)\n\n    def forward(self, x):\n        x = self.layer_1(x)\n        x = F.relu(x)\n        x = self.dropout(x)\n        x = self.b_norm(x)\n\n        x = self.layer_2(x)\n        x = F.relu(x)\n        x = self.dropout(x)\n\n        x = self.layer_3(x)\n        x = F.relu(x)\n        x = self.dropout(x)\n\n        x = self.layer_4(x)\n        x = F.softmax(x)\n\n        return x\n\nВизуализация структуры нейронной сети:\nРисунок 16 - Схема, отображающая структуру использованной нейронной сети\nНейронная сеть состоит из трех полносвязных слоев, между которыми расположены слои для регуляризации и нормализации. Техники батч-нормализации и Dropout использованы для предотвращения переобучения (overfitting). В выходном слое применяется функция активации Softmax для получения вероятностного распределения между двумя классами (выжил/погиб).\nОбучение \nОбучение нейросети проводилось в файле \nlearning.py\n. С выбранной структурой нейронной сети, наибольших успехов на тестовых данных удалось достичь со следующими параметрами обучения. \nТочность на валидационной выборке составила более 0.9\n.\nПараметр\nЗначение\nОписание\nnum_epochs\n1500\nКоличество эпох обучения\nbatch_size\n64\nРазмер пакета данных (batch)\nlearning_rate\n0.01\nСкорость обучения (learning rate)\nweight_decay\n0.01\nКоэффициент уменьшения весов (L2 регуляризация)\nvalidation_split\n0.1\nДоля данных, выделенных для валидации\noptimizer\nAdam\nТип оптимизатора\nannealing_factor\n0.6\nФактор уменьшения скорости обучения (LR annealing)\nloss_function\nCrossEntropyLoss\nТип функции потерь\nВ процессе обучения был использован LR Annealing, для которого задан фактор уменьшения скорости обучения 0.6 и количество эпох (patience) равное 100. Если значение функции потерь не уменьшалось в течение 100 эпох, скорость обучения уменьшалась на заданный фактор.\nДалее представлены графики обучения сети с заданной структурой и параметрами. После \nэтого обучения\n, на тестовых данных сеть показала точность \n0.787\n.\nРисунок 17 - Точность на тренировочных данных в ходе тренировки\nРисунок 18 - Точность на валидационной выборке в ходе тренировки\nРисунок 19 - Значение функции потерь  в ходе тренировки\nРисунок 20 - Значение функции потерь на валдационной выборке в ходе тренировки\nЗаключение \nВ работе был проведен анализ данных пассажиров парохода \"Титаник\", выявлено влияние различных факторов на вероятность человека выжить в катастрофе. Выбранные факторы обработаны и преобразованы для использования в нейронной сети. После построения и обучения модели нейросети на предоставленных данных результативность обученной модели на тестовых данных составила 0.78.\nКлючевые факторы, влияющие на выживаемость пассажиров Титаника, были определены следующими: пол пассажира, возраст, класс каюты, наличие номера каюты, количество родственников на борту, путешествовал ли пассажир в одиночку. Использование нейросетевой модели позволило учесть сложные взаимодействия между этими факторами и предсказать вероятность выживания каждого пассажира с приемлемой точностью.\nДля возможного улучшения модели, можно дополнительно исследовать исходные данные, попробовать включать и не включать различные из отобранных признаков, рассмотреть различные архитектуры нейронных сетей, варьировать гиперпараметры обучения, а также попробовать другие алгоритмы машинного обучения, такие как решающие деревья или алгоритмы на основе ансамбля, в целях увеличения точности предсказания выживаемости.\nСписок источников \nKaggle. Titanic: Machine Learning from Disaster [Электронный ресурс]. — Режим доступа: \nhttps://www.kaggle.com/competitions/titanic/\n. — Дата обращения: 02.04.2022.\nРахманов, А. В. Катастрофа Титаника: социально-классовая структура и шансы на спасение / А. В. Рахманов // Вестник Московского университета. Серия 18. Социология и политология. — 2016. — № 22. — С. 62-82.\nEncyclopedia Titanica. Titanic Statistics [Электронный ресурс]. — Режим доступа: \nhttps://www.encyclopedia-titanica.org/titanic-statistics.html\n. — Дата обращения: 02.04.2022.\nGleicher, D. The Rescue of the Third Class on the Titanic: A Revisionist History / David Gleicher. — International Maritime Economic History Association, 2006. — (Research in Maritime History, No. 31). — ISBN 978-0-9738934-1-0.\nЛорд, У. A Night to Remember / Уолтер Лорд. — Нью-Йорк: St. Martin's Griffin, 2005. — ISBN 978-0-8050-7764-3.\nBarczewski, S. Titanic: A Night Rememb / Stephanie Barczewski. — Лондон: Continuum International Publishing Group, 2006. — ISBN 978-1-85285-500-0.\nГубачек, М. С. Титаник / Милош Губачек. — Минск: Попурри, 2000. — 656 с. — ISBN 978-985-15-1679-3.\nВикипедия. English honorifics [Электронный ресурс]. — Режим доступа: \nhttps://en.wikipedia.org/wiki/English_honorifics\n. — Дата обращения: 02.04.2022.\nХабр. Титаник на Kaggle: вы не дочитаете этот пост до конца [Электронный ресурс]. — Режим доступа: \nhttps://habr.com/en/company/mlclass/blog/270973/\n. — Дата обращения: 02.04.2022.\nEncyclopedia Titanica. The Cave List [Электронный ресурс]. — Режим доступа: \nhttps://www.encyclopedia-titanica.org/the-cave-list.html\n. — Дата обращения: 02.04.2022.\nХабр. Разбор задачи Титаник на Kaggle (Baseline) [Электронный ресурс]. — Режим доступа: \nhttps://habr.com/en/post/655955/\n. — Дата обращения: 02.04.2022.\nITnan. Kaggle и Titanic — еще одно решение задачи с помощью Python [Электронный ресурс]. — Режим доступа: \nhttps://itnan.ru/post.php?c=1&p=274171\n. — Дата обращения: 02.04.2022.\nNeurohive. Разбор решения задачи «Титаник» на Kaggle для начинающих [Электронный ресурс]. — Режим доступа: \nhttps://neurohive.io/ru/osnovy-data-science/razbor-resheniya-zadachi-titanik-na-kaggle-dlya-nachinajushhih/\n. — Дата обращения: 02.04.2022.\nKaggle. Titanic Solution - a Beginner's Guide (Russian) [Электронный ресурс]. — Режим доступа: \nhttps://www.kaggle.com/code/adavydenko/titanic-solution-a-beginner-s-guide-russian/\n. — Дата обращения: 02.04.2022.\n \n ",
    "tags": [
        "python",
        "pytorch",
        "kaggle",
        "titanic",
        "neural networks",
        "data analysis"
    ]
}