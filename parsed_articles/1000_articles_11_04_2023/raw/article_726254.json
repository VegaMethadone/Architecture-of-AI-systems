{
    "article_id": "726254",
    "article_name": "Основы генеративно-состязательных сетей",
    "content": "Что такое GAN и что они могут делать?\nНа высоком уровне GAN — это нейронные сети, которые учатся генерировать реалистичные образцы данных, на которых они обучались. Например, имея фотографии рукописных цифр, GAN узнают, как создавать реалистичные фотографии большего количества рукописных цифр. Что еще более впечатляюще, GAN могут даже научиться создавать реалистичные фотографии людей, такие как приведенные ниже.\nЧеловеческие лица, сгенерированные GAN. Ни одно из вышеперечисленных лиц не является реальным  \nТак как же работают GAN? По сути, GAN изучают распределение интересующего объекта. Например. GAN, обученные рукописным цифрам, изучают распределение данных. Как только распределение данных изучено, GAN может просто выбрать из распределения для создания реалистичных изображений.  \nРаспространение данных\nЧтобы укрепить наше понимание распределения данных, давайте рассмотрим следующий пример. Предположим, что у нас есть следующие 6 изображений ниже.\nКаждое изображение представляет собой сероватый прямоугольник, и для простоты предположим, что каждое изображение состоит всего из 1 пикселя. Другими словами, в каждом изображении есть только один сероватый пиксель.\nТеперь предположим, что каждый пиксель имеет возможное значение от -1 до 1, где белый пиксель имеет значение -1, а черный пиксель имеет значение 1. Таким образом, 6 серых изображений будут иметь следующие значения пикселей:\nЧто мы знаем о распределении значений пикселей? Что ж, просто проверив, мы знаем, что большинство значений пикселей около 0, а несколько значений приближаются к крайним значениям (-1 и 1). Поэтому мы можем предположить, что распределение является гауссовским со средним значением 0.  \nПримечание. При наличии большего количества выборок получить гауссово распределение этих данных тривиально, вычислив среднее значение и стандартное отклонение. Однако это не является нашей целью, поскольку рассчитать распределение данных по сложным объектам сложно, в отличие от этого простого примера.\n  \nБазовое распределение нашего пикселя — это распределение Гаусса со средним значением 0.  \nЭто распределение данных полезно, потому что оно позволяет нам генерировать больше серых изображений, как 6 выше. Чтобы создать больше похожих изображений, мы можем случайным образом выбрать из распределения.  \n10 пикселей, нарисованных случайным образом и независимо от распределения Гаусса. Обратите внимание, что большинство значений пикселей близки к среднему (0), с небольшими выбросами на краях (-1 и 1).  \nХотя вычисление лежащего в основе распределения серых пикселей может быть тривиальным, вычисление распределения кошек, собак, автомобилей или любого другого сложного объекта часто оказывается математически неразрешимым.\nКак же тогда мы изучаем базовое распределение сложных объектов? Очевидный ответ — использовать нейронные сети. Имея достаточно данных, мы можем научить нейронную сеть изучать любую сложную функцию, например базовое распределение данных.\nГенератор — модель обучения распределению\nВ GAN генератор — это нейронная сеть, которая изучает базовое распределение данных. Чтобы быть более конкретным, генератор принимает в качестве входных данных случайное распределение (также известное как «шум» в литературе по GAN) и изучает функцию отображения, которая отображает входные данные в желаемый результат, который является фактическим базовым распределением данных.\nОднако обратите внимание, что в приведенной выше архитектуре отсутствует ключевой компонент. Какую функцию потерь мы должны использовать для обучения генератора? Как мы узнаем, действительно ли сгенерированные изображения напоминают настоящие рукописные цифры? Как всегда, ответ « \nиспользуйте нейронную сеть\n ». Эта вторая сеть известна как дискриминатор.\nДискриминатор — противник Генератора\nРоль дискриминатора состоит в оценке качества выходных изображений генератора. Технически дискриминатор представляет собой двоичный классификатор. Он принимает изображения в качестве входных данных и выводит вероятность того, что изображение является реальным (т. е. фактическим тренировочным изображением) или фальшивым (т. е. полученным от генератора).\nСначала генератор изо всех сил пытается создать изображения, которые выглядят реальными, и дискриминатор может легко отличить настоящие изображения от поддельных, не делая слишком много ошибок. Поскольку дискриминатор является двоичным классификатором, мы можем количественно оценить производительность дискриминатора, используя потери двоичной кросс-энтропии .  \nПотери дискриминатора являются важным сигналом для генератора. Напомним ранее, что генератор сам по себе не знает, похожи ли сгенерированные изображения на реальные. Однако генератор может использовать потери BCE дискриминатора в качестве сигнала для получения обратной связи для сгенерированных им изображений.\nВот как это работает. Мы отправляем изображения, выдаваемые генератором, в дискриминатор, и он предсказывает вероятность того, что изображение реально. Первоначально, когда генератор плохой, дискриминатор может легко классифицировать изображения как поддельные, что приводит к низким потерям BCE. Однако со временем генератор улучшается, и дискриминатор начинает делать больше ошибок, ошибочно классифицируя поддельные изображения как настоящие, что приводит к более высоким потерям BCE. Следовательно, потеря BCE дискриминатора сигнализирует о качестве изображения, выводимого генератором, и генератор стремится максимизировать эту потерю.\nГенератор использует потери дискриминатора как показатель качества сгенерированных им изображений. Задача генератора состоит в том, чтобы настроить свои веса таким образом, чтобы потери BCE от дискриминатора были максимальными, эффективно «обманывая» дискриминатор.  \nТренировка дискриминатора\nА как же дискриминатор? До сих пор мы предполагали, что у нас с самого начала есть отлично работающий дискриминатор. Однако это предположение неверно, и дискриминатор также требует обучения.\nПоскольку дискриминатор является бинарным классификатором, процедура его обучения проста. Мы предоставим дискриминатору набор помеченных реальных и поддельных изображений и будем использовать потери BCE для настройки весов дискриминатора. Мы обучаем дискриминатор распознавать настоящие и поддельные изображения, предотвращая «обман» дискриминатора генератором.\nGAN — история о двух сетях\nДавайте теперь соберем все вместе и посмотрим, как работают GAN.\nАрхитектура базовой GAN  \nК настоящему времени вы знаете, что GAN состоят из двух взаимосвязанных сетей, генератора и дискриминатора. В обычных GAN генераторы и дискриминаторы представляют собой простые нейронные сети с прямой связью.  \nЧто уникально для GAN, так это то, что генератор и дискриминатор обучаются по очереди, враждебно друг другу.  \nДля обучения генератора мы используем в качестве входных данных вектор шума, выбранный из случайного распределения. На практике мы используем вектор длины 100, взятый из гауссовского распределения, в качестве вектора шума. Входные данные проходят через ряд полностью связанных слоев в нейронной сети с прямой связью. Выход генератора — это изображение, которое в нашем примере MNIST представляет собой \n28x28\nмассив. Генератор передает свой вывод дискриминатору и использует потери BCE дискриминатора для настройки своих весов с целью максимизации потерь дискриминатора.\nДля обучения дискриминатора мы используем помеченные изображения из генератора, а также реальные изображения в качестве входных данных. Дискриминатор учится классифицировать изображения как настоящие или поддельные и обучается с помощью функции потерь BCE.\nНа практике мы обучаем генератор и дискриминатор по очереди, один за другим. Эта схема обучения похожа на минимаксную состязательную игру для двух игроков, поскольку генератор стремится максимизировать \nпотери\n дискриминатора, а дискриминатор стремится \nминимизировать\n свои собственные потери.\nСоздание собственной ГАН\nТеперь, когда мы понимаем теорию, лежащую в основе GAN, давайте применим ее на практике, создав собственную GAN с нуля с помощью PyTorch!\nПрежде всего, давайте добавим набор данных MNIST. Библиотека \ntorchvision\nпозволяет нам легко получить набор данных MNIST. Мы выполним некоторую стандартную нормализацию изображений перед сведением \n28x28\nизображений MNIST к \n784\nтензору. Это выравнивание необходимо, поскольку слои в сети являются полностью связанными слоями.\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, datasets\n\nmnist_transforms = transforms.Compose([transforms.ToTensor(),\n                                       transforms.Normalize(mean=0.5, std=0.5),\n                                       transforms.Lambda(lambda x: x.view(-1, 784))])\n\ndata = datasets.MNIST(root='/data/MNIST', download=True, transform=mnist_transforms)\n\nmnist_dataloader = DataLoader(data, batch_size=128, shuffle=True, num_workers=4) \nДалее давайте напишем код для класса генератора. Из того, что мы видели ранее, генератор — это просто нейронная сеть с прямой связью, которая принимает \n100\nтензор длины и выдает \n784\nтензор. В генераторе размер плотных слоев обычно удваивается после каждого слоя (256, 512, 1024).  \nclass Generator(nn.Module):\n  '''\n  Generator class. Accepts a tensor of size 100 as input as outputs another\n  tensor of size 784. Objective is to generate an output tensor that is\n  indistinguishable from the real MNIST digits \n  '''\n  \n  def __init__(self):\n    super().__init__()\n    self.layer1 = nn.Sequential(nn.Linear(in_features=100, out_features=256),\n                                nn.LeakyReLU())\n    self.layer2 = nn.Sequential(nn.Linear(in_features=256, out_features=512),\n                                nn.LeakyReLU())\n    self.layer3 = nn.Sequential(nn.Linear(in_features=512, out_features=1024),\n                                nn.LeakyReLU())\n    self.output = nn.Sequential(nn.Linear(in_features=1024, out_features=28*28),\n                                nn.Tanh())\n\n  def forward(self, x):\n    x = self.layer1(x)\n    x = self.layer2(x)\n    x = self.layer3(x)\n    x = self.output(x)\n    return x\nЭто было легко, не так ли? Теперь давайте напишем код для класса дискриминатора. Дискриминатор также представляет собой нейронную сеть с прямой связью, которая принимает \n784\nтензор длины и выдает тензор размера \n1\n, обозначающий вероятность того, что входные данные принадлежат классу 1 (реальное изображение). В отличие от генератора, мы уменьшаем вдвое размер плотных слоев после каждого слоя (1024, 512, 256).  \nclass Discriminator(nn.Module):\n  '''\n  Discriminator class. Accepts a tensor of size 784 as input and outputs\n  a tensor of size 1 as  the predicted class probabilities\n  (generated or real data)\n  '''\n\n  def __init__(self):\n    super().__init__()\n    self.layer1 = nn.Sequential(nn.Linear(in_features=28*28, out_features=1024),\n                                nn.LeakyReLU())\n    self.layer2 = nn.Sequential(nn.Linear(in_features=1024, out_features=512),\n                                nn.LeakyReLU())\n    self.layer3 = nn.Sequential(nn.Linear(in_features=512, out_features=256),\n                                nn.LeakyReLU())\n    self.output = nn.Sequential(nn.Linear(in_features=256, out_features=1),\n                                nn.Sigmoid())\n    \n  def forward(self, x):\n    x = self.layer1(x)\n    x = self.layer2(x)\n    x = self.layer3(x)\n    x = self.output(x)\n    return x\nТеперь мы собираемся создать класс GAN, который включает в себя как класс генератора, так и класс дискриминатора. Этот класс GAN будет содержать код для обучения генератора и дискриминатора по очереди, в соответствии со схемой обучения, которую мы обсуждали ранее. Мы собираемся использовать для этого \nPyTorch Lightning\n , чтобы упростить наш код и сократить шаблонный код. \nimport pytorch_lightning as pl\n\nclass GAN(pl.LightningModule):\n\n  def __init__(self):\n    super().__init__()\n    self.generator = Generator()\n    self.discriminator = Discriminator()\n    # After each epoch, we generate 100 images using the noise\n    # vector here (self.test_noises). We save the output images\n    # in a list (self.test_progression) for plotting later.\n    self.test_noises = torch.randn(100,1,100, device=device)\n    self.test_progression = []\n\n  def forward(self, z):\n    \"\"\"\n    Generates an image using the generator\n    given input noise z\n    \"\"\"\n    return self.generator(z)\n\n  def generator_step(self, x):\n    \"\"\"\n    Training step for generator\n    1. Sample random noise\n    2. Pass noise to generator to\n       generate images\n    3. Classify generated images using\n       the discriminator\n    4. Backprop loss to the generator\n    \"\"\"\n    \n    # Sample noise\n    z = torch.randn(x.shape[0], 1, 100, device=device)\n\n    # Generate images\n    generated_imgs = self(z)\n\n    # Classify generated images\n    # using the discriminator\n    d_output = torch.squeeze(self.discriminator(generated_imgs))\n\n    # Backprop loss. We want to maximize the discriminator's\n    # loss, which is equivalent to minimizing the loss with the true\n    # labels flipped (i.e. y_true=1 for fake images). We do this\n    # as PyTorch can only minimize a function instead of maximizing\n    g_loss = nn.BCELoss()(d_output,\n                           torch.ones(x.shape[0], device=device))\n\n    return g_loss\n\n  def discriminator_step(self, x):\n    \"\"\"\n    Training step for discriminator\n    1. Get actual images\n    2. Predict probabilities of actual images and get BCE loss\n    3. Get fake images from generator\n    4. Predict probabilities of fake images and get BCE loss\n    5. Combine loss from both and backprop loss to discriminator\n    \"\"\"\n    \n    # Real images\n    d_output = torch.squeeze(self.discriminator(x))\n    loss_real = nn.BCELoss()(d_output,\n                             torch.ones(x.shape[0], device=device))\n\n    # Fake images\n    z = torch.randn(x.shape[0], 1, 100, device=device)\n    generated_imgs = self(z)\n    d_output = torch.squeeze(self.discriminator(generated_imgs))\n    loss_fake = nn.BCELoss()(d_output,\n                             torch.zeros(x.shape[0], device=device))\n\n    return loss_real + loss_fake\n\n  def training_step(self, batch, batch_idx, optimizer_idx):\n    X, _ = batch\n\n    # train generator\n    if optimizer_idx == 0:\n      loss = self.generator_step(X)\n    \n    # train discriminator\n    if optimizer_idx == 1:\n      loss = self.discriminator_step(X)\n\n    return loss\n\n  def configure_optimizers(self):\n    g_optimizer = torch.optim.Adam(self.generator.parameters(), lr=0.0002)\n    d_optimizer = torch.optim.Adam(self.discriminator.parameters(), lr=0.0002)\n    return [g_optimizer, d_optimizer], []\n\n  def training_epoch_end(self, training_step_outputs):\n    epoch_test_images = self(self.test_noises)\n    self.test_progression.append(epoch_test_images)\nТеперь мы можем обучить наш GAN. Мы будем обучать его с помощью графического процессора в течение 100 эпох.\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = GAN()\n\ntrainer = pl.Trainer(max_epochs=100, gpus=1)\ntrainer.fit(model, mnist_dataloader)\nВизуализация сгенерированных изображений\nОсталось только визуализировать сгенерированные изображения. В \ntraining_epoch_end()\nфункции из нашего класса GAN выше мы сохраняли изображения, выводимые генератором после каждой эпохи обучения, в список.\nМы можем визуализировать эти изображения, нанеся их на сетку. Приведенный ниже код случайным образом выбирает 10 изображений, сгенерированных после 100-й эпохи обучения, и наносит их на сетку.\nimport numpy as np\nfrom matplotlib import pyplot as plt, gridspec\n\n# Convert images from torch tensor to numpy array\nimages = [i.detach().cpu().numpy() for i in model.test_progression]\n\nepoch_to_plot = 100\nnrow = 3\nncol = 8\n\n# randomly select 10 images for plotting\nindexes = np.random.choice(range(100), nrow*ncol, replace=False)\n\nfig = plt.figure(figsize=((ncol+1)*2, (nrow+1)*2)) \nfig.suptitle('Epoch {}'.format(epoch_to_plot), fontsize=30)\n\ngs = gridspec.GridSpec(nrow, ncol,\n         wspace=0.0, hspace=0.0, \n         top=1.-0.5/(nrow+1), bottom=0.5/(nrow+1), \n         left=0.5/(ncol+1), right=1-0.5/(ncol+1)) \n\nfor i in range(nrow):\n    for j in range(ncol):\n        idx = i*ncol + j\n        img = np.reshape(images[epoch_to_plot-1][indexes[idx]], (28,28))\n        ax = plt.subplot(gs[i,j])\n        ax.imshow(img, cmap='gray')\n        ax.axis('off')\nНаконец, как и было обещано, мы создадим анимацию, показанную вверху поста. Используя \nFuncAnimation\nфункцию в \nmatplotlib\n, мы будем анимировать изображения на графике кадр за кадром.  \nimport numpy as np\nfrom matplotlib import pyplot as plt, gridspec, rc\nfrom matplotlib.animation import FuncAnimation\nrc('animation', html='jshtml')\n\nimages = [i.detach().cpu().numpy() for i in model.test_progression]\n\nnrow = 3\nncol = 8\n\nindexes = np.random.choice(range(100), nrow*ncol, replace=False)\n\nfig = plt.figure(figsize=((ncol+1)*2, (nrow+1)*2)) \n\ngs = gridspec.GridSpec(nrow, ncol,\n         wspace=0.0, hspace=0.0, \n         top=1.-0.5/(nrow+1), bottom=0.5/(nrow+1), \n         left=0.5/(ncol+1), right=1-0.5/(ncol+1)) \n\nfor i in range(nrow):\n  for j in range(ncol):\n    ax = plt.subplot(gs[i,j])\n    ax.axis('off')\n\ndef animate(frame):\n  fig.suptitle('Epoch {}'.format(frame), fontsize=30)\n  ret = []\n  for i in range(nrow):\n    for j in range(ncol):\n      idx = i*ncol + j\n      img = np.reshape(images[frame][indexes[idx]], (28,28))\n      ax = fig.axes[idx]\n      ax.imshow(img, cmap='gray')\n      ret.append(ax.get_images()[0])\n  return ret\n    \nanim = FuncAnimation(fig, animate, frames=100, interval=50, blit=True)\nЧто дальше?\nПоздравляю! Вы дошли до конца этого урока. Надеюсь, вам понравилось читать это так же, как мне понравилось писать это.\n \n ",
    "tags": [
        "python",
        "gan",
        "pytorch",
        "torchvision"
    ]
}