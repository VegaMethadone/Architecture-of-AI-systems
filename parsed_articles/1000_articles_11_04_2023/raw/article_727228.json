{
    "article_id": "727228",
    "article_name": "Предварительная обработка данных с помощью библиотеки Pandas (Задача)",
    "content": "В современном мире большинство бизнес-процессов связаны с обработкой больших объемов данных, получаемых от различных источников. Часто эти данные содержат ошибки, дубликаты и пропуски, что может привести к неверным выводам и решениям. Одним из инструментов, которые позволяют очистить и преобразовать данные, является библиотека pandas для языка программирования Python.\nЯ собираюсь рассмотреть задачу по очистке данных с помощью pandas. Для этого возьмем данные, содержащие дубликаты строк, неправильные типы данных, пропуски и отрицательные значения. Затем я буду использовать функциональные возможности pandas для очистки и преобразования этих данных в форму, пригодную для дальнейшего анализа.\nПредположим, у вас есть набор данных, содержащий информацию о продажах компании за последние несколько лет. Но данные не очень чистые, и вы заметили, что есть некоторые проблемы с форматированием и некоторые строки содержат ошибки.\nЗадача: Необходимо очистить данные о продажах компании за последние несколько лет с помощью библиотеки Pandas.\nИсходные данные:\nФайл CSV, содержащий информацию о продажах компании за последние несколько лет.\nФайл содержит следующие столбцы: дата продажи, название продукта, количество проданного товара, цена за единицу, общая стоимость продажи, имя продавца и регион продажи.\nВ некоторых строках присутствуют ошибки, например, неправильный формат даты или отсутствие цены за единицу.\nЗадачи, которые необходимо выполнить:\nЗагрузить исходные данные из файла в Pandas DataFrame.\nУдалить строки, которые содержат ошибки в данных.\nПривести столбец с датами к формату \ndatetime\n.\nПривести столбцы с числами к числовому формату (float или int).\nОпределить и удалить дубликаты строк.\nСохранить очищенные данные в новый файл CSV.\nОписание столбцов:\ndate\n - дата продажи, в формате \"YYYY-MM-DD\";\nproduct_name\n - название продукта\nquantity\n - количество продукта\nunit_price\n - цена за единицу продукта\ntotal_price\n - общая стоимость продукта, равная произведению количества и цены за единицу\nseller_name\n - имя продавца\nregion\n - регион продажи\nЗагрузка данных\nЧтобы загрузить данные в pandas, можно использовать метод \nread_csv()\n для загрузки данных из файла \nCSV\n или \nread_excel()\n для загрузки данных из файла \nExcel\n. В нашем случае у нас \ncsv\n файл.\nИмпортируем необходимые библиотеки и загружаем данные.\nimport pandas as pd\nimport re\n\ndf = pd.read_csv('data_with_errors.csv')\nВыводим наш DataFrame.\ndf.head(5)\nНа первый взгляд в данных видно наличие отрицательных значений и пропусков. Однако, в нашем задании сказано, что после загрузки мы должны удалить строки, в которых есть ошибки. Мы поступим немного по-другому. Сначала мы проверим типы столбцов, и если обнаружится, что какие-то столбцы не соответствуют данным, которые в них находятся, мы изменим тип на соответствующий. При возникновении проблем в ходе выполнения этой задачи, мы будем исправлять то, что будет необходимо.\nОбработка данных\nДля начала посмотрим на то, какие типы имеют наши столбцы. Для этого нам поможет команда \ninfo()\n.\ndf.info()\nМы получаем информацию о нашем DataFrame, которая говорит нам о наличии пропусков в столбце \ntotal_price\n. Также мы видим, что столбец с датами имеет строковый тип, также как и столбцы \nquantity\n и \nunit_price\n, которые содержат числовые данные. Нам необходимо это исправить.\nПопробуем сразу привести столбец date к типу \ndatetime\n. Для этого нам понадобится следующий код:\ndf['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\nК сожалению, этот код не сработает, так как в столбце с данными присутствуют значения, которые не позволяют сразу привести столбец к нужному нам типу. В результате работы выражения будет выведено сообщение об ошибке.\nСуществует множество способов решения данной проблемы, один из них представлен ниже. Так как даты в нашем столбце date указаны в формате \"YYYY-MM-DD\", мы можем использовать регулярное выражение для поиска всех значений столбца, которые не соответствуют данному формату. Для этого мы создадим лямбда-функцию, которая будет применена к столбцу методом \nmap()\n. Регулярное выражение будет выглядеть следующим образом: `\\d{4}-\\d{2}-\\d{2}`.\nСоздаем лямбда-функцию.\nsearch = lambda x: x if re.search(r\"\\d{4}-\\d{2}-\\d{2}\", x) else 'not found'\nПрименяем лямбда-функцию к столбцу \ndate\n.\ndf['date'] = df['date'].map(search)\nПроверим результат.\ndf.query('date == \"not found\"').count()\nМы видим, что в 53 строках данные не соответствуют формату..\nПосмотрим на эти строки, чтобы понять, с чем мы имеем дело.\ndf.query('date == \"not found\"').head(5)\nМы замечаем отсутствие даты, а также латинские буквы вместо чисел в столбце количества \nquantity\n. Кроме того, столбец \ntotal_price\n содержит множество пропусков, а \nunit_price\n имеет много повторяющихся значений. В таком виде данные не представляют ценности для анализа, и мы должны удалить строки, содержащие ошибки, как указано в задании.\ndf = df.drop(df.query('date == \"not found\"').index)\ndf.query('date == \"not found\"').count()\nПриведем столбец \ndate\n к нужному нам типу данных.\ndf['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\ndf.info()\nВидим что столбец \ndate\n теперь имеет тип \ndatetime.\nДля того чтобы привести столбец \nquantity\n к числовому формату, мы можем использовать метод \nto_numeric()\n с параметром \nerrors='coerce'\n, который преобразует значения в числа, а нечисловые значения заменяет на NaN.\ndf['quantity'] = pd.to_numeric(df['quantity'], errors='coerce')\nТоже самое мы делаем с \nunit_price.\ndf['unit_price'] = pd.to_numeric(df['unit_price'], errors='coerce')\nДля продолжения, мы сфокусируемся на отрицательных значениях в указанных столбцах и выведем их на экран.\ndf.query('quantity < 0')\nЭти значения будут преобразованы с помощью функции \nabc()\n, чтобы преобразовать отрицательные значения в столбцах. Это позволит получить абсолютные значения и избавиться от знака минус.\ndf.loc[df['quantity'] < 0,'quantity'] = abs(df['quantity'])\nТаким же образом мы поступим \nunit_price.\ndf.query('unit_price < 0')\nЗаменяем отрицательные значения на положительные.\ndf.loc[df['unit_price'] < 0,'unit_price'] = abs(df['unit_price'])\nОбработаем столбец \ntotal_price\n. В задаче указано, что \ntotal_price\n представляет собой общую стоимость продукта, которая равна произведению количества и цены за единицу. Значит, мы можем заполнить пустые значения в этом столбце, умножив значение \nquantity\n на значение \nunit_price\n. Так и поступим.\ndf.loc[df['total_price'].isna(), 'total_price'] = df['quantity'] * df['unit_price']\nДанные содержат некоторое количество дубликатов, которые необходимо удалить в соответствии с заданием.\ndf[df.duplicated()]\nУдаляем дубликаты.\ndf = df.drop(df[df.duplicated()].index)\nПроверим категориальные переменные.\ndf.product_name.unique()\ndf.seller_name.unique()\ndf.region.unique()\nВсе значения категориальных переменных в порядке. Осталось только сохранить данные в csv. В этом нам поможет функция \nto_csv()\n.\ndf.to_csv('processed_data.csv',index=False, header=True)\n В результате мы получим файл \nprocessed_data.csv\n.\nЗаключение\nТакое задание позволяет закрепить навыки работы с pandas, например, загрузка данных из файла, очистка данных от дубликатов и пропусков, изменение типов данных столбцов и обработка пропущенных значений. Задание также поможет новичкам овладеть принципами анализа данных, включая методы pandas для анализа данных.\nВ скором времени я планирую выложить разбор реальной задачи для продуктового аналитика, который поможет вам лучше понять, как применять знания и навыки, полученные в процессе изучения данной темы. Я надеюсь, что этот материал будет интересен и полезен для вас, и вы сможете успешно применить полученные знания на практике. Буду благодарен за ваши комментарии! Спасибо!\n \n ",
    "tags": [
        "данные",
        "очистка данных",
        "библиотека Pandas",
        "ошибки в данных",
        "удаление строк",
        "datetime",
        "дубликаты",
        "Задача для аналитика",
        "обработка данных"
    ]
}