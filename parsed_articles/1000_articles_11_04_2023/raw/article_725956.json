{
    "article_id": "725956",
    "article_name": "Autobinary: библиотека для простого обучения «деревяшек» — Part 1",
    "content": "Мы – команда «Модели управления Жизненным Циклом Клиента». Ранее мы рассказывали о нашей работе и задачах вот \nздесь\n. Сегодня мы расскажем вам про \nинструмент\n, которым пользуемся для построения моделей и оптимизации. \nКак все начиналось\nРождение autobinary, как и многих других фреймворков, началось с автоматизации рутинных задач. На тот момент мы создавали много look-alike моделей (в основе - модель бинарной классификации) по разным продуктам банка. Одни и те же скрипты писать было скучно. Более того – накопилось много разрозненных скриптов, которые хотелось привести к единому формату. \nНачали мы с алгоритма XGBoost и модели бинарной классификации. Сначала сделали функционал для кросс-валидации, далее сделали методы для получения различных метрик, важностей факторов, построения графиков и т.д. И, в результате, назвали библиотеку autobinary, подразумевая, что это фреймворк для простого обучения бинарной классификации на бустинге. \nЧто сейчас?\nШло время, появлялось все больше разнообразных задач. \nТеперь библиотека поддерживает не только задачи бинарной классификации, но и регрессии, мультиклассовой классификации, а также uplift задачи на различных алгоритмах, например, XGBoost, Catboost, LightGBM, Decision Tree, Random Forest.\nФункционал библиотеки расширился, а название осталось тем же.\nПомимо обучения самих моделей, реализованы различные методы, которые позволяют построить стабильную модель с небольшим количеством факторов, а также интерпретировать результаты обучения модели. \nВозможности Autobinary\nБазовый анализ факторов\nЗачастую факторы имеют разные распределения. Для проведения быстрого однофакторного анализа для задач бинарной классификации и регрессии мы используем графики фактора против таргета. \nКласс TargetPlot позволяет разбить фактор по заданному количеству бакетов с настройкой по отсечениям, специальным значениям и др. \nФактор Age из соревнования «титаник» для задачи бинарной классификации\nФактор LotArea из соревнования «House Price» для задачи регрессии\nPipeline обработки\nТипичная ошибка при моделировании – это лики в данных. Например, моделист сначала заполняет пустые значения в фичах средним значением, а только потом разделяет выборку на train и test. В результате происходит смещение среднего, и в нем содержится информация как о train, так и о test. \nПравильная стратегия в этом случае – сначала разделить данные, посчитать среднее на train, а потом этим средним, посчитанном на train, заменить пустые значения и на train и на test.\nЕсли шагов обработки много, то за всем этим становится сложно следить. Именно поэтому обычно используют \npipeline\n из sklearn. \nТаким образом, пайплайн сначала обучается на train, а потом применяется и на train и на test.\nМы для быстрых тестов сделали базовый пайплайн обработки, который принимает на вход категориальные и числовые фичи в виде списков и делает следующее: \nПустые значения заполняет большим отрицательным числом для числовых\nКатегориальные фичи обрабатываются с помощью \nCatBoostEncoder\n из библиотеки Category Encoders.\nP.S. Рекомендую попробовать разные энкодеры из этой библиотеки, они действительно очень удобные и показывают хорошее качество. \nКросс-валидация\nКросс-валидацию мы обычно используем для отбора факторов, подбора параметров, или, в целом, для проверки модели на стабильность, расчета важностей, расчета средних метрик и т.д. \nДавайте посмотрим детально на конкретный \nпример\n – кросс-валидация для задачи бинарной классификации «Титаник» с использованием Catboost.\nЗагружаем данные: \nЗадаем списки числовых и категориальных фичей, а также название таргета: \nДелим выборку на train и test. На train будем учить кросс-валидацию: \nЗадаем пайплайн обработки данных, в который передаем списки фичей: \nПередача пайплайна позволяет упростить преобразование данных и избежать ликов.\nЕсли у нас 5 фолдов, как в этом примере, то на каждой итерации кросс-валидации пайплайн заново переобучается на 4 частях, а потом применяется и к 4 частям и к одной части. \nТак как используется pipeline из sklearn, то можно сделать его сколь угодно сложным, а также некоторые части можно написать самому. \n Теперь задаем параметры модели, параметры для обучения модели, сам инстанс модели, а также стратегию кросс-валидации: \nСтратегию кросс-валидации можно задать любую из sklearn, или написать свою!\nТеперь передаем в модель все параметры, которые задали ранее:\nMain_estimator – инстанс модели, которую будем обучать\nMain_fit_params – параметры обучения модели\nMain_prep_pipe – пайплайн обработки данных\nMain_features – все фичи, на которых будет учиться модель\nПочему main? Есть некоторые uplift-модели, которые состоят из двух моделей. Поэтому придется передавать сразу две модели в класс AutoTrees. Но об этом мы вам расскажем в следующих частях. \nX_train, y_train – выборка и целевая метка\nMain_metric – метрика, которая будет выводиться для справки на каждом шаге кросс-валидации и усредняться в методе model.get_mean_cv_scores().\nModel_type – модель, которую обучаем. \nТеперь запускаем обучение кросс-валидации, передавая стратегию (задали ее выше). \nПример логов обучения одного фолда показан ниже: \nОсобенность обучения бустингов нашей библиотекой в том, что мы передаем в параметрах модели большое количество итераций (в данном случае 1000), а также в параметрах обучения указываем early_stopping_rounds (в данном случае 200). В результате, на каждом фолде срабатывает остановка, как только модель начинает переобучаться. \nРезультаты кросс-валидации\nТеперь давайте посмотрим, какие можно получить результаты после обучения кросс-валидации. \nВ первую очередь это средняя метрика, которую задали в main_metric. Для этой задачи это \ngini\n (2*roc_auc-1): \nТакже это количество итераций на каждом фолде: \n Дополнительная информация по метрикам на каждом из фолдов: \nВажности факторов: \nВидов важностей у бустингов много, мы взяли стандартные gain важности. \nГрафики roc-кривых:\nИ, наконец, графики обучения модели на всех фолдах. Для примера на первом фолде:\nЧерная прямая указывает на место, где сработала остановка из-за переобучения!\nИтоги\nНа этом все! \nСегодня мы рассказали о базовом анализе факторов, пайплайне обработки данных, а также кросс-валидации, которая используется во многих других методах моделирования. \nВ следующих частях мы расскажем вам об отборе факторов, подборе параметров и других интересных особенностях нашей библиотеки!\nНад библиотекой работали: \nВасилий Сизов - \nhttps://github.com/Vasily-Sizov\nДмитрий Тимохин - \nhttps://github.com/dmitrytimokhin\nПавел Зеленский - \nhttps://github.com/vselenskiy777\nРуслан Попов - \nhttps://github.com/RuslanPopov98\n \n ",
    "tags": [
        "data fest",
        "uplift",
        "response",
        "look-alike",
        "жизненный цикл",
        "бизнес-правила",
        "boosting",
        "xgboost",
        "catboost",
        "lightgbm"
    ]
}