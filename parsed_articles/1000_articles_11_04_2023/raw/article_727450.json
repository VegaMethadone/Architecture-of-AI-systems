{
    "article_id": "727450",
    "article_name": "Йошуа Бенжио о замедлении развития ИИ-систем, которые проходят тест Тьюринга",
    "content": "Примечание переводчика: \nЙошуа Бенжио\n это один из самых авторитетных и цитируемых исследователей ИИ в мире. Он получил премию Тьюринга в 2018 году вместе с Джеффри Хинтоном и Яном Лекуном за развитие алгоритмов и теории искусственного интеллекта. Из этой троицы, Хинтон, как и Бенжио, тоже, кажется, \nсильно обеспокоен траекторией развития ИИ\n. Лекун наиболее оптимистичен и наименее озабочен. Завтра, в пятницу, \nЛекун вместе с Эндрю Нг проведут вебинар\n, на котором расскажут, почему они против идеи замедления развития систем, более мощных, чем GPT-4.\nНедавно я подписал \nоткрытое письмо\n с просьбой замедлить развитие гигантских ИИ‑систем, более мощных, чем GPT-4, — тех, которые сейчас проходят тест Тьюринга и могут обмануть человека, заставив его поверить, что он разговаривает с человеком, а не с машиной.\nЯ счел подписание этого письма уместным, чтобы предупредить общественность о необходимости снижения темпов развития ИИ‑систем, которое сейчас происходит в ущерб принципу предосторожности и в ущерб этике. Мы должны уделить время чтобы лучше понять эти системы и разработать необходимые ограничения на национальном и международном уровнях для повышения защиты общества.\nТакое неожиданное ускорение — я, вероятно, не подписал бы такое письмо год назад — требует от нас отступить на шаг назад, и именно поэтому мое мнение изменилось.\nНет гарантий, что в обозримом будущем кто‑то не создаст опасные автономные ИИ‑системы с поведением, отклоняющимся от целей и ценностей человечества. Краткосрочные и среднесрочные риски — манипулирование общественным мнением в политических целях, особенно через дезинформацию, — легко предсказать, в отличие от долгосрочных рисков — ИИ‑систем, которые представляют опасность, несмотря на цели, заложенные в них программистами, — и мне кажется важным изучить оба типа рисков.\nС появлением ChatGPT мы стали свидетелями изменения отношения компаний, для которых давление коммерческой конкуренции увеличилось в десятки раз. Существует реальный риск того, что они устремятся к разработке этих гигантских ИИ‑систем, отбросив нормы прозрачности и открытой науки, которые они развили за последнее десятилетие исследований в области ИИ.\nСуществует срочная необходимость регулирования этих систем с целью обеспечения большей прозрачности и контроля над ИИ‑системами для защиты общества. Я верю, как и многие другие, что риски и неопределенность достигли такого уровня, что требуется также ускорение разработки наших механизмов регуляции, надзора и управления (governance).\nОбществам требуется время для адаптации к изменениям, законам нужно время, чтобы быть принятыми, а регулятивные ограничения и нормы должны быть разработаны. Поэтому кажется важным быстро повысить осведомленность, поставить этот вопрос на больше радаров и стимулировать большую общественную дискуссию.\nЯ говорю об этом уже много лет, и я повторяю в этом письме, которое сосредоточено на регуляции и надзоре над огромными ИИ‑системами, большими, чем GPT-4, а не на ИИ в целом: вместо этого важно инвестировать государственные средства в разработку ИИ‑систем, посвященных общественным приоритетам, которые часто игнорируются бизнес‑сектором, таким как исследования в области здравоохранения или борьба с климатическими изменениями. Такое применение ИИ гораздо менее вероятно будет использовано во вред обществу, в отличие от универсальных систем, таких как GPT-4.\nНам нужно стимулировать усилия исследователей, особенно в области социальных и гуманитарных наук, потому что решения включают не только технический, вычислительный аспект, но и, прежде всего, социальные и человеческие соображения.\nМы должны продолжать борьбу за благополучие человечества и разработку полезных ИИ‑приложений, таких как те, которые направлены на решение климатического кризиса. Это потребует изменений на уровне каждой страны и принятия международных договоров. Мы смогли регулировать ядерное оружие в мировом масштабе после Второй мировой войны, и мы можем достичь аналогичного соглашения для ИИ.\nНесмотря на то, что может показаться из письма, я оптимистичен, что технологии смогут помочь нам преодолеть великие вызовы, стоящие перед человечеством. Однако, чтобы им противостоять, нам нужно уже сейчас думать о том, как адаптировать наши общества или даже полностью их переизобрести.\nВот некоторые часто задаваемые вопросы об открытом письме. Мнения, выраженные в ответах, не обязательно разделяются всеми подписантами этого письма.\nПочему вы подписали это открытое письмо?\nМы перешли критический порог: теперь машины могут разговаривать с нами и притворяться людьми. Эта власть может быть использована в политических целях в ущерб демократии. Разработка все более мощных инструментов чревата усилением концентрации власти. Будь то в руках нескольких человек, компаний или стран, это представляет опасность для демократии (что означает власть народу и, следовательно, противоположность концентрации власти), для уже и без того хрупкого глобального баланса безопасности и даже для функционирования рынков (которые нуждаются в конкуренции, а не монополиях).\nРазве тон письма не слишком тревожен?\nНикто, даже ведущие эксперты по ИИ, включая тех, кто разработал эти гигантские ИИ‑модели, не может быть абсолютно уверен, что такие мощные инструменты сейчас или в будущем не могут быть использованы катастрофическим для общества образом. Письмо не утверждает, что GPT-4 станет автономным — это было бы технически неверным — и угрожает человечеству. Вместо этого, очень опасным — и вероятным — является то, что люди с плохими намерениями или просто не осознающие последствия своих действий могут сделать с этими инструментами и их будущими версиями в ближайшие годы.\nБудет ли это письмо достаточным, чтобы убедить технологических гигантов замедлиться?\nДаже если надежда мала, стоит начать широкое общественное обсуждение. Потому что нам придется принимать коллективные решения в ближайшие годы, в том числе о том, что мы хотим делать с мощными инструментами, которые разрабатываем. Я даже подозреваю, что многие в этих компаниях надеются на регулирование, которое уравняет условия игры: начиная с ChatGPT, менее осторожные игроки имеют конкурентное преимущество и поэтому могут легче продвигаться вперед, снижая уровень осмотрительности и этического контроля.\nХватит ли шести месяцев паузы? Не тщетны ли эти усилия?\nТо же самое можно сказать о наших усилиях по борьбе с климатическими изменениями. Окружающей среде уже было нанесено много вреда, инерция нашей промышленной ткани упряма — не говоря уже о лоббистских группах — и усилия ученых и активистов в области климата по корректировке нашего коллективного курса (экономики), кажется, не работают. Стоит ли сдаваться? Конечно, нет. Всегда есть способы сократить будущий ущерб, и каждый шаг в правильном направлении может быть полезным.\nРазве страхи перед ИИ-системами не научная фантастика?\nУже существует литература, документирующая текущий ущерб, который помогла бы минимизировать регуляция, от ущемлений человеческого достоинства, таких как дискриминация и предвзятость, до военного использования ИИ, например, автономных дронов‑убийц.\nСледует ли прекратить разработку ИИ-систем вообще?\nВ письме говорится не об этом. Оно касается только систем, которые еще не разработаны и которые будут мощнее, чем GPT-4. Тем не менее, мне кажется очевидным, что мы должны принять определенное замедление технологического прогресса для обеспечения большей безопасности и защиты коллективного благополучия. Общество ввело строгие регулирования для химикатов, авиации, лекарств, автомобилей и т. д. Компьютеры, которые теперь оказывают огромное влияние на многие сферы нашего общества, на мой взгляд, заслуживают аналогичного подхода.\nПочему вы подписали письмо вместе с людьми, у которых политические взгляды противоположны вашим?\nЭто открытое письмо на конкретную тему. Подписывая его, человек не одобряет все другие заявления подписантов. По вопросу о экзистенциальных и долгосрочных рисках для человечества я не согласен с многим из написанного по этому поводу («\nлонгтермизм\n«). Конечно, долгосрочные риски важны — и именно поэтому я выступаю за эффективное решение климатических проблем. Но эти риски должны быть сопоставлены с вероятностью их осуществления, и чем дольше временной горизонт, тем менее определенны эти риски. В сравнении с этим, ущерб, причиняемый живущим сегодня людям, не должен быть отброшен, потому что более краткосрочные риски гораздо более осязаемы. Так что я думаю, что мы должны рассматривать все риски, основываясь на их величине и оцененной вероятности, риски на разных временных горизонтах. И мы должны использовать разум и науку для оценки всего этого, не забывая о нашем сочувствии к живущим и страдающим сегодня людям.\nГотово ли общество столкнуться с приходом этих новых и чрезвычайно мощных технологий?\nЧеловечество сталкивается с несколькими глобальными кризисами, которые, вероятно, усугубятся: в области общественного здравоохранения, окружающей среды, военной и политической безопасности и стабильности, неравенстве и социальных несправедливостей и, конечно же, в области рисков, связанных с бесконтрольным развитием ИИ. \nЯ сомневаюсь, что текущая организация нашего общества на национальном и глобальном уровнях является адекватной для преодоления этих вызовов\n [выделение переводчика]. На коротком горизонте, на мой взгляд, нельзя обойтись без регулирования. Я надеюсь, что на долгосрочную перспективу этого будет достаточно, но сейчас мы должны рассмотреть возможность того, что социальная организация общества, которая работала в прошлом веке, больше не адекватна перед лицом этих глобальных кризисов.\n \n ",
    "tags": [
        "ИИ",
        "chatgpt",
        "gpt-4"
    ]
}