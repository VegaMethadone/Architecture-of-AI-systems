{
    "article_id": "726764",
    "article_name": "Частотный vs байесовский подходы: оцениваем True Positive Rate при неполной разметке данных",
    "content": "Привет, Хабр! Меня зовут Алан Савушкин (\n@naive_bayes\n), я — дата-сайентист \nв команде Data Science & Big Data «Лаборатории Касперского»\n, и мы отвечаем в том числе за фильтрацию нерелевантных алертов при телеметрии киберугроз в проекте Kaspersky Managed Detection and Response (MDR). \nВ данной статье хочу с вами поделиться, как мы решали задачу построения оценки TPR (True Positive Rate) в условиях неполной разметки данных. Может возникнуть вопрос: а что там оценивать? TPR по своей сути всего лишь доля, а построить доверительный интервал на долю легче простого.\nСпорить не буду, но добавлю, что из статьи вы узнаете:\nЧто даже в использовании такого интервала есть свои условия.\nКак на основе серии проверки гипотез получить доверительный интервал, используя под капотом гипергеометрическое распределение. А можно ли использовать биномиальное? Спойлер: можно, но тогда важно понимать, на какой вопрос вы отвечаете, пользуясь такой оценкой. Здесь мы рассмотрим задачу с частотной точки зрения.\nЧто будет, если скрестить биномиальное распределение с бета-распределением, и как этот гибрид используется в качестве сопряженного априорного распределения для гипергеометрического распределения. А здесь мы рассмотрим задачу с байесовской точки зрения.\nИ, собственно, в чем прикол этой неполной разметки данных, и как мы докатились до всего перечисленного выше.\nТизер получился обширным, и если вам стало интересно — что ж, тогда давайте разбираться.\nПостановка задачи\nНачнем с краткого описания, откуда берется неполная разметка данных и почему это проблема.\n \nИтак, наш \nKaspersky MDR (Managed Detection and Response)\n предназначен для защиты клиентской инфраструктуры от киберугроз, и общая схема его работы выглядит следующим образом:\nС клиентских хостов передается телеметрия — события, связанные с активностью пользователей. В среднем с одного хоста может поступать около 15 тысяч событий в день. Множество этих событий агрегируется и фильтруется — выделяются подозрительные действия и формируются алерты для отправки аналитикам в Security Operations Center (подробнее о том, как у нас работает SOC, можно прочитать в \nэтой хабрастатье моего коллеги Александра Родченко\n). В среднем со всех клиентских хостов мы получаем около 1200 алертов в сутки.\nАналитики центра должны расследовать каждый алерт и в случае обнаружения угроз предупреждать клиентов, формируя рекомендации по устранению опасности. Число алертов кажется небольшим, но наши специалисты ограничены во времени — по условиям SLA у них есть не более часа на реакцию.\nКак это часто бывает, если нельзя пропустить подозрительное событие, ты слишком бдителен. В итоге большая часть алертов является нерелевантной. Это связано еще и с тем, что для одного клиента определенная активность может быть вполне характерной, а для другого — подозрительной. И здесь мы приходим на помощь аналитикам, вооружившись ML. Задача нашего ML-сервиса — фильтровать нерелевантные алерты, т. е. по факту мы делаем классификатор, который принимает решение, отдать алерт аналитикам или нет. \nБлагодаря нашему сервису аналитики меньше времени тратят на нерелевантные алерты, а больше внимания уделяют реальным угрозам. Получается оптимизация ресурсов на обеспечение клиентской защиты — без сервиса «Лаборатории Касперского» пришлось бы расширять штат аналитиков.\nТребования и метрики\nНам поставили цель фильтровать 50% потока алертов. За этой метрикой легко следить, поскольку мы знаем, сколько отфильтровываем, а сколько передаем аналитикам. \nОднако стоит учитывать, что ML-модели неидеальны и возможны ошибки. В нашем случае критичной ошибкой является ошибка 2-го рода (False Negative), то есть что мы отфильтруем релевантный алерт. И в этом плане требование к нашему сервису достаточно высокое — не более 2% пропусков. За этим показателем необходимо тщательно следить в режиме реального времени, чтобы оперативно отреагировать, если что-то пойдет не так. \nМы используем метрику True Positive Rate — она должна быть не менее 98%. Напомню, как она считается: \nЗдесь:\nTrue positive — то, что мы отдали аналитикам, и это действительно оказались релевантные алерты. С этим показателем проблем нет — аналитики посмотрят и все разметят.\nFalse negative — то, что неверно отфильтровали. И как получить эту величину, с ходу неясно, потому что как только сервис освободил аналитиков от работы, мы потеряли разметку данных.\nПростая перепроверка\nДавайте будем брать из потока случайные алерты и передавать их аналитикам для перепроверки, как будто мы ничего не фильтровали. Аналитики отработают в обычном режиме, не зная, что это перепроверка. Но для себя мы отметим, верно ли отработал фильтр. Таким образом, мы получаем разметку данных. \nЧтобы понять, достаточно ли информации для использования формулы расчета TPR, проведем симуляцию на синтетических данных и оценим, что можем получить в зависимости от количества переданных на проверку алертов. \nДопустим, мы не перепроверяем ничего — верим нашему сервису. В этом случае формула расчета TPR даст 1.\nОго, это же очень круто! Но голос внутри нас подсказывает, что что-то здесь не так. \nМожет, хотя бы что-то отдадим на перепроверку? Если мы передаем на проверку небольшую долю (10%), ошибки обнаруживаются, но редко. Мы все равно слишком позитивны.\nПередавая на проверку 50%, мы можем найти мало или много. Но в среднем это все равно слишком оптимистичный прогноз.\n Только передавая на перепроверку все, мы доходим до истинного значения. \nВ итоге наивный подход дает нам завышенную оценку. Но нам критически важно следить за реальным качеством сервиса, чтобы оперативно реагировать на изменения картины. Необходимо получить честную оценку, но сохранить пользу от сервиса.\nМожет возникнуть мысль, что вроде же и так очевидно, что таким способом мы будем получать завышенную оценку. Зачем эти картинки? Согласен, но иногда бывает полезно посмотреть и на очевидные вещи, чтобы стало еще очевиднее=)). Например, здесь мы увидели странную на первый взгляд вещь. Во-первых, сначала у нас разброс такой же, как и когда мы получаем все данные. А во-вторых, когда отдаем 50% на перепроверку, у нас разброс больше, чем когда отдаем 10%, что противоречит предположению, что чем больше данных, тем меньше неопределенность. Но на самом деле здесь нет ничего странного, если понять, какую вероятностную модель использовать. Как раз дальше мы это и рассмотрим. А сейчас отметим самое главное, для чего мы это все описывали.\nВся неопределенность метрики заключается в количестве объектов False Negative, но они находятся в фильтруемой части. То есть точное количество мы не знаем, поэтому нужно каким-то образом оценить границы этой величины за счет нашей схемы перепроверки. То есть здесь мы отвечаем на вопрос: сколько алертов или какую долю алертов мы неверно \nотфильтровали\n? Я специально подсветил последнее слово в вопросе — дополнительно мы увидим, что можно отвечать и немного на другой вопрос.\nДавайте посмотрим, как эту задачу можно решить с помощью частотного подхода.\nЧастотный подход\nВ частотном подходе для оценки границ или выражения неопределенности мы строим доверительные интервалы. Давайте рассмотрим, что это, какие есть способы их построения и какой из способов подходит для нашей задачи.\nДоверительный интервал 100(1 – α)%\nДоверительный интервал — это интервал, построенный с помощью случайной выборки из распределения с неизвестным параметром, такой, что он содержит данный параметр c вероятностью не менее (1 – α).\nЗдесь важно понимать, что в частотном подходе у нас выборка случайна и границы являются случайными величинами. А сам параметр является фиксированным, просто мы его не знаем. А вот в байесовском подходе все наоборот, но об этом позже.\nРассмотрим различные способы построения доверительных интервалов и разберемся, какой из способов нам подходит.\nНачнем с точного доверительного интервала.\nЧтобы получить точный доверительный интервал, необходимо взять статистику\n, зависящую от данных и параметра, который хотим оценить. Нам нужна такая статистика, чтобы ее распределение\nне зависело от параметра \n. Это позволяет решить уравнение и получить границы. \nПредположим, у нас выборка из нормального распределения. Оцениваем среднее — это и будет точный доверительный интервал. \nПояснение\nПусть наша выборка \n— независимо и одинаково распределенные (i.i.d.) случайные величины с распределением\n.\nЗдесь у нас \n—мат. ожидание, а \n— дисперсия. \nТогда\n — тут мы  воспользовались тем, что \nдля независимо и одинаково распределенных случайных величин. Тогда получаем\nЗдесь мы показали, что в случае выборки из нормального распределения статистика  \n   имеет стандартное нормальное распределение.\nИ дальше, подставляя нашу статистику в уравнение, получаем:\nгде \n — соответствующие квантили стандартного нормального распределения.\nИ в силу симметрии стандартного нормального распределения относительно нуля мы имеем \nчто в итоге нам окончательно дает привычный вид доверительного интервала\nНо избавиться от зависимости от параметра при построении интервала получается не всегда. В таких ситуациях используется \nасимптотический\n доверительный интервал. Схема его вычисления похожа, просто мы берем «удобное» распределение, чтобы спокойно выводить границы.\nПример.\nДопустим, нам надо оценить долю по выборке. Тогда в этом случае мы делаем предположение, что наша выборка \n— независимо и одинаково распределенные (i.i.d.) случайные величины с распределением \nБудем действовать, как в примере с точным доверительным интервалом \n — биномиальное распределение. \nНапомню, что у биномиального распределения\nТогда распределение выборочного среднего \n это какое-то дискретное распределение с параметрами\nТакое распределение не имеет определенного названия. Идем дальше.\nСтатистика \n— это какое-то дискретное распределение с параметрами\nИ наконец, статистика \nэто какое-то дискретное распределение с парметрами\nИтак, мы получили какое-то дискретное распределение, мы знаем его некоторые характеристики, но им неудобно пользоваться, так как мы не знаем его явного вида и непонятно, как получить нужные нам квантили. \nИ здесь нам на помощь приходит \nцентральная предельная теорема\n (ЦПТ), в которой утверждается, что\nпо распределению при \n. А вот это уже удобно, так как из этого распределения мы можем легко получить нужные нам квантили. Но пока мы решили лишь половину проблемы. Давайте подставим полученную статистику в уравнение, которое нам надо решить. Сделаем это уже с учетом ЦПТ.\nОднако здесь получается замкнутый круг. Чтобы оценить границы неизвестного параметра, нам нужно знать этот неизвестный параметр=)). Чтобы из него выйти, воспользуемся законом больших чисел (ЗБЧ): \n, \nТогда в левой и правой части неравенства заменим \nнашей оценкой \n. В итоге получаем\nТакой вид интервала для доли, думаю, знаком многим из вас. Его легко построить, но чтобы к нему прийти, нам по пути пришлось сделать несколько допущений. Первое — это сходимость к стандартному нормальному распределению. Но тут как раз нюанс в сходимости к распределению, так как скорость сходимости для различных значений доли не одинакова.\nРассмотрим на картинках для наглядности.\nКак видно из графиков, при \nраспределения статистики к стандартному нормальному распределению наиболее быстрая. А вот для крайних значений \nсходимость медленная, и более того — видно, что при аппроксимации нормальным распределением мы не учитываем асимметрию распределения нашей статистики.\nВторой нюанс — это замена \nна \n. Как можно заметить из вида интервала, если мы случайно получим крайние значения для оценки доли, то наш интервал выродится в точку. Причем неважно, много или мало наблюдений нам доступно. И это может приводить к тому, что наш доверительный интервал не будет накрывать истинное значение параметра с нужной нам вероятностью. Рассмотрим графики \ncoverage probability \nдля наглядности.\nКак видно из графика, если у нас немного данных, то для значений параметра \n, близких к крайним значениям, наш асимптотический доверительный интервал будет накрывать истинное значение параметра реже, чем мы предполагаем.\nВсе это в совокупности может приводить к более частым ошибкам первого рода. Так что учитывайте эти нюансы, когда используете какую-нибудь аппроксимацию=) .\nМетод еще проще — бутстреп. Мы просто сэмплируем подвыборки и много раз считаем на них распределение. Получаем набор значений, по которым можно вывести границы.\nЗдесь приведен пример перцентильного доверительного интервала на основе бутстрепа. Об остальных можно прочесть \nвот тут\n.\nОб еще одном методе говорят редко. Он возникает из интерпретации доверительного интервала и его взаимосвязи с проверкой гипотез.\nДоверительный интервал 100(1 – α)% — это область значений параметра θ, для которых мы не отвергаем гипотезу \nH\n0\n: θ = θ\n0\n на уровне значимости \nα\n. Иными словами, доверительный интервал — это те значения параметра, которые согласуются с нашими данными при заданном уровне значимости.\nЧтобы построить этот интервал, мы фиксируем значение θ и проверяем нулевую гипотезу о равенстве параметра этому фиксированному значению. Значение нам подходит, если мы не можем отклонить нулевую гипотезу. И проверку надо выполнить для всех допустимых значений θ.\nНам нужно собрать все θ\ni\n, для которых \np\nvalue\n > α/2 (уровень значимости здесь α/2, поскольку мы ищем две границы).\nТут достаточно простая процедура, самое главное — определиться с вероятностной моделью для проверки гипотезы.\nИ вы, наверное, уже догадались, что не просто так этот метод упоминается. Да, это действительно так, и давайте разберемся, почему. Для этого рассмотрим более формально нашу систему перепроверки.\nДоверительный интервал для выборки без возвращения\nКогда мы передаем аналитикам алерты на проверку, они уже не могут считаться отфильтрованными. Таким образом, у нас модель выборки без возвращения.\nЭту модель стоит рассмотреть более формально. Пусть:\nN — количество отфильтрованных алертов, мы это знаем;\nM — сколько всего False Negative отфильтровали, это величину мы не знаем и хотим оценить;\nn — сколько объектов отдали на перепроверку (и это мы знаем);\nk — сколько False Negative алертов нашли на перепроверке (это тоже знаем).\nТакая модель описывается гипергеометрическим распределением.\nИтак, мы знаем величины \nN\n, \nk\n, \nn\n, а величину \nM\n нам нужно оценить. И с ходу неясно, какую нам статистику считать по выборке, чтобы воспользоваться первыми тремя способами построения доверительных интервалов. \nВ теории мы могли бы просто оценивать долю \n с помощью статистики \n. Строить интервал для доли \n, потом выводить границы для \nM\n, как \nНо тут у нас несколько проблем. Первое — мы можем очень редко находить алерты False Negative. Соответственно, у нас \nk\n может быть часто нулевым. В таком случае использовать бутстреп и асимптотический метод нецелесообразно, так как в обоих случаях у нас проблемы со сходимостью, и интервалы, по сути, вырождаются в точку, а именно в ноль. Тогда и оценка величины \nM\n будет часто нулем, и мы опять слишком позитивны.\nМы могли бы использовать точный интервал, но в этом случае \nM\n может оказаться дробным и неясно, в какую сторону его округлять. При больших \nM\n такого вопроса не возникает, но при малых мы можем ошибочно сместить оценку, что в итоге скажется на TPR.\nКстати, интересно, что точный интервал для доли, а именно интервал Клоппера —Пирсона — это на самом деле интервал, основанный на четвертом методе построения интервала, просто он красиво сводится от перебора значений к прямому вычислению нужных квантилей. \nЗдесь\n хорошо об этом написано, плюс мы еще затронем этот интервал в нашей статье.\nВ итоге только один из обсуждавшихся методов на основе проверки гипотез учитывает все особенности.\nПостроение доверительного интервала на практике\nРассмотрим на примере, как строить такой интервал.\nПредположим, мы отфильтровали 1000 алертов (N = 1000) и хотим оценить параметр \nM\n — построить 95%-ный доверительный интервал.\n100 алертов отдали аналитикам (n = 100), 25 нашли на перепроверке (k = 25). Все эти величины мы уже можем подставить в гипергеометрическое распределение:\nПараметр \nM\n неизвестен, но мы можем предположить, что он равен какому-то значению. Так у нас появится фиксированное гипергеометрическое распределение — мы проверяем гипотезу о равенстве параметра этому значению.\nСначала рассмотрим поиск нижней границы \nФиксируем величину \nM\n и вычисляем \np\nvalue\n — в данном случае правый хвост распределения от величины \nk\n. Интуитивно это похоже на проверку, а не слишком ли много мы достали объектов False Negative в предположении, что всего их \nM\n штук в нашей отфильтрованной части.\nВ первом случае значение \n, нам оно подходит.\nПробуем уменьшить \nM\n.\nНаше распределение сместилось, вследствие чего \np\nvalue\n уменьшилось, но это значение нам также пока подходит. Двигаемся дальше.\nСледующее значение мы получаем на грани.\nМы пока не отклоняем нулевую гипотезу, но если сместимся еще на единицу, ее придется отклонить при нашем уровне значимости.\nНам нужно последнее подходящее значение, поэтому мы берем предыдущее.\nАналогично выглядит поиск верхней границы, но все зеркально. \nM\n необходимо увеличивать и проверять для конкретного числа. \nP\nvalue \n— это теперь левый хвост распределения. Здесь интуиция такая: а не слишком ли мы мало достали объектов False Negative в предположении, что всего их \nM\n штук в нашей отфильтрованной части.\nБудем двигаться все выше и выше, пока не отклоним нулевую гипотезу. И возьмем значение, которое подходило последним.\nВерхняя и нижняя границы найдены — можно строить интервал для TPR, подставив их в исходную формулу.\nДоверительный интервал в динамике\nРассмотрим, как интервал выглядит в динамике.\nПредположим, мы запустили сервис. На перепроверку отдаем 15% алертов. Эта величина была выбрана в качестве своеобразного \ntrade-off\n, чтобы интервалы оставались широкими не так уж долго — чтобы мы быстрее набирали данные, но при этом все же могли отфильтровывать более 50% алертов.\nКак видно на графике, сразу после запуска сервиса данных пока мало, а неопределенность высока. Но со временем мы набираем данные, и интервалы сужаются.\nДополнительно на этом графике выведен результат «наивного» подсчета — он показывает, насколько в этом случае мы позитивно к себе относимся. Нам такой вариант не подходит.\nЗдесь важно отметить, что наши интервалы покрывают целевое значение, т. е. мы не можем отклонить гипотезу о том, что TPR = 0,98 и можно спать спокойно. Этот «универсальный» подход ненамного сложнее стандартных методов, но решает проблему завышенной оценки.\nИспользование интервала Клоппера — Пирсона\nВ самом начале и по ходу статьи упоминалось, что можно строить так называемый точный интервал Клоппера — Пирсона на основе биномиального распределения. Давайте разберем, как его можно построить — и как от этого меняется вопрос, на который мы себе отвечаем.\nВыше мы видели, что «наивный» подсчет TPR дает нам завышенную оценку. Решение этой проблемы, которое было представлено выше, опиралось на то, что величина TP (True Positive — отдали релевантный алерт) у нас полностью известна и фиксирована, а вся неопределенность у нас в величине FN (False Negative — отфильтровали релевантный алерт). Но «наивный» подсчет можно подправить еще одним способом.\nЕще раз посмотрим на наивный подсчет TPR более наглядно.\nИз картинки видно, что мы в неравной степени учитываем объекты из двух групп (Filtered и Not filtered). То есть наша выборка нерепрезентативна для оценки доли. Чтобы это исправить, нам нужно сделать так, будто мы из группы Not filtered берем тоже x% от алертов True Positive. Это сделать достаточно просто, а именно — в формуле для TPR умножить число TP на \n, то есть на долю перепроверки. Тогда это будет равноценно тому, что мы в равной степени берем объекты из двух групп.\nДавайте теперь проведем симуляцию нашей схемы перепроверки и посмотрим, что мы получим в этом случае.\nАга, видим теперь, что скорректированный TPR дает нам несмещенную оценку. Еще видим, что при увеличении процента перепроверки у нас уменьшается дисперсия оценки. Здесь мы убрали случай, когда мы не проверяем наш сервис, так как с точки зрения математики получаем неопределенность, по формуле получаем \n. \nНо важно отметить, что это согласуется с интуицией, так как, ничего не проверяя, мы в полной степени не уверены в том, что там у нас происходит.\nТакже видим знакомую картину — ее мы уже видели, когда рассматривали асимптотический доверительный интервал для доли. А именно: если давать на перепроверку не много данных, распределение статистики несимметрично, и тогда не совсем корректно использовать асимптотический доверительный интервал на основе нормального распределения.\nЗдесь нам на помощь приходит интервал \nКлоппера — Пирсона\n. По сути, этот интервал строится тем же методом, что мы описали выше. Просто в данном случае мы перебираем сразу значения для доли, то есть значения TPR. А в статистическом тесте теперь мы используем биномиальное распределение. Грубо говоря, проверяем следующее: «Окей, а какова вероятность увидеть такие или еще более экстремальные данные в предположении о том, что доля имеет конкретное значение?», как с фиксированием параметра \nM\n в методе выше. Методы аналогичны, просто под капотом используем разные распределения. И если вы разобрались в методе, который мы описали ранее, то с этим методом будет еще проще. Но тут дополнительно приходит на помощь связь биномиального распределения с бета-распределением, и поэтому в данном случае нам не требуется перебирать значения для доли. Границы можем получить сразу, вычислив квантили соответствующего бета-распределения.\nВажно отметить, что здесь получаются немного другие обозначения. Теперь параметр \n который мы хотим оценить, это непосредственно TPR.  \nВеличина \n— размер выборки. \nВеличина \n — количество верно отфильтрованных алертов в нашей выборке. \nТогда \n— наше биномиальное распределение.\nЗдесь может возникнуть вопрос: вроде бы биномиальное распределение — это про схему выборки с возвращением, а тут у нас выборка без возвращения, как же так? Действительно, на практике почти всегда, по сути, мы имеем выборку без возвращения, да и размер генеральной совокупности тоже не бесконечен. Но в нашем случае, когда размер выборки (величина n) много меньше размера генеральной совокупности (величина N), из которой мы сэмплируем, схему выборки без возвращения можно заменить схемой выборки с возвращением. То есть мы аппроксимируем гипергеометрическое распределение биномиальным.\nА почему мы можем сделать предположение, что n << N в нашей задаче? Здесь все просто: мы считаем, что наша генеральная совокупность — это алерты, по которым еще не вынесли вердикт аналитики или которые должны быть в будущем. То есть наша оценка теперь предполагает такую схему:\nДавайте рассмотрим в динамике доверительные интервалы, построенные с помощью двух методов, и сравним их.\nНа графике мы дополнительно отметили красными точками скорректированный TPR. Первое, что видим по красным доверительным интервалам, это то, что доверительные интервалы вовсе не обязаны быть симметричными. И это логично, так как за 1 мы выйти не можем, и ранее мы видели, что в крайних значениях для доли распределение статистики у нас не симметрично. Второе: видим, что интервалы Клоппера — Пирсона шире, чем интервалы на основе гипергеометрического распределения, что тоже соответствует тому, что мы моделируем и оцениваем. Если раньше мы отвечали на вопрос, сколько или какую долю алертов мы\n отфильтровали\n, то теперь мы отвечаем на вопрос, сколько или какую долю алертов мы\n фильтруем. \nТо есть мы распространяем нашу неопределенность еще и на будущее.\nБайесовский подход\nЕсли вам не по душе частотный подход с его формулировками на тему повторения экспериментов с целью получить в 95% случаев какой-то результат, можно использовать другой подход — байесовский. Как и частотный подход, он используется, чтобы как-то выразить неопределенность в отношении параметра, и в какой-то степени больше выражает нашу житейскую интуицию. Если в частотном подходе параметр — фиксированная величина (хоть и неизвестная), в байесовском мы сразу рассматриваем распределение на искомое значение.\nРаспределением мы выражаем нашу уверенность в определенных значениях (в одних мы уверены больше, в других меньше, исходя из данных). По-разному мы интерпретируем и доверительный интервал.\nВ частотном подходе это в большей степени бинарный вывод — подходит или не подходит значение, т. е. это область значений, которые мы не отвергаем на уровне значимости \nα\n. В байесовском подходе мы выражаем эмоции, подразумевая, что с вероятностью (1 – α) значение параметра лежит в заданной области. У меня это ассоциируется с фразой «примерно что-то где-то там»=).\nАпостериорное распределение\nПосле запуска сервиса мы постепенно собираем данные. Апостериорное распределение — это наша уверенность в значениях параметра уже после того, как некоторые данные получены.\nАпостериорное распределение включает следующие элементы:\nправдоподобие — насколько значения параметра согласуются с нашими данными (это мы уже использовали в предыдущем подходе);\nаприорное распределение — это наше знание до проведения экспериментов и получения данных: например, мы могли получить нашу уверенность в значениях из офлайн-экспериментов и затем использовать ее на проде;\nобычная нормализация, чтобы все суммировалось в единицу.\nК нашей задаче это применимо следующим образом. Символов стало больше, но сейчас я напомню, что они означают:\nN — известная величина, сколько отфильтровали (в нашей схеме мы знаем эту величину);\nn — сколько отдали аналитикам на перепроверку;\nk — сколько пропустили;\nM — искомый параметр;\nв знаменателе дроби — все та же нормализация.\nЧасто в литературе можно увидеть в качестве индексов \nN\n и \nM\n, а не как у нас — \nN-n\n и \nM-k\n.\nМне указание только лишь \nN\n и \nM\n не очень нравится, потому что, судя по \nфорумам\n, это смущает людей. Важно писать именно \nN-n\n и \nM-k\n, потому что здесь появляется смещение. Мы рассматриваем схему выбора без возвращения. Когда что-то передаем аналитикам для перепроверки и получаем данные, неопределенность остается только в том, что мы не отдавали — как раз для этого множества алертов мы и выражаем неопределенность.\nНа данный момент мы имеем следующее. Мы не знаем априорное распределение, но уже можем указать правдоподобие — помним, что у нас схема выборки без возвращения и гипергеометрическое распределение.\nАприорное распределение\nАприорное распределение нам неизвестно, но было бы удобно, если бы оно было сопряженным. Например, предположим, что априорное распределение является нормальным. Объединив это с правдоподобием, получим нормальное апостериорное распределение. Это и означает, что априорное распределение — сопряженное.\nИмея сопряженное априорное распределение, в качестве бонуса мы получаем удобство расчетов.\nВернемся к схеме фильтрации, чтобы вывести априорное распределение.\nС какой-то вероятностью в нашей корзине один алерт будет False Negative (неверно отфильтрованным). Здесь мы можем применить схему Бернулли. Если алерт один — это распределение Бернулли, а когда их много — это биномиальное распределение.\nПараметр p нам неизвестен, но мы опять же можем рассмотреть нашу модель при каком-то значении параметра.\nЗафиксируем некоторое значение параметра p и тогда получим вполне определенное биномиальное распределение. Я привел несколько на изображении ниже, там же я показал априорное распределение, которое выражено бета-распределением. По ходу дела мы увидим, почему именно его берем.\nНо уверенность в разных значениях p разная. Допустим, p = 1. Это значит, что все, что мы отфильтровали — False Negative, но это не так (мы все-таки верим в нашу модель).\nТаким образом, у нас есть несколько биномиальных распределений. Чтобы получить одно распределение, их нужно объединить, причем пропорционально нашей уверенности в каждом из них.\nРассмотрим это более формально. Здесь приведено биномиальное распределение (при фиксированном параметре p). Априорное распределение при этом выражено бета-функцией.\nЕсли вас пугает вид бета-функции, то расслабьтесь, сам интеграл в этой функции нам не важен=). Самое главное для нас — это то, как аргументы бета-функции соотносятся со степенями в выражении этой функции. Просто подставим все известные выражения в интеграл. В результате магии чисел мы получаем также бета-функцию, но уже с другими аргументами, А штука, которую мы получили в результате, называется бета-биномиальным распределением.\nБета-биномиальное распределение интерпретируется как схема Бернулли с неизвестной вероятностью «успеха». А это как раз то, что мы имеем в нашей схеме перепроверки.\nПараметры α и β — это наши априорные знания:\nα — количество «успехов» до опыта (количество алертов False Negative, полученных, например, в офлайн-экспериментах, когда мы тестировали модель);\nβ — количество «неудач» до опыта (количество алертов True Negative — то, что мы верно отфильтровали).\nЗдесь может показаться немного странным употребление слов «успех» и «неудача». Это в своем роде устоявшиеся обозначения для схемы Бернулли. Особенно если вспомнить о применении этой схемы в моделировании неисправностей приборов или, более того, в оценке рисков, где успехом считается неблагоприятное с точки зрения жизни событие. Поэтому в данном случае мы использовали эти обозначения в кавычках.\nИтак, мы получили апостериорное распределение следующего вида:\nЯ привел свойства для вывода — нам необходимо пожонглировать факториалами и сочетаниями. Важно, что в итоговой формуле мы явно видим смещение на параметр \nM\n, т. е. схема как раз учитывает, что мы сделали выборку без возвращения.\nИтак, мы искали сопряженное априорное распределение. И это дало нам огромный бонус — весь байесовский вывод удалось свести к простому сложению-вычитанию (пересчету параметров).\nБайесовский доверительный интервал\nРассмотрим, как это будет выглядеть на примере.\nПредположим, изначально мы не уверены ни в каких значениях.\nМы выполнили перепроверку и получили какие-то данные. Далее мы пересчитываем параметры и получаем новое бета-биномиальное распределение (при этом мы не забываем о смещении).\nИмея построенное распределение, можем выделить область значений, в которых мы в наибольшей степени уверены. Это и будут границы количества алертов, которые мы неверно отфильтровали.\nПосчитаем TPR.\nМы построили границы, вспомнили о смещении. Теперь, чтобы получить байесовский доверительный интервал, нужно то же самое просто подставить в первую формулу.\nПлюс этого распределения в том, что оно имеет реализацию. Нам остается просто подставить значения и рассчитать. Для этого требуется всего несколько строк кода.\nРассмотрим, как это выглядит в динамике. Изначально мы запускаем сервис — неопределенность высока. Постепенно мы получаем данные, и интервал сужается.\nКогда априорное распределение равномерное (т. е. мы ни в каких значениях не уверены), все это похоже на доверительный интервал. Однако важно помнить, что это принципиально другой взгляд. Правда, работать здесь можно точно так же — если бы наш интервал с байесовской точки зрения был далек от целевого значения, пора было бы паниковать. Также на графике представлен случай, когда априорно мы настроены чуть более скептично (красные интервалы). В итоге мы получаем похожую динамику в процессе набора данных, но наши интервалы смещены чуть ниже.\nВ рамках байесовского подхода мы подошли к задаче с другой стороны. На мой взгляд, здесь в большей степени выражается интуиция — мы вывели явное распределение на параметр \nM\n, не забыли о смещении, и это удобно. Результат получили схожий, хотя через совсем другую интерпретацию.\nИспользование биномиального распределения\nКогда мы обсуждали частотный подход, то дополнительно рассмотрели схему с биномиальным распределением, в котором использовали в качестве статистики скорректированный TPR. То же самое мы можем сделать и в рамках байесовского подхода. Тут на самом деле еще проще в плане вывода. Напомню обозначения.\nТеперь параметр \n, который мы хотим оценить, это непосредственно TPR. Величина \n— размер выборки. \nВеличина \n— количество верно отфильтрованных алертов в нашей выборке.\nТогда наше апостериорное распределение будет выглядеть следующим образом:\nИтак, как вы могли заметить, здесь в качестве правдоподобия мы используем биномиальное распределение, а в качестве априорного распределения используем бета-распределение, которое в свою очередь является сопряженным априорным распределением, поскольку на выхлопе мы снова получили бета-распределение. Как я и обещал, здесь вывод распределения еще проще=)).\nИ снова весь байесовский вывод с его интегралами мы свели к простому пересчету параметров.\nАналогично посмотрим на байесовские доверительные интервалы в динамике.\nЗдесь видим картину, похожую на ту, когда мы сравнивали частотные доверительные интервалы с разными распределениями под капотом. А именно, если мы используем биномиальное распределение, то интервалы получаются шире. Как мы уже разбирали, это соответствует тому, что мы накидываем нашу неопределенность еще и на будущие алерты.\nВыводы\nВ этой статье я хотел показать, как мы решаем проблемы. На одну и ту же вещь можно смотреть с разных точек зрения даже внутри одного подхода (вспоминаем разные распределения под капотом). Мы привыкли сравнивать методы — что лучше, что хуже. Но в данном контексте выбор сводится к тому, как вам удобнее рассуждать и чем оперировать. Также выбор сводится к тому, а на какой вопрос вы хотите ответить с помощью статистики, неважно — байесовской или частотной. Конечно, стоит пользоваться именно тем, что ты хорошо понимаешь, потому что при решении задачи нужно оперативно интерпретировать результаты и донести их до других. А в таких проектах, как наш, умение понять и быстро объяснить результат является критическим :).\nЕсли вам удобнее формулировать, что «с вероятностью 0,95 значение параметра лежит в данной области», выбирайте байесовский подход. Лично мне привычнее и интуитивно понятнее частотный подход, в рамках которого мы говорим, что «если будем повторять эксперимент много раз, с вероятностью 0,95 наш интервал будет накрывать истинное значение параметра». Именно поэтому в нашем проекте мы выбрали частотный подход. К байесовскому же подходу мы обращаемся тогда, когда с ходу неясно, как можно построить интервал с помощью частотного подхода, и нужно оценить поведение интервалов в динамике. Хотя признаюсь, что изначально я был большим фанатом байесовского подхода. Но со временем пришло осознание того, что не стоит себя ограничивать в рамках одного подхода или парадигмы. Ведь в конечном итоге у этих двух подходов одна цель — выразить с помощью математики нашу неопределенность.\nЕсли вам интересны подобные задачи, если хочется погрузиться в недра построения моделей машинного обучения и благодаря этому строить безопасное будущее, приходите \nк нам в команду Data Science & Big Data\n. С помощью больших данных мы совершенствуем продукты компании и оптимизируем бизнес-процессы. У нас множество задач, связанных с контентной фильтрацией по категориям, которая в конечном счете помогает лучше справляться с угрозами безопасности. А если вам интересно копаться в описанных мной проблемах именно со стороны ИБ и противодействия атакам, то обязательно загляните к моим коллегам в подразделение Security Services, где открыты вакансии \nстаршего SOC-аналитика\n, а также \nспециалиста по реагированию на инциденты\n.\n \n ",
    "tags": [
        "алгоритмы",
        "машинное+обучение",
        "machine learning",
        "data science",
        "big data",
        "bigdata",
        "большие данные",
        "анализ данных",
        "data engineering",
        "информационная безопасность"
    ]
}