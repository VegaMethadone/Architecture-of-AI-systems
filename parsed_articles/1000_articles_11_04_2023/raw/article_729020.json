{
    "article_id": "729020",
    "article_name": "Зачем нам Reactive и как его готовить",
    "content": "Привет! Меня зовут \nТатьяна Руфанова\n. Сегодня мы будем понимать и принимать Reactive (Реактив). В статье расскажу, почему мы выбрали Реактив в мидл слое мобильного приложения Альфа-Банка (а у нас 300 микросервисов и треть из них реактивные), разберём, почему «нелогичное» поведение реактивной программы на самом деле очень логичное, какие сложности реактивный подход принесёт в процессе написания и исполнения кода, и как с этим бороться. А чтобы не траблшутить в проде, будем ломать тесты на Project Reactor.\nНалейте чаю, включите звуки природы и настройтесь пройти все стадии принятия Reactive.\nНемного о себе: работаю в Альфа-Банке уже 5 лет, участвую в продуктовой и внутренней разработке, 3 года мы с командой пишем реактивный код.\nПочему мы используем Реактив в Альфа-Банке\nНагруженный микросервис до переписывания…\nНа картинке реальный мониторинг одного из нагруженных микросервисов Альфа-Банка в его «дореактивный» период\n. \nПриложение запущено в 8 инстансах, чтобы суммарно держать 750 запросов в секунду.\n750 запросов в секунду\nПри этом на сервисах бэка, к которым обращается наш микросервис, могут происходить тайм-ауты, что сразу сказывается на времени ответа.\nТаймауты в 10 секунд\nПомимо времени ответа, таймауты бэкэнда влияют на «здоровье» микросервиса — он обрастает потоками, и в какой-то момент начинает перезапускаться.\nПотоки упираются в потолок и сервис перезапускается\nПочему так происходит? \nУ нас обычное приложение с бизнес-логикой: собери данные из нескольких сервисов, сходи в базу, кэш, соедини всё вместе и отдай наружу — никаких сложных вычислений. Зато много клиентских запросов, каждый из них порождает параллельные вызовы во внешние источники данных, а они, в свою очередь, могут долго отвечать. \nЧто делать, чтобы выдерживать пиковые нагрузки? \nУвеличивать количество потоков в пулах севера Tomcat.\nУвеличивать количество потоков в пулах внешних вызовов Hystrix.\nУвеличивать память и ЦПУ самому приложению (потокам нужны ресурсы).\nУвеличивать количество инстансов.\nИли…\n…переписать всё на Реактив! Ведь в нашем бизнес-приложении потоки большую часть времени заблокированы вводом/выводом и ждут, когда кто-нибудь пришлёт им данные по сети — \nпотребляют ресурсы и ничего не делают!\n…И после переписывания на Реактив \nМониторинги того же приложения, но уже в реактивном исполнении. \nВ 2,5 раза больше запросов в секунду (в пике почти 2000) на меньшее количество инстансов, всего 5.\n2000 запросов в секунду\nТаймауты внешних вызовов по-прежнему случаются.\nТаймауты в 10 секунд\nНо при этом количество потоков стабильно небольшое: 60 против 350.\nМенее 60 потоков\nПочему так? \nПотому что микросервис неблокирующий, теперь он на Webflux и Project Reactor, которые хорошо работают с IO. Точнее с NIO — неблокирующим вводом-выводом. \nВ отличие от Tomcat, где под каждый блокирующий вызов создаётся отдельный поток, в Webflux другая модель: \nнебольшое количество потоков бегает в цикле событий ввода вывода (event loop);\nи как только для какого-то ранее приостановленного реактивного стрима приходит событие о том, что ввод или вывод окончен (то есть мы дождались или отправили данные)...\n…поток продолжает выполнять логику этого стрима. \nПолучается, что в нашем приложении для одного клиента выполняем бизнес-логику, пока для другого ждём ответа извне. И всё это в одном и том же потоке.\nЕщё раз подчеркну, что в нашем случае отсутствуют CPU Intensive задачи.\nЕсли бы они были, у потока бы не было «свободного времени», он бы всё время занимался вычислениями. И для обработки большого количества входящих запросов, по-прежнему, потребовалось бы много параллельных потоков.\nНе только теория, но и наш опыт промышленной эксплуатации показывает, что реактивные микросервисы держат нагрузки значительно лучше. \nИз наших 300 микросервисов больше трети уже реактивные и мы не собираемся останавливаться! А чтобы упростить разработку и сопровождение такой большой кодовой базы, мы пишем библиотеки для реактивного логирования, кэширования, трейсинга, метрик, тестирования и прочие утилиты. \nНеобходимость писать библиотеки для реактивного стэка — одна из сложностей использования Реактива\n. Где для обычного многопоточного приложения уже всё написано и работает «из коробки», для реактивного часто нужно «доработать напильником». Но о сложностях поговорим позднее. \nПомимо внутренней оптимизации работы приложения, реактивный подход позволяет выстроить реактивное взаимодействие между сервисами, делая их более отзывчивыми. Приложение может получать на вход и отдавать на выход поток данных по мере их «готовности». Так, например, клиенту банка не обязательно видеть в истории все операции сразу, тем более, что загрузка всего объёма займёт заметное время. Достаточно отобразить первую страницу и, по мере чтения данных из базы, подгружать последующие. \nРеактивное межсервисное взаимодействие останется за рамками этой статьи, мы будем говорить исключительно про внутренности. \nА сейчас предлагаю разобраться с тем, что такое же такое Реактив.\nЧто такое Реактив в Java\nReactive Streams и причем здесь Project Reactor\nЕсли ничего не работает, почитайте документацию\n… Немного теории. \nЗдесь рекомендую познакомиться с \nThe Reactive Manifesto\n, если ещё не знакомы. Манифест описывает принципы реактивного подхода в общем. Дальше мы будем говорить про реализацию в JVM, а именно про спецификацию \nReactive Streams\n.\nЦель Reactive Streams — найти минимальный набор интерфейсов, методов и протоколов, который опишет необходимые операции и сущности для реализации асинхронного потока данных с неблокирующим обратным давлением (non-blocking backpressure). \nОбратное давление\n — это механизм, с помощью которого каждый метод обработки потока данных может управлять количеством входящих в него данных, не блокируя при этом поток. Например, когда источник отдаёт данные быстрее, чем потребитель может их обработать, backpressure поможет выровнять скорость между источником и потребителем.\nСогласно спецификации реактивный стрим должен:\nобработать потенциально бесконечное количество элементов;\nпоследовательно;\nасинхронно передавая элементы между компонентами;\nс обязательным неблокирующим обратным давлением.\nСама спецификация Reactive Streams состоит из следующих частей:\nAPI\n — определяет интерфейсы для реализации Reactive Streams, а также позволяет совмещать различные реализации.\nSpecification\n — сама спецификация, в которой описано, как должны вести себя реализации этих интерфейсов.\nThe Technology Compatibility Kit (\nTCK\n) — минимальный набор тестов для проверки соответствия спецификации.\nВот эти самые интерфейсы (API). \nИнтерфейсы Reactive Streams и взаимодействие между ними\nНас будут интересовать Publisher, Subscriber и Subscription.\nPublisher\n — это источник данных, на который можно подписаться методом subscribe.\nSubscriber\n — потребитель: после подписки может получать события жизненного цикла стрима (onSubscribe, onError, onComplete) или данные, ради которых всё и затевалось, они же элементы реактивного стрима (onNext).\nSubscription\n — результат подписки потребителя на источник, с помощью которого можно запросить n элементов (request) или отменить подписку (cancel).\nВ Java все контрибьютят как могут, реализаций Reactive Streams много. Вот некоторые из них: \nРеализации Reactive Streams\nСамая популярная реализация, пожалуй,\n Project Reactor\n (настоятельно рекомендую к прочтению \nReactor 3 Reference Guide\n целиком). И, что приятно, с ней хорошо интегрируется Spring Framework, который активно используется в микросервисах Альфа-Банка.\nНа диаграмме классов видно, как взаимосвязан интерфейс реактивных стримов Publisher с двумя основными классами Reactor, Flux и Mono. \nДиаграмма наследования классов Project Reactor от Reactive Streams\nОба класса — источники данных с той разницей, что Flux отдаёт потенциально бесконечное количество элементов, а Mono не больше одного.\nЖизненный цикл реактивного стрима\nЖизненный цикл пригодится, когда мы будем говорить про накладные расходы (overhead), производительность, работу операторов и потоки. Давайте напишем небольшой реактивный стрим и рассмотрим этапы его сборки, подписки и исполнения.\nВсе примеры кода можно найти здесь: \nhttps://github.com/tirufanova/reactor-exx\n.\nСборка\nВ примере кода ниже:\n.range создает последовательность элементов от 5 до 100;\n.map преобразует каждый элемент в строку;\n.filter оставляет в стриме только строки, длина которых равна 1;\n.take берет из всей последовательности только 3 первых элемента.\n \nAssemblySubscriptionExecutionTest::assemble\nСборка реактивного стрима\nНа оператор .hide не смотрите, он здесь для того, чтобы убрать внутренние оптимизации библиотеки, которые могут помешать нам \nпоймать дзен\n понять Реактив.\nПроцесс сборки стрима идёт сверху вниз, по мере того, как программа выполняется. Каждый раз на каждом операторе создаётся по дополнительной обертке — «флаксу» — в примере получилось 5 штук.\nПодписка\nНа предыдущем шаге мы только собрали цепочку операторов, которые обрабатывают элементы, но никакой обработки по факту не произошло, потому что нам нужно подписаться на стрим. Для этого подойдёт метод .blockLast, который под капотом вызывает subscribe источника (Flux).\nAssemblySubscriptionExecutionTest::subscribe\nПодписка на реактивный стрим\nПодписка происходит снизу вверх: \nсначала оператор .blockLast подписывается на оператор .take;\nоператор .take подписывается на .filter;\nи так далее, пока кто-то не подпишется на первый Flux.range.\nИ здесь на каждом вызове создаются новые обертки-декораторы. Ещё 5 пять объектов в дополнение к тем, что уже были созданы на этапе сборки. \nИсполнение\nЦепочка собрана, на неё подписался потребитель. Логично, что данные (элементы стрима) идут сверху вниз, от источника к потребителю. Но по реактивному стриму проходят не только элементы, но и события. А вот с ними не всё так однозначно. Добавим в реактивную цепочку две точки логирования (метод log), чтобы увидеть события.\nAssemblySubscriptionExecutionTest::execute\nИсполнение реактивного стрима\nПервым видим сигнал request. Элементы по стриму не начнут идти, пока они не будут запрошены (request). Это тот самый backpressure из реактивного манифеста и реактивной спецификации. Сигнал запроса идёт снизу вверх, от потребителя к источнику.\nЗапрос элементов, он же backpressure\nBackpressure позволяет регулировать, сколько данных мы готовы принять и обработать. В нашем случае — unbounded — присылай всё и без остановки. \nНа иллюстрации запрос залогирован 2 раза, так как в реактивной цепочке 2 точки логирования. По факту, каждый оператор снизу вверх запрашивает элементы у вышестоящего. При этом количество запрошенных элементов может отличаться в зависимости от внутреннего устройства запрашивающего оператора.\nТеперь, наконец-то, начинают идти элементы по стриму, сверху вниз, как и положено, генерируя события onNext.\nОтправка элементов\nКогда оператор .take насчитает 3 элемента, он отправляет источнику сигнал о необходимости прекратить отправку элементов. Точка логирования с меткой filtered (выше по стриму) поймала это событие. При получении такого сигнала источник должен прекратить отправку.\nОтмена подписки\nА после сигнала для источника, .take вниз отправляет событие о том, что элементы закончились, можно больше ничего не ждать и выходить из метода .blockLast.\nОкончание стрима\nНадеюсь, логика жизни реактивного стрима стала понятнее. И появилось поле для самостоятельных экспериментов. \nУправление потоками\nВ самом начале статьи мы говорили, что \nреактивный подход не даст нам преимуществ в CPU Intensive задачах\n, потому что работает на небольшом количестве потоков (threads). \nДругой случай, когда реактивный подход не подойдет — \nиспользование блокирующих вызовов\n. Всё по той же причине: потоков мало, они заблокируются, и приложение какое-то время не сможет выполнять никакую другую реактивную логику.\nНа самом деле, если по какой-то ведомой разработчику причине (например, блокирующий драйвер к базе данных), подобного рода задачи приходится решать на реактивном стэке, выход есть! \nПо умолчанию реактивный стрим целиком исполняется на том же потоке, на котором был создан (точнее, на котором на него произошла подписка), но этим поведением можно управлять. \nДля этого нам понадобится отдельный \nScheduler — реактивная абстракция пула потоков\n. Например, для блокирующих вызовов документация Project Reactor рекомендует использовать пул Schedulers.boundedElastic(). Осталось разобраться, как переключить нужный оператор реактивного стрима на новый пул.\nДля переключения потока в реактивную цепочку необходимо добавить операторы publishOn либо subscribeOn.\npublishOn\nОператор publishOn изменяет поток на этапе исполнения жизненного цикла, для событий onNext, onComplete и onError. Другими словами, поток меняется для всех операторов, выполняющихся ниже по реактивной цепочке. Это в теории… Посмотрим, что происходит на практике.\nДобавим в реактивную цепочку вызов publishOn с пулом parallel, а также две точки логирования: до переключения потока (с меткой “before”) и после (с меткой “after”).\nPublishOnSubscribeOnTest::publishOn\nПереключение публикации стрима на parallel пул оператором publishOn\nЛогично предположить, что все сообщения с меткой “before” будут выполнены на потоке Test worker (в моем случае это поток JUnit), а с меткой “after” — на потоке пула parallel. Всё правильно, но есть тонкости.\nПрограмма выведет следующий лог.\nЛог событий реактивного стрима с оператором publishOn\nИ, как мы видим, наше предположение сработало не полностью. Действительно, для событий onNext и onComplete с меткой before видим поток Test worker, а с меткой “after” — parallel-1. Но для остальных событий (выделенных жирным) поток выглядит случайным. На самом деле это не так!\nДавайте разбираться. В документации к методу написано, что publishOn изменяет поток при публикации элементов (\nonNext\n), а также при публикации событий окончания стрима и ошибки (\nonComplete\n и \nonError\n). Для всех остальных событий используется поток, на котором произошло предыдущее событие. А именно: \nСобытия \nonSubscribe\n и \nrequest\n происходят на этапе подписки и в начале исполнения стрима, то есть никакая публикация элементов ещё не происходила. Поэтому используется тот же поток, на котором была выполнена подписка на стрим.\nСобытия \nonComplete\n при этом подчиняются тем же правилам, что и onNext. Если бы не оператор .take в нашей цепочке, отправивший сигнал cancel источнику, в логе было бы ещё одно сообщение onComplete с меткой after на потоке parallel-1.\nА вот сигнал \ncancel\n отправляется оператором .take вверх по реактивной цепочке, то есть смена потока опять не происходит. Поскольку оператор .take находится после publishOn, то его сигналы будут обработаны на треде пула parallel.\nА как изменить поток для остальной части реактивной цепочки, для этапа подписки?\nsubscribeOn\nОператор subscribeOn выполняет смену потока в процессе подписки на реактивный стрим, а именно для событий subscribe, onSubscribe и request. Вспомним жизненный цикл — событие подписки проходит снизу вверх. То есть subscribeOn изменит поток для операторов, которые находятся выше него по цепочке? Почти…\nДавайте возьмем предыдущий пример с теми же метками логирования, но заменим оператор смены потока (вместо publishOn используем subscribeOn).\nPublishOnSubscribeOnTest::subscribeOn\nПереключение подписки стрима на parallel пул оператором subscribeOn\nИ посмотрим, что появится в логе.\nЛог событий реактивного стрима с оператором subscribeOn\nДля первых четырех сообщений метка “after” соответствует потоку Test worker, а метка “before” — потоку пула parallel. \nДействительно, в момент подписки и запроса элементов событие проходит снизу вверх по реактивной цепочке: сначала выполнится “after”, а потом “before” уже на новом потоке. Но метод subscribeOn никак не влияет на то, что происходит после подписки. Поэтому события остальных фаз жизненного цикла будут происходить на потоке, который был установлен в момент подписки оператором subscribeOn, то есть parallel-1. Вне зависимости от направления сигнала.\nОтсюда следует правило: subscribeOn должен находиться как можно ближе к источнику (условно, следующим оператором после источника в реактивной цепочке), а publishOn — как можно ближе к операции обработки, которую хотим переключить на новый пул (непосредственно перед самой операцией). \nЧтобы лучше понять это правило, попробуйте в примере выше использовать сразу оба оператора subscribeOn и publishOn, а потом поменять их местами. Сообщения в логе в этих двух случаях будут абсолютно разными.\nНеявная смена потока\nОператоры subscribeOn, publishOn, сигналы, события… Запутано, но код хотя бы делает то, что обещает — явно изменяет поток исполнения.\nТеперь давайте уберём из нашей подопытной реактивной цепочки все операторы смены потока. А вместо них добавим новую логику обработки, метод .delayElements: отдавай каждый следующий элемент вниз по реактивной цепочке с задержкой в 5 наносекунд. \nImplicitThreadSwitchTest::delayElementsThread\nРеактивный стрим с задержкой публикации элементов\nТочки логирования остались те же, давайте смотреть логи.\nЛог исполнения стрима с задержкой публикации\nИ… откуда-то взялись новые потоки! Причём разные. \nСпасибо документации метода delayElements, в ней явно описано, что дальнейшее исполнение стрима будет происходить на пуле parallel. Хотя такой побочный эффект совсем не очевиден из названия метода.\nНа самом деле, \nреактивный scheduler значительно более мощный инструмент, чем просто пул потоков.\n Он позволяет планировать отложенное выполнение какой-либо логики. Например, задерживать публикацию элементов: получи элемент из оператора выше по цепочке, подожди, только потом отправь элемент дальше. \nВо внутренней реализации метод .delayElements как раз использует отложенную публикацию на parallel пуле. Метка “after” после оператора .delayElements выводит поток для такой отложенной публикации (onNext). А cancel уже выполнится на том потоке, который оставила предшествовавшая ему отложенная публикация.\nВ реальной жизни не так часто возникает необходимость задерживать обработку полученных элементов. А объединять элементы из нескольких реактивных стримов — задача практически ежедневная. Например, чтобы собрать из нескольких внешних запросов общий результат. \nОбъединить несколько стримов помогут такие методы, как .merge, concat или zip. В реализации этих операторов явная смена потока отсутствует. Зато может произойти неявная, если один из исходных реактивных стримов запущен другом потоке. Давайте рассмотрим на примере.\nImplicitThreadSwitchTest::mergeDifferentThreads\nОбъединение стримов, публикующихся на разных потоках\nСоберём два реактивных стрима, которые генерируют последовательности чисел. \nПервый, parallelThreadFlux, отдает числа 10, 11 и переключен на отдельный поток.\nВторой, testWorkerThreadFlux, отдаёт 20, 21 и запускается на потоке по умолчанию. \nИспользуем оператор .merge для того, чтобы собрать все числа в одну последовательность. Порядок чисел при этом будет соответствовать очерёдности их получения оператором .merge. И, конечно, расставим точки логирование исходных и результирующего стрима с соответствующими метками.\nЛог стримов, публикующихся на разных потоках\nРазберём сообщения в логе. Первые шесть строк: сначала оператор blockLast инициировал подписку (и запрос элементов) на оператор merge, после чего внутри оператора merge произошла поочерёдная подписка на все стримы, которые ему необходимо объединить. Все подписки и запросы элементов произошли на потоке Test worker, потому что никаких смен потока не происходило. \nПосле запроса элементов по стримам начали идти данные. По меткам testWorker и parallel для событий onNext мы видим, что parallelThreadFlux публикует элементы на parallel пуле, а testWorkerThreadFlux на потоке на Test worker, как и ожидалось. А вот результирующая последовательность (метка merge, выделена жирным в логе) постоянно меняет поток в зависимости от того, на каком потоке (из какого стрима, соответственно) получен исходный элемент. Таким образом смена потока для результирующего стрима происходит неявно.\nПочему важно помнить про неявную смену потока? Потому что она может «портить» предшествующую явную смену потока операторами publishOn и subscribeOn, и ваша логика запустится совсем не там, где вы ожидаете. Чтобы избежать такого поведения, используем publishOn и subscribeOn как можно ближе к логике, нуждающейся в отдельном потоке.\nСамое время вооружиться всеми полученными знаниями и оценить сложности Реактива. \nКакие сложности приносит Reactive и как с этим бороться\nСложности при написании программы\nКод становится непонятнее.\nОбъективно нам стало сложнее. Если в императивном исполнении код будет понятен любому начинающему программисту…\nReadabilityTest::imperativeVsReactive\nИмперативный код\n…то переписанный на Реактив тот же самый код уже требует значительно больше знаний. Обрастает «служебными» методами типа .blockLast. И вдобавок плохо читается.\nРеактивный код\nЭто означает, что порог вхождения выше, разработка дольше, а ошибок потенциально больше.\nПоэтому лучше не использовать «реактивщину» там, где она не нужна\n, например, где маленькая нагрузка, нет большого числа внешних вызовов или не требуется высокая отзывчивость (то есть отдавать данные как можно скорее по мере их получения, а не все сразу). Если вы всё-таки решили использовать Реактив, его придется изучить.\nДаже если код уже реактивный, не стоит переделывать на Reactor всё подряд. Часто индикаторы того, что вы что-то делаете не так, это вызовы в реактивном коде методов Flux.just, Flux.fromIterable и block*. Подумайте, нельзя ли решить задачу с помощью коллекций, нереактивных стримов или императивного кода? Или остаться в реактивном подходе, но подобрать более подходящие операторы? Это снизит шансы выстрелить себе в ногу.\nИ, конечно, пишите тесты!\n В этом поможет библиотека io.projectreactor:reactor-test. Она содержит инструменты для проверки поведения реактивного стрима или реактивной логики, обрабатывающей реактивный стрим.\nПомимо сложностей понимания кода, длинные реактивные цепочки порождают и другую сложность, а именно длинный стэк.\nСтэк становится длиннее.\nИ непонятнее. \nВ процессе отладки мы увидим примерно следующее.\nСтэк вызовов реактивного стрима\nА где, собственно, наш код?.. А, маленькая строчка внизу экрана. Понять, что именно происходит в процессе исполнения программы, даже опытному разработчику, достаточно сложно. \nПлюс получаем оверхэд в процессе исполнения. Но об этом чуть позже.\nКак помочь себе с отладкой?\n Можно использовать оператор .log(), он позволяет залогировать события жизненного цикла стрима с заданной меткой, в том числе элементы данных, проходящие через стрим.\nОшибки искать сложнее.\nКогда мы видим стектрейс исключения (который стал длиннее, см. пункт выше), непонятно, что и где сломалось. В стектрейсе будет множество служебных реактивных обёрток, и, с большой вероятностью, наш код просто не влезет. А так как в коде приложения происходит только сборка стрима и подписка, а исполнение идёт в недрах Реактива, явная ссылка на логику, породившую ошибку, может вообще отсутствовать в стэке.\nЗдесь на помощь придёт библиотека io.projectreactor:reactor-tools, которая \nдобавит в стэк вызовы нашей программы\n, чтобы мы смогли сопоставить исключение с кодом приложения. Одно из приятных свойств этой библиотеки то, что она не добавляет оверхэд в процессе выполнения программы, а это значит, что её можно использовать в продакшн.\nВторой важный момент, который сильно упростит жизнь — \nлогируем ошибки явно\n. Для этого максимально используем оператор onError. Он должен быть как можно ближе к потенциальному месту исключения. Лучше написать лишний onError, чем в логах не найти, где именно произошла ошибка.\nНеобходимо дорабатывать инструменты.\nВыше мы много говорили про смену потоков. Реактив не даёт никаких гарантий, какая часть кода запустится в какой момент и на каком потоке, поэтому многие традиционные инструменты перестают работать. Где-то уже есть реактивные аналоги, а остальное придётся дорабатывать под себя и Реактив. \nПрямое следствие смены и переиспользования потоков различными операторами реактивной цепочки то, что ThreadLocal переменные ломаются. Точнее, сами ThreadLocal, конечно, работают, а вот трэйсинги, контексты логирования, данные клиентских запросов, использовавшие эти локальные переменные в многопоточном коде, в реактивном не годятся.\nПростой способ добавить контекст к реактивному стриму — явно передавать его вместе с элементами стрима\n. Подход надёжный, понятный, но портит архитектуру приложения. Реактивный способ решения задачи — использование контекста (Context) библиотеки Reactor. \nКонтекст — это аналог Map\n: также хранит в себе пары ключ-значение, позволяя записывать и считывать их. Контекст неизменяемый (immutable), то есть при добавлении к нему нового значения создаётся новый экземпляр контекста. Контекст привязывается к реактивному стриму на этапе подписки, то есть виден только операторам, которые находятся выше его в реактивной цепочке.\nПодход нужен чаще для написания библиотек, а не кода приложения, поэтому подробно останавливаться не будем. Продолжим разбираться со сложностями и перейдём от написания программы к её исполнению.\nСложности в процессе выполнения программы\nКак влияет на работу нашего приложения создание всяких обёрток? Мы говорили про длинный стек. Собственно, вот он.\nОбертки-декораторы\nСтэк состоит из тех самых оберток, через которые проходят наши элементы.\nЧем это плохо? Оверхедом:\nБольше объектов, длиннее стэк – больше потребляемой памяти.\nМного маленьких объектов — больше работы для GC.\nПортим оптимизации JIT компилятора.\nОграничения оптимизаций JIT компилятора\nКак мы с этим боремся?\nИзучаем операторы\n, которые используем (у Project Reactor очень хороший официальный гайд). Некоторые операторы могут добавлять накладные расходы, генерировать маленькие объекты (например, очереди) под капотом, хотя для нашей задачи мог бы подойти оператор попроще. \nСтараемся не делать длинных реактивных цепочек\n, по возможности \nобъединяем операторы\n. Например, из нескольких последовательных операторов filter всегда можно сделать один.\nИспользуем оператор\n .handle. Он тоже позволяет объединять логику нескольких операторов и объединяет логику .map и .filter. Если в случае с .map и .filter. у нас создается 4 дополнительных объекта,… \nHandleTest::withoutHandle\nПоследовательность из нескольких операторов, map и filter\n…то с .handle всего 2.\nHandleTest::withHandle\nЗамена нескольких операторов map и filter на один handle\nОговорюсь, что не стоит увлекаться преждевременными оптимизациями\n. Если у вас нет проблем с производительностью реактивного приложения и в нём отсутствуют длинные реактивные цепочки, то код с .map и .filter читается значительно лучше. А Project Reactor достаточно умный, чтобы делать собственные оптимизации под капотом. Как всегда, серебряной пули не существует, ищите свои рецепты, проверяйте на практике.\nТеперь самое время перейти к ней, к практике.\nКак сломать реактивный стрим\nРеактив позволяет выполнять (условно) параллельную обработку данных, берёт на себя все сложности работы с многопоточностью. В его арсенале множество операторов манипуляции с данными и самими реактивными стримами. Но как бы не были скрыты сложности многопоточности, иногда непонимание внутреннего устройства может привести к тому, что обработка данных пойдёт не по плану. \nСейчас мы наконец-то что-нибудь сломаем! Для этого нам понадобится два оператора — groupBy и flatMap. \nОператор groupBy\nОператор groupBy разбивает исходный стрим на множество отдельных стримов по какому-то условию. Похож на работу оператора groupBy в Java Stream API.\nFlux::groupBy\nОператор groupBy\nЗдесь нас интересует prefetch — это количество элементов, которые оператор предподгружает из реактивного стрима в свой внутренний буфер. В событиях реактивного стрима мы увидим его как backpressure, запрос элементов. Значение по умолчанию 256. \nОператор flatMap\nРаботает наоборот, а именно:\nпреобразует каждый элемент исходного реактивного стрима в новый реактивный стрим (с помощью функции, которую получает на вход);\nзатем сливает эти внутренние стримы в один;\nпри этом элементы из внутренних стримов будут чередоваться.\nТоже похож на оператор flatMap в Java Stream API.\nFlux::flatMap\nОператор flatMap\nЕсли посмотреть документацию, то мы найдём интересный параметр — concurrency. Он задаёт максимальное количество внутренних стримов, которые одновременно может объединять оператор flatMap. Значение по умолчанию — 256. То есть потенциально flatMap объединит любое количество стримов, но чтобы перейти к обработке 257 стрима, один из первых 256 должен завершиться.\nСобираем стрим\nВ руководстве Project Reactor \nвисит ружье, которому пора выстрелить\n есть примечание: если воспользоваться одновременно groupBy и flatMap, то при большом количестве групп в groupBy (high cardinality) и низкой конкурентности flatMap (одновременно обрабатывается мало стримов, low concurrency) обработка стрима может зависнуть (lead to hangs). \nПримечание о взаимодействии между groupBy и flatMap\nКазалось бы, у нас неблокирующая обработка, как она может зависнуть? Звучит странно. Давайте разберёмся. \nДопустим, у нас есть список имён — входной стрим namesFlux. \nИ нам нужно посчитать количество имён по первой букве — функция countNamesFunction.\nДля этого сначала сгруппируем имена по первой букве оператором groupBy, применим функцию подсчёта countNamesFunction и соединим результаты обратно в общий стрим оператором flatMap.\nПо всем стримам расставим точки логирования: в функции подсчёта имен, а также перед оператором groupBy и после flatMap.\nGroupByWithFlatMapNamesTest::completeNamesCount\nПодсчет имён\nПока всё идет по плану, в логе появятся следующие значения для 4 групп имен (остальные события опущены для краткости): \nГруппы имён по первой букве\nВ нашей цепочке недостаточно много групп и не такая низкая конкурентность, чтобы всё сломалось. Будем это исправлять, зададим конкурентность 3 для flatMap (достаточно мало для четырёх групп). \nЧтобы добиться зависания на нашем объёме данных, понадобится также поменять prefetch для оператора groupBy, сделаем его 3. Чуть позже станет понятно, почему именно это «магическое число».\nРеактивный стрим подсчета имён теперь выглядит так.\nGroupByWithFlatMapNamesTest::timeoutNamesCount\nНастраиваем реактивную цепочку подсчёта имен\nИ он зависнет! Чтобы понять, почему, разберём логи. \nЛог поломанной реактивной цепочки\nВот что происходит, построчно:\n1, 2 — события подписки.\n3 — запрос бесконечного количества элементов оператором blockLast.\n4 — запрос трёх элементов оператором groupBy (значение параметра prefetch).\n5 — источник namesFlux получил запрос и начал отправлять элементы, первый Carl.\n6, 7 — groupBy обработал первый элемент, создал группу для буквы C и отдал реактивный стрим с группой оператору flatMap. Тот, в свою очередь, подписался на группу и запросил 32 элемента для подсчёта имён.\n8 — groupBy ожидает ещё 2 элемента в ответ на первый запрос элементов (в строке 4), но так как значение prefetch равно 3, запрашивает ещё один элемент.\n9-16 — аналогично 5-8, создалось ещё 2 группы, теперь flatMap подписан на 3 реактивных стрима (для первых букв C, D, A). Новые подписки он создавать не будет, пока какой-то из текущих стримов групп не завершится.\n17-19 — groupBy получил ещё три элемента. Но все эти имена относятся к новой группе на букву B, а flatMap больше не создаёт новые подписки. Оператор groupBy при этом не запрашивает новые элементы, так как prefetch равен 3 и ровно столько же элементов ещё не отправлено дальше по стриму. И поскольку новые элементы не запрашиваются, groupBy не знает, можно ли завершить какую-то из предыдущих групп, так как событие об окончании стрима придёт только после следующего элемента Alice.\nВсё, стрим заблокирован. \nВ реальной жизни, на б\nо\nльшем объёме и разнообразии данных, блокировка может произойти и для значений prefetch и concurrency по умолчанию.\nПоэтому важно понимать, какие именно данные проходят через реактивный стрим и как работают операторы, которые их обрабатывают. Возможно для конкретной задачи необходимо поменять значения по умолчанию или выстроить логику обработки по-другому.\nЗаключение\nРеактив — мощный инструмент, который позволяет строить высоконагруженные отзывчивые приложения. Мы в Альфа-Банке убедились в этом на практике. \nВместе с тем важно понимать, какой именно профит даст реактивный подход для конкретной задачи. Ведь вместе \nс большой силой приходит большая ответственность\n с большими возможностями приходят и новые вызовы для разработчика.\nРеактивный код имеет структуру и логику исполнения отличную от императивного многопоточного. \nЭто заставляет разработчика думать по-другому. А также менять привычные инструменты тестирования, трассировки, логирования, взаимодействия с внешними сервисами и т.д.\nЧтобы программа делала то, что задумано, важно понимать, как устроены реактивные стримы в целом и конкретные операторы. \nПомогут в этом документация и инструменты реактивного тестирования, логирования и обработки ошибок.\nИ конечно, Реактив иногда подкидывает головоломки. Разбираться в них может быть непросто, зато очень интересно.\nИспользуйте Реактив с удовольствием.\nРекомендуем почитать [подборка от редактора]\nКем вы видите себя через 6 лет в тестировании?\nУ нас была стратегия и мы её придерживались: как подружить бизнес и DevRel, сохранив ментальное здоровье\nXSS атакует! Краткий обзор XSS уязвимостей\nАрт-терапия и вялотекущая миграция с монолита\nКак мы сайт Альфа-Банка на митапе шатали и нам за это ничего не было\nПочему мы ошибаемся при первоначальной оценке фич?\nКак в банке внедрить облачные технологии так, чтобы это было удобно, безопасно, быстро и дёшево\nА работают ли игровые механики?\nПро микросервисы на примерах\nКак мы ведём требования к ПО: формализация\nТакже подписывайтесь на Телеграм-канал\n Alfa Digital\n — там мы постим новости, опросы, видео с митапов, краткие выжимки из статей, иногда шутим.\n \n ",
    "tags": [
        "java",
        "project reactor",
        "reactive streams",
        "реактив",
        "реактивные стримы",
        "webflux",
        "инстансы",
        "микросервисы"
    ]
}