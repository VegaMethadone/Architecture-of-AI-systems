{
    "article_id": "726672",
    "article_name": "Микросервисы сына маминой подруги. Пишем правильные микросервисные приложения на Java",
    "content": "Всем привет! Сегодня я решил написать статейку про всеми любимые микросервисы. Если вы давно хотели изучить тему микросервисных приложении и актуальных технологии, которые используются для их построения, то данная статья должна вам помочь в этом.\nЧто такое \"микросервисы\"\nМикросервисы - это архитектурный подход к разработке приложений, который предполагает разбиение приложения на маленькие и независимые компоненты, каждый из которых выполняет определенную функцию. Эти компоненты могут взаимодействовать друг с другом через API, что позволяет разрабатывать приложения более гибко и масштабируемо. \nЕсли говорить более простым языком, микросервисы - это как Lego для программистов. Вы просто собираете разные кирпичики вместе, чтобы создать красивое здание, а если что-то сломается, то можно легко заменить только нужный кирпичик, не перестраивая всю конструкцию. И да, приятно наступать на микросервисы, потому что они маленькие и не так болят, как большие монолиты!\nАвтор статьи когда придумал аналогию с лего\nМикросервисная архитектура стала такой актуальной, потому что она предоставляет ряд преимуществ, которые важны для современной разработки программного обеспечения:\nГибкость и масштабируемость: микросервисы позволяют быстро и гибко развивать приложения, добавляя новые функции и компоненты. Они также обеспечивают легкую масштабируемость приложений при необходимости.\nРазделение ответственности: каждый микросервис выполняет определенную функцию, что позволяет разделять ответственность между разными командами и упрощает сопровождение приложения.\nНезависимость и устойчивость к ошибкам: каждый микросервис работает независимо от других, что позволяет изолировать ошибки и сбои в работе одного компонента, не затрагивая работу всего приложения.\nЛегкая замена и обновление: микросервисы легко заменять и обновлять, что упрощает поддержку приложения и уменьшает время простоя в случае сбоев или изменений.\nПодход к использованию современных технологий: микросервисы позволяют использовать различные технологии и языки программирования для каждого компонента, что упрощает разработку и повышает производительность. (Но запомните, лучше Java ничего нет)\nКроме того, микросервисная архитектура предоставляет возможность использования облачных технологий и контейнеров, таких как \nDocker\n, что облегчает развертывание приложений и повышает их масштабируемость.\nКак дела у Java с микросервисами\nСегодня \nSpring Boot\n предоставляет огромный пакет инструментов для работы с микросервисами, подробнее с этим топиком вы можете ознакомиться по этой \nссылке\n, ну а мы пойдем дальше и рассмотрим всеми любимый \nSpring Cloud\n. \nSpring Cloud - это набор инструментов, разработанных компанией Spring, которые позволяют быстро и легко создавать микросервисные приложения. Он обеспечивает множество функций, таких как конфигурация, регистрация и отслеживание микросервисов, балансировка нагрузки, трассировка запросов и многое другое.\nДля понимания, насколько важен Spring Cloud, представьте себе, что вы пытаетесь создать микросервисную архитектуру без него. Вы должны были бы написать свой собственный код для каждой из функций, таких как конфигурация, регистрация и отслеживание микросервисов, балансировка нагрузки, и так далее. Это занимает много времени и усилий, и может привести к ошибкам, которые можно было бы избежать с помощью Spring Cloud.\nAPI Gateway и Сервер Реестра Сервисов\nАрхитектура микросервисных приложении на самом деле очень простая и крайне действенная. Главная мысль такой архитектуры состоит в инкапсуляций наших сервисов от запросов из вне. Для коммуникации с нашими сервисами всегда поднимается отдельный API Gateway. \nAPI Gateway\n - это как дверь в космический корабль. Он предоставляет доступ к различным отсекам корабля, но также управляет входящим и исходящим трафиком, чтобы защитить экипаж от космических опасностей. И когда капитан корабля попросит открыть дверь, API Gateway будет готов выполнить свою задачу и позволить ему получить доступ к нужному отсеку! \nНо не все так просто как может казаться на первый взгляд. В первую очередь, для того, чтобы ваш Gateway работал правильно вам нужно иметь tool регистрации ваших микросервисов, иначе gateway не будет знать куда нужно отправлять те или иные запросы. Для этого в Java есть \nSpring Cloud Netflix\n в котором есть прекрасная \nEureka\n. \nSpring Cloud Eureka\n - это сервер реестра сервисов, который используется для обнаружения и регистрации микросервисов в распределенной системе. Он является частью библиотеки Spring Cloud и предоставляет механизмы для управления и мониторинга состояния сервисов в системе.\nПринцип работы Spring Cloud Eureka достаточно прост: каждый микросервис регистрирует себя на сервере Eureka при запуске, сообщая о своем имени, IP-адресе и порте. Затем клиенты могут использовать Eureka для поиска нужных сервисов и получения их адресов.\nТо есть, мы настраиваем наш gateway таким образом, чтобы он мог трекать наш реестр сервисов, брать оттуда нужную информацию о микросервисе и перенаправлять туда наши запросы. Давайте разберем следующий пример:\nGateway настраивается крайне просто, для этого сначала нам нужно добавить 2 dependency в наш Java проект:\npom.xml:\n<dependency>\n      <groupId>org.springframework.cloud</groupId>\n      <artifactId>spring-cloud-starter-gateway</artifactId>\n</dependency>\n<dependency>\n      <groupId>org.springframework.cloud</groupId>\n      <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>\n</dependency>\ngradle.build:\nimplementation group: 'org.springframework.cloud', name: 'spring-cloud-starter-gateway'\nimplementation group: 'org.springframework.cloud', name: 'spring-cloud-starter-netflix-eureka-client'\n\nДалее, мы должны пометить наши Application файлы аннотацией \n@EnableEurekaClient\n для регистрации проектов как микросервисы. (Это нужно сделать как для ApiGateway так и для любого другого микросервиса).\nПоследним шагом остается настройка application.yml или .properties файла следующим образом. Для примера предположим, что у нас есть 2 сервиса куда нужно переадресовывать запросы: Incident-Service и Authentication-Service.\nserver:\n  port: 8083\n\nspring:\n  application:\n    name: api-gateway\n  cloud:\n    gateway:\n      routes:\n        - id: incidents\n          uri: lb://INCIDENTS\n          predicates:\n            - Path=/api/v1/incident/**\n        - id: authentication\n          uri: lb://AUTHENTICATION\n          predicates:\n            - Path=/api/v1/authentication/**\n\n\neureka:\n  client:\n    service-url:\n      defaultZone: http://localhost:8761/eureka\n    fetch-registry: true\n    register-with-eureka: true\nid и uri генерятся в зависимости от поля spring.application.name в вашем конфигурационном файле.\nОбщение Сервисов \nНу вот мы и пришли к нашим любимым брокерам сообщений. Я их называю страшным сном Junior программистов, потому что когда на собесах они слышат такие слова как \"Message Queue\", \"Kafka\" и \"RabbitMQ\" то их лицо покрывается мокрым потом.\nТаска на собесе для Джуна: Напиши мне копию Спринг бута за 15 минут и покрой весь код юнит тестами.\nНа самом деле брокеры сообщений очень крутая и простая штука, которая позволяет оптимизировать работу микросервисных приложении. \nMessage queue\n - это механизм, который позволяет компонентам системы обмениваться сообщениями друг с другом через посредника, называемого очередью сообщений. Очередь сообщений является центральным местом для хранения и передачи сообщений между компонентами системы.\nЕсли представить себе систему как ресторан, то очередь сообщений - это как раз та очередь, которая складывается перед самым популярным блюдом в меню. Как только заказы на это блюдо начинают поступать, официант ставит их в очередь, а повар начинает готовить их по очереди. Таким образом, каждый посетитель получает свою порцию блюда в порядке очереди, без хаоса и конфликтов.\nОднако, также как и в ресторане, очередь сообщений может переполниться, если в системе постоянно поступают большие объемы запросов или компоненты не успевают обрабатывать сообщения быстро. И в этом случае, как и в ресторане, может произойти настоящий \"фуд-файт\", который приведет к сбою в работе системы.\nТак что, если вы решите использовать message queue, не забывайте следить за ее объемами и убедитесь, что все компоненты системы работают в режиме \"один за другим\". И тогда ваша система будет функционировать как швейцарские часы и каждый посетитель будет получать свой заказ вовремя и без задержек!\nУ многих всегда возникает один и тот же вопрос: \"Зачем мне использовать брокер сообщений для общения между микросервисами? Я могу отправлять запросы простым restTemplate и не парить себе мозги\".  На этот вопрос я всегда люблю отвечать примерно в таком ключе:\nИспользование брокера сообщений между микросервисами имеет несколько преимуществ, которые делают его важным элементом в микросервисной архитектуре.\nРазрыв зависимостей: Брокер сообщений позволяет уменьшить зависимость между микросервисами, что делает систему более гибкой и масштабируемой. Микросервисы могут обмениваться сообщениями через брокер, не имея непосредственного знания друг о друге, что позволяет легко добавлять, удалять и изменять микросервисы.\nРаспределение нагрузки: Брокер сообщений может обрабатывать сообщения асинхронно, что позволяет распределить нагрузку между микросервисами и обеспечить более быструю обработку запросов.\nГарантированная доставка: Брокер сообщений обеспечивает гарантированную доставку сообщений, даже если один из микросервисов временно недоступен или отказался обрабатывать сообщение.\nУлучшенная отказоустойчивость: Если один из микросервисов временно недоступен или вышел из строя, брокер сообщений может сохранить сообщения в очереди и отправить их, когда микросервис снова станет доступен.\nТаким образом, использование брокера сообщений между микросервисами позволяет обеспечить более гибкую, масштабируемую и отказоустойчивую систему. Это как занесение банкира между игроками в настольный футбол - он обеспечивает правильное распределение мяча и гарантирует, что игра будет проходить справедливо и без обидных проигрышей.\nНа рынке сегодня есть 2 основных open-source решения по брокерам сообщении. Это всеми любимые \nKafka\n и \nRabbitMQ\n. Подробнее об их отличиях вы можете почитать в \nэтой \nпрекрасной статье на хабре ну а мы пойдем дальше и рассмотрим простые кейсы настройки брокеров в Java Spring Boot Applications.\nДавайте разберем такой use-case: \nУ нас есть 2 сервиса:\nIncident Service\nEmail Notification Service\nОба микросервиса ранятся на одном сервере, но на разных хостах. Наша задача состоит в написание метода, который будет создавать новый инцидент и отправлять какую-то информацию на сервис email-notification.\nДля начала запомните, что когда вы работаете с брокером сообщения у вас есть 3 основных понятия:\nProducer - отправитель\nConsumer - получатель\nTopic - топик вашего приложения\nДля правильной работы вашего брокера сообщении вы должны их правильно сконфигурировать в вашем Java Application.\nKafkaConsumerConfig:\n@Configuration\n@RequiredArgsConstructor\npublic class KafkaConsumerConfig {\n\n    @Value(\"localhost:29092\")\n    private String bootstrapService;\n\n\n    public Map<String, Object> consumerConfig() {\n        Map<String, Object> props = new HashMap<>();\n        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapService);\n        return props;\n    }\n\n    @Bean\n    public ConsumerFactory<String, EmailNotificationDtoRequest> consumerFactory() {\n        // EmailNotificationDtoRequest DTO который наш consumer будет принимать\n        JsonDeserializer<EmailNotificationDtoRequest> deserializer =new JsonDeserializer<>();\n        deserializer.addTrustedPackages(\"*\");\n        return new DefaultKafkaConsumerFactory<>(consumerConfig(),new StringDeserializer(), deserializer);\n    }\n\n    @Bean\n    public KafkaListenerContainerFactory<ConcurrentMessageListenerContainer<String, EmailNotificationDtoRequest>> factory(ConsumerFactory<String, EmailNotificationDtoRequest> consumerFactory) {\n        ConcurrentKafkaListenerContainerFactory<String, EmailNotificationDtoRequest> factory = new ConcurrentKafkaListenerContainerFactory<>();\n        factory.setConsumerFactory(consumerFactory);\n        return factory;\n    }\n}\nKafkaProducerConfig:\n@Configuration\npublic class KafkaProducerConfig {\n\n    @Value(\"localhost:29092\")\n    private String bootstrapService;\n\n\n    public Map<String, Object> producerConfig() {\n        Map<String, Object> props = new HashMap<>();\n        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapService);\n        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);\n        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);\n        return props;\n    }\n\n    @Bean\n    public ProducerFactory<String, EmailNotificationDtoRequest> producerFactory() {\n        return new DefaultKafkaProducerFactory<>(producerConfig());\n    }\n\n    @Bean\n    public KafkaTemplate<String, EmailNotificationDtoRequest> kafkaTemplate(ProducerFactory<String, EmailNotificationDtoRequest> producerFactory) {\n        return new KafkaTemplate<>(producerFactory);\n    }\n\n}\nKafkaTopicConfig:\n@Configuration\npublic class KafkaTopicConfig {\n\n    @Bean\n    public NewTopic gilgameshNotificationTopic() {\n        return TopicBuilder.name(\"gilgamesh-notification\")\n                .build();\n    }\n}\n\nГлавное не пугайтесь страшных слов \"Сериалайзеры\" И \"Десериалайзеры\" в них мы просто указываем тип передачи данных между сервисами.\nМок реализация нашего метода:\n@Override\n    @Transactional\n    public Incident create(IncidentDtoRequest dtoRequest) {\n        Incident incident;\n        try {\n            incident = new Incident();\n            incident.setCategory(categoryService.getByIdThrowException(dtoRequest.getCategoryId()));\n            incident.setDescription(dtoRequest.getDescription());\n            incident.setPriorityLevel(priorityLevelService.getByIdThrowException(dtoRequest.getPriorityLevelId()));\n            incident.setTitle(dtoRequest.getTitle());\n            incident.setTags(tagService.getAllByListOfIds(dtoRequest.getTagIds()));\n            incident.setTypes(typeService.getAllByListOfIds(dtoRequest.getTypeIds()));\n\n            dtoRequest.getUserIds().forEach(ids -> incidentUsersService.create(incident.getId(), ids));\n\n            EmailNotificationDtoRequest emailNotificationDtoRequest = new EmailNotificationDtoRequest();\n            emailNotificationDtoRequest.setEmailType(1L);\n            emailNotificationDtoRequest.setDescription(\"Вы создали новый инцидент под названием: \" + dtoRequest.getTitle());\n            emailNotificationDtoRequest.setTitle(\"Создание нового инцидента\");\n            kafkaTemplate.send(\"gilgamesh-notification\",emailNotificationDtoRequest);\n\n            return this.save(incident);\n        }\n        catch (Exception e) {\n            log.error(e);\n            throw new CustomCouldNotCreateException(CustomStatusCode.COULD_NOT_CREATE_RECORD_IN_DB.getCode());\n        }\n    }\nЗдесь мы можем наблюдать, как мы сначала создаем инцидент а потом при помощи kafkaTemplate отправляем запрос на топик \"gilgamesh-notification\". \nОсталось только настроить KafkaListener на нашем email-notification-service.\nKafkaListeners:\n@Component\n@RequiredArgsConstructor\npublic class KafkaListeners {\n\n    private final EmailNotificationService emailNotificationService;\n\n    @KafkaListener(topics = \"gilgamesh-notification\", groupId = \"groupId\", containerFactory = \"factory\")\n    void listener(EmailNotificationDtoRequest dtoRequest) {\n        System.out.println(\"Listener recieved data: \" + dtoRequest);\n        emailNotificationService.create(dtoRequest);\n    }\n}\nПоздравляю, вы официально теперь Senior программист, который умеет работать с Брокерами Сообщений(нет).\nТрассировка Запросов\nТрассировка запросов в микросервисной архитектуре - это процесс отслеживания запросов, проходящих через различные микросервисы в системе, с целью обнаружения проблем и улучшения производительности системы в целом.\nКогда пользователь отправляет запрос к системе, он может проходить через несколько микросервисов, каждый из которых выполняет свою часть работы. При трассировке запросов каждый микросервис записывает информацию о запросе, такую как его идентификатор и время начала и окончания обработки. Эта информация передается следующему микросервису, который добавляет свою информацию к записи. Таким образом, мы можем отследить, как запрос проходит через систему и какие микросервисы на него влияют.\nТрассировка запросов позволяет обнаруживать узкие места в системе и находить проблемы производительности. Например, если один микросервис выполняет долгую операцию, это может замедлить всю систему. Трассировка запросов помогает быстро определить эту проблему и принять меры для ее устранения.\nКроме того, трассировка запросов может использоваться для отладки и анализа ошибок в системе. Если запрос не может быть выполнен из-за ошибки в одном из микросервисов, мы можем легко определить, где произошла ошибка и что ее вызвало.\nТаким образом, трассировка запросов является важным инструментом для мониторинга и управления микросервисной архитектурой. Это как GPS-навигатор, который помогает водителю определить свое местоположение и выбрать наиболее эффективный маршрут.\nМоя любимая связка приложении всегда будет Sleuth+Zipkin. \nSleuth\n и \nZipkin\n - это две программы, которые используются для трассировки запросов в микросервисной архитектуре.\nSleuth - это библиотека, разработанная компанией Spring, которая автоматически генерирует уникальные идентификаторы запросов и добавляет их в логи каждого микросервиса. Когда запрос проходит через несколько микросервисов, Sleuth позволяет связать все логи вместе и создать полную картину запроса в системе. Это упрощает процесс трассировки запросов и помогает быстрее обнаруживать и исправлять проблемы в системе.\nZipkin - это инструмент для трассировки запросов, который позволяет визуализировать взаимодействие между микросервисами в системе. Он использует информацию, собранную Sleuth, чтобы создать диаграмму запросов, которая показывает, как запросы проходят через различные микросервисы в системе. Это упрощает процесс отслеживания запросов и обнаружения проблем в системе.\nТаким образом, Sleuth и Zipkin работают вместе для обеспечения эффективной трассировки запросов в микросервисной архитектуре. Sleuth собирает информацию о запросах в каждом микросервисе и передает ее в Zipkin, который создает диаграмму запросов и помогает быстро находить проблемы в системе.\nДля корректной работы данных приложении хватает нескольких зависимостей и строк в application файлах:\npom.xml:\n<dependency>\n      <groupId>org.springframework.cloud</groupId>\n      <artifactId>spring-cloud-starter-sleuth</artifactId>\n</dependency>\n<dependency>\n       <groupId>org.springframework.cloud</groupId>\n       <artifactId>spring-cloud-sleuth-zipkin</artifactId>\n</dependency>\ngradle.build:\nimplementation group: 'org.springframework.cloud', name: 'spring-cloud-starter-sleuth'\nimplementation group: 'org.springframework.cloud', name: 'spring-cloud-sleuth-zipkin'\napplication.yml:\nspring:\n  application:\n    name: \"название вашего сервиса\"\n  zipkin:\n    base-url: http://localhost:9411\nВсего пар строк кода и вы облегчили жизнь десяткам людей на поддержке!\nЗаключение\nМикросервисы крайне интересный и увлекательный топик. Вы можете играться с настройками брокеров сообщении, api gateway как вам угодно. Но запомните главное правило - микросервисы это не панацея. Иногда монолиты являются более оптимальным решением нежели микросервисы. \nВсем добра и позитива! Пользуйтесь Kcell и Activ!\n \n ",
    "tags": [
        "микросервисы",
        "java",
        "брокеры сообщений",
        "kafka",
        "spring-cloud",
        "spring"
    ]
}