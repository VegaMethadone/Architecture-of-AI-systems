{
    "article_id": "727192",
    "article_name": "Chaos Engineering: принципы, процессы и примеры",
    "content": "Предсказывать системные бои становится всё сложнее. Чтобы предотвратить остановки в работе, крупные и малые компании обратились к chaos engineering в качестве решения.\nChaos engineering позволяет вам прогнозировать и выявлять потенциальные сбои, намеренно внося неисправности в систему. Таким образом можно находить и устранять сбои ещё до того, как они превратятся в простои. Chaos engineering — растущая тенденция для DevOps и IT-команд. Даже такие компании, как Netflix и Amazon, используют эти принципы при разработке своих продуктов.\nЕсли вы новичок в chaos engineering, вы пришли по верному адресу. Сегодня мы подробно познакомим вас с принципами его работы и покажем, как начать работу с Kubernetes.\nВы узнаете:\nЧто такое Chaos Engineering?\nОб инструментах Chaos Engineering\nО принципах и процессах Chaos Engineering\nО примере Chaos Engineering: приложении Kubernetes\nЧему нужно учиться дальше\nЧто такое Chaos Engineering?\nChaos engineering — это дисциплина, основанная на проведении опытов над системой. С помощью Chaos engineering мы намеренно пытаемся вывести нашу систему из строя при определённых нагрузках для того, чтобы определить потенциальные сбои, найти слабые места и повысить отказоустойчивость.\nChaos engineering отличается от тестирования программного обеспечения или внедрения ошибок. Он нужен для выполнения всевозможных требований и предсказания непредвиденных ситуаций, включающих скачки трафика, условия гонки и многое другое.\nВо время использования Chaos engineering мы пытаемся выяснить, как вся система реагирует на отказ отдельного компонента.\nНапример, Chaos engineering помогает ответить на вопросы функциональности:\nЧто происходит, когда сервис по какой-то причине становится недоступным?\nКаким будет результат сбоев, если приложение получит слишком много трафика или если оно недоступно?\nСтолкнемся ли мы с каскадными ошибками, если из-за единой точки отказа приложение выйдет из строя?\nЧто происходит, когда наше приложение выходит из строя?\nЧто происходит, когда возникают неполадки с сетью?\nПредыстория\n: Chaos Engineering был разработан Netflix в 2008 году, когда потоковый сервис по подписке был переведен в общедоступное облако. Инженеры Netflix отметили, что им нужны новые способы тестирования системы на отказоустойчивость. Поэтому в 2011 году они придумали Chaos Monkey — инструмент для проверки устойчивости облачных систем путем создания сбоев в инфраструктуре и бизнес‑системе.\nС тех пор Chaos Engineering получил развитие, и такие компании, как Google, Facebook, Amazon и Microsoft, внедрили аналогичные модели тестирования.\nПреимущества Chaos Engineering  \nChaos Engineering предлагает преимущества, которые недоступны при других формах тестирования программного обеспечения или тестирования сбоев. Тесты на сбой могут проверять только одно условие в двоичной структуре. Это не позволяет тестировать систему в условиях беспрецедентных или неожиданных нагрузок.\nС другой стороны, хаос-инжиниринг объясняет реальные сбои и проблемы. С его помощью можно решить текущие проблемы и получить новое представление о приложении для будущих улучшений.\nЭксперименты с хаосом уменьшают количество отказов и отключений, одновременно улучшая само понимание устройства системы. Chaos Engineering улучшает доступность и надежность сервиса, поэтому клиенты меньше страдают от простоев. Он также помогает предотвратить потерю доходов и снизить затраты на обслуживание на уровне бизнеса.\nИнструменты Chaos Engineering\nChaos Engineering — это еще не тот сегмент рынка, который устоялся и хорошо развит. Тем не менее, существует ряд инструментов, из которых мы можем выбирать.\nОдин из самых известных инструментов для Chaos Engineering — это Simian Army, разработанный Netflix. Simian Army подходит для облачных сервисов и AWS. Он может генерировать сбои и обнаруживать отклонения от нормы. Подобным занимается и Chaos Monkey от Netflix — это инструмент устойчивости к случайным сбоям.\nPowerfulSeal — это мощный инструмент для тестирования кластеров Kubernetes, а Litmus можно использовать для stateful рабочих нагрузок в Kubernetes. Pumba используется с Docker для тестирования хаоса и эмуляции сети. Gremlin предлагает платформу Chaos Engineering, которая теперь поддерживает тестирование в кластерах Kubernetes.\nChaos Dingo используют для Microsoft Azure, а прокси-сервер «Chaos HTTP proxy»  нужен для внесения сбоев в HTTP-запросы.\nПринципы и процесс Chaos Engineering\nПо мере того, как с годами все больше команд проводили эксперименты, они научились наиболее эффективно применять подходы Chaos Engineering к своим системам. Эти передовые практики стали основными принципами Chaos Engineering. Давайте рассмотрим их.\nПостройте гипотезу steady state\nПосле построения steady state можно выполнять потенциально опасные действия с задержкой в ​​сети, приложениями, узлами или любым другим компонентом системы.\nСоздавайте острые ситуации для подтверждения, что гипотеза \nsteady state \nверна. Вы сможете предположить, что когда система находится в определенном состоянии, она выполняет действия и завершает такую ​​же проверку, чтобы подтвердить, что состояние не изменилось.\nМоделируйте реальные события\nПрименяйте Chaos Engineering на основе реальных событий. Другими словами, копируйте только те события, которые могут произойти в вашей системе. Например, это может быть сбой приложения, нарушение работы сети или отказ узла.\nПроведите эксперименты в продакшене \nПроводите эксперименты с хаосом в продакшене. Если вы проводите эксперименты с хаосом только на окружениях разработки и для интеграции, вы не можете получить реальную картину того, как ведет себя промышленная система.\nАвтоматизируйте эксперименты и запускайте их непрерывно\nАвтоматизируйте эксперименты с хаосом, чтобы они выполнялись непрерывно или как составная часть конвейеров непрерывной поставки. Это может означать каждый час, каждые несколько часов, каждый день, каждую неделю или каждый раз, когда в нашей системе происходит какое-то событие. Проводите эксперименты каждый раз, когда развёртываете новую версию.\nМинимизируйте радиус поражения\nКогда вы начинаете эксперименты с хаосом, начните с малого и наращивайте масштаб параллельно с тем, как растет уверенность ваша в системе. В конце концов, вам следует провести эксперименты во всей системе.\nРезюме главных принципов:\nпостройте гипотезу о стабильном состоянии;\nмоделируйте реальные события;\nпроводите эксперименты в продакшене;\nавтоматизируйте эксперименты и запускайте их непрерывно;\nминимизируйте радиус поражения.\nПроцесс Chaos Engineering\nОбщий процесс Chaos Engineering выглядит следующим образом:\nОпределение гипотезы устойчивого состояния:\n вам нужно начать с представления о том, что может пойти не так. Начните с выбора ошибки для внедрения в систему и спрогнозируйте результат, когда она будет внедрена в работающую систему.\nПодтверждение стабильного состояния и моделирование некоторых реальных событий:\n выполните тесты с использованием реальных сценариев, чтобы увидеть, как ваша система ведет себя при определенных стрессовых условиях или обстоятельствах.\nЕще раз подтвердите стабильное состояние:\n нам нужно подтвердить, какие изменения произошли, поэтому повторная проверка дает нам представление о поведении системы.\nСбор показателей и наблюдение за информационными панелями:\n вам нужно измерить надежность и доступность вашей системы. Используйте ключевые показатели производительности, которые соотносятся с клиентским опытом. Например, мы хотим измерить сбой в соответствии с нашей гипотезой, изучив такие факторы, как влияние на задержку или количество запросов в секунду.\nВнесение изменений и исправление проблемы.\n После проведения эксперимента вы должны хорошо понимать, что работает, а что нужно изменить. Теперь мы можем определить, что приведет к недоступности сервиса, и мы точно знаем, что нарушает работу системы. Итак, исправим это и попробуем еще раз с новым экспериментом.\nПример Chaos Engineering  \nРазберём теорию на реальном примере, чтобы лучше понять Chaos Engineering. Для этого будем использовать Kubernetes. Сначала создадим кластер Kubernetes, затем развернем наше приложение и уничтожим его. А дальше — покажем, как определять стабильные состояния.\nПримечание.\n Если вы новичок в Kubernetes, мы рекомендуем пройти курс \n«Kubernetes: База»\n, прежде чем продолжить изучение хаоса. \nСоздайте кластер Kubernetes\nНам нужен кластер Kubernetes для уничтожения. Вы можете выбрать Minikube, Docker Desktop, AKS, EKS и GKE. Ниже мы используем Docker Desktop для создания кластера. Если вы хотите узнать, как создать кластер с помощью других инструментов, обратитесь к курсу The DevOps Toolkit: Kubernetes Chaos Engineering.\n# Source: https://gist.github.com/f753c0093a0893a1459da663949df618\n\n####################\n# Create A Cluster #\n####################\n\n# Open Docker Preferences, select the Kubernetes tab, and select the \"Enable Kubernetes\" checkbox\n\n# Open Docker Preferences, select the Resources > Advanced tab, set CPUs to 4, and Memory to 6.0 GiB, and press the \"Apply & Restart\" button\n\n#######################\n# Destroy the cluster #\n#######################\n\n# Open Docker Troubleshoot, and select the \"Reset Kubernetes cluster\" button\n\n# Select *Quit Docker Desktop*\nКлонирование и осмотр репозитория  \nНам нужно развернуть демонстрационное приложение, которое мы подготовили ниже. Мы собираемся клонировать репозиторий \nvfarcic/go-demo-8\n, созданный Виктором Фарчичем (Viktor Farcic).\ngit clone https://github.com/vfarcic/go-demo-8.git\nДалее мы заходим в каталог, куда склонировали репозиторий.\ncd go-demo-8\ngit pull\nТеперь создадим пространство имен k8s с именем \ngo-demo-8.\nkubectl create namespace go-demo-8\nДавайте кратко рассмотрим приложение, которое мы собираемся развернуть, расположенное в каталоге \nterminate-pods\n в файле с именем \npod.yaml\n.\n---\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: go-demo-8\n  labels:\n    app: go-demo-8\nspec:\n  containers:\n  - name: go-demo-8\n    image: vfarcic/go-demo-8:0.0.1\n    env:\n    - name: DB\n      value: go-demo-8-db\n    ports:\n    - containerPort: 8080\n    livenessProbe:\n      httpGet:\n        path: /\n        port: 8080\n    readinessProbe:\n      httpGet:\n        path: /\n        port: 8080\n    resources:\n        limits:\n          cpu: 100m\n          memory: 50Mi\n        requests:\n          cpu: 50m\n          memory: 20Mi\nЭто приложение определяется как один pod с одним контейнером \ngo-demo-8\n. Он включает в себя так же и другие ресурсы, такие как \nlivenessProbe\nи \nreadinessProbe\n.\nПрименение манифеста к кластеру\nТеперь мы применяем этот манифест к нашему кластеру внутри пространства имен go-demo-8. Это запустит наше приложение как под.\nkubectl --namespace go-demo-8 apply --filename k8s/terminate-pods/pod.yaml\nА теперь пришло время что-нибудь сломать и уничтожить наше приложение!\nУстановите плагин Chaos Toolkit Kubernetes\nЧтобы провести эксперименты с хаосом в нашем приложении, мы можем использовать плагин Chaos Toolkit для Kubernetes. Этот инструментарий не поддерживает базовый Kubernetes. Нам нужен плагин для функций, выходящих за рамки базовых готовых функций. Давайте установим плагин Kubernetes, используя \npip\n.\npip install -U chaostoolkit-kubernetes\nПримечание\n. Изучите плагин Chaos Toolkit с помощью команды \ndiscover\n, чтобы увидеть все его функции, параметры и аргументы.\nЗавершение работы экземпляров приложения  \nДавайте начнем разрушения. Посмотрите на первый манифест, который мы будем использовать, расположенное в каталоге \nchaos\n файла \nterminate-pod.yaml\n.\ncat chaos/terminate-pod.yaml\nКоманда даст нам следующий вывод:\nversion: 1.0.0\ntitle: What happens if we terminate a Pod?\ndescription: If a Pod is terminated, a new one should be created in its places.\ntags:\n- k8s\n- pod\nmethod:\n- type: action\n  name: terminate-pod\n  provider:\n    type: python\n    module: chaosk8s.pod.actions\n    func: terminate_pods\n    arguments:\n      label_selector: app=go-demo-8\n      rand: true\n      ns: go-demo-8\nТеперь, когда мы ознакомились с определением, давайте запустим \nterminate-pod.yaml.\nchaos run chaos/terminate-pod.yaml\nВывод будет такой:\n[... INFO] Validating the experiment's syntax\n[... INFO] Experiment looks valid\n[... INFO] Running experiment: What happens if we terminate a Pod?\n[... INFO] No steady state hypothesis defined. That's ok, just exploring.\n[... INFO] Action: terminate-pod\n[... INFO] No steady state hypothesis defined. That's ok, just exploring.\n[... INFO] Let's rollback...\n[... INFO] No declared rollbacks, let's move on.\n[... INFO] Experiment ended with status: completed\nПосле первоначальной проверки манифеста был проведен эксперимент под названием \nWhat happens if we terminate a Pod?\n и обнаружено, что есть \nno steady state hypothesis defined\n. Судя по выводу, есть только одно действие —  \nterminate-pod.\nЗатем был произведен возврат к \nsteady state hypothesis\n и плагин определил, что это состояние не определено. Далее была произведена попытка \nrollback\n и, оказалось, что она не может быть выполнена. Все, что мы сделали до сих пор, — это выполнили действие по завершению работы пода. Мы можем увидеть результат в последней строке: \nexperiment ended with status: complete\n.\nТеперь давайте выведем код выхода предыдущей команды. Если мы получим 0, это означает успех в Linux. Эти коды выхода сообщают системе, неудача это или успех!\nПосмотрим на поды в нашем пространстве имен.\nkubectl --namespace go-demo-8 get pods\nВ выводе указано, что \nno resources\n были найдены в \ngo-demo-8 namespace.\nМы развернули единственный под и провели эксперимент, в результате которого он был уничтожен. Мы не проводили никаких проверок. А также мы выполнили одно действие для завершения работы пода, которое было успешным.\nОпределение стабильных состояний  \nВсё, что мы сделали выше —  уничтожили под. Однако цель инженерии хаоса — найти слабые места в наших кластерах. Поэтому мы обычно определяем стабильное состояние, соответствие которому проверяем до и после эксперимента.\nЕсли состояние до и после одинаково, мы можем сделать вывод, что наш кластер отказоустойчив в этом случае. В случае Chaos Toolkit мы достигаем этого путем определения \nsteady state hypothesis\n.\nДавайте посмотрим на манифест, который определяет состояние, которое будет проверяться до и после действия.\ncat chaos/terminate-pod-ssh.yaml\nРезультат даст нам:\n> steady-state-hypothesis:\n>   title: Pod exists\n>   probes:\n>   - name: pod-exists\n>     type: probe\n>     tolerance: 1\n>     provider:\n>       type: python\n>       func: count_pods\n>       module: chaosk8s.pod.probes\n>       arguments:\n>         label_selector: app=go-demo-8\n>         ns: go-demo-8\nВ манифесте есть новый раздел \nsteady-state-hypothesis\n. Теперь мы можем провести настоящий эксперимент с хаосом, чтобы проверить наше стабильное состояние  \nЗапуск эксперимента с хаосом и проверка вывода\nДавайте проведем эксперимент с хаосом, чтобы увидеть правильный результат.\nchaos run chaos/terminate-pod-ssh.yaml\nПолучаем следующее:  \n[... INFO] Validating the experiment's syntax\n[... INFO] Experiment looks valid\n[... INFO] Running experiment: What happens if we terminate a Pod?\n[... INFO] Steady state hypothesis: Pod exists\n[... INFO] Probe: pod-exists\n[... CRITICAL] Steady state probe 'pod-exists' is not in the given tolerance so failing this experiment\n[... INFO] Let's rollback...\n[... INFO] No declared rollbacks, let's move on.\n[... INFO] Experiment ended with status: failed\nЗдесь есть критически важная проблема: \nSteady state probe ’pod-exists’ is not in the given tolerance\n. Проверка не удалась, прежде чем мы выполнили действия, потому что мы уничтожили под. Итак, наш эксперимент провалился и подтвердил, что начальное состояние не соответствует тому, что мы хотим.\nИтак, давайте применим манифест \nterminate-pods/pod.yaml\n, чтобы воссоздать под. Затем мы сможем увидеть, что произойдет, когда мы повторно запустим эксперимент с \nsteady-state-hypothesis.\nkubectl --namespace go-demo-8 apply --filename k8s/terminate-pods/pod.yaml\nПовторение эксперимента\nС заново запущенным подом повторно запустим эксперимент.\nchaos run chaos/terminate-pod-ssh.yaml\nРезультат выглядит следующим образом:\n[... INFO] Validating the experiment's syntax\n[... INFO] Experiment looks valid\n[... INFO] Running experiment: What happens if we terminate a Pod?\n[... INFO] Steady state hypothesis: Pod exists\n[... INFO] Probe: pod-exists\n[... INFO] Steady state hypothesis is met!\n[... INFO] Action: terminate-pod\n[... INFO] Steady state hypothesis: Pod exists\n[... INFO] Probe: pod-exists\n[... INFO] Steady state hypothesis is met!\n[... INFO] Let's rollback...\n[... INFO] No declared rollbacks, let's move on.\n[... INFO] Experiment ended with status: completed\nТеперь мы видим, что проба \npod-exists\n подтвердила правильное состояние и действие \nterminate-pod\n было выполнено. Мы также можем видеть, что была проведена новая проверка на соответствие стабильному состоянию. Под существовал и до действия, и после. Но как может под существовать, если мы его уничтожили?\nДобавление задержки  \nЭксперимент не провалился, потому что наши проверки и действия выполнялись одно за другим. Kubernetes не успел полностью удалить под. Итак, нам нужно добавить паузу, чтобы эксперимент стал более полезным. Давайте посмотрим на YAML.\ncat chaos/terminate-pod-pause.yaml\nЭто дает нам следующий результат:\n>   pauses: \n>     after: 10\nМы видим здесь, что мы добавили раздел \npauses\n после того \naction\n, которое завершает под. Теперь, когда мы выполняем действие по завершению работы пода, система будет ждать 10 секунд перед проверкой нашего состояния.\nПроведите эксперимент с задержки\nПосмотрим, что мы получим, если проведем этот эксперимент с задержкой.\nchaos run chaos/terminate-pod-pause.yaml\nЭто дает нам следующий результат:\n[... INFO] Validating the experiment's syntax\n[... INFO] Experiment looks valid\n[... INFO] Running experiment: What happens if we terminate a Pod?\n[... INFO] Steady state hypothesis: Pod exists\n[... INFO] Probe: pod-exists\n[... INFO] Steady state hypothesis is met!\n[... INFO] Action: terminate-pod\n[... INFO] Pausing after activity for 10s...\n[... INFO] Steady state hypothesis: Pod exists\n[... INFO] Probe: pod-exists\n[... CRITICAL] Steady state probe 'pod-exists' is not in the given tolerance so failing this experiment\n[... INFO] Let's rollback...\n[... INFO] No declared rollbacks, let's move on.\n[... INFO] Experiment ended with status: deviated\n[... INFO] The steady-state has deviated, a weakness may have been discovered\nНа этот раз проверка была неуспешна и выдала, что \nsteady state probe ’pod-exists’ is not in the given tolerance so failing this experiment\n. Теперь мы дали Kubernetes достаточно времени, чтобы удалить под, а затем проверили, существует ли под.\nСистема вернулась к нам с сообщением, что пода нет. Мы можем вывести код выхода последней команды, чтобы убедиться, что она действительно не сработала.\nЧто изучить дальше \nКруто! Мы уничтожили наше приложение, используя стабильное состояние, а также изучили основы Chaos Engineering. Далее необходимо исправить ошибки, которые мы создали, чтобы сделать приложение отказоустойчивым.\nНужно разобраться в каждой из проблем в системе. \nНа курсе \n«Chaos Engineering»\n мы как раз рассматриваем технологии хаос-инжиниринга и показываем, как их использовать. Новый поток стартует \n15 мая 2023 года. \nКурс\n \nполезен разработчикам, архитекторам и техлидами, которые хотят улучшить устойчивость систем к различным нештатным ситуациям. На курсе также разберём: \nКаждую из проблем в системе, вроде деградации сети, забивание диска логами и т. д.\nОжидаемый результат и проверку того, что он трастовый.\nПрактику по Chaos Blade. \nРаботу с Cloud native приложениями.  \nУзнать подробности и записаться: \nhttps://slurm.club/3U9ZeB4\nС этого момента можно применять все виды разрушений и проверок приложения, такие как:\nразличные этапы и условия проверок;\nэксперименты с доступностью;\nочистка (drain) узлов кластера;\nвыполнение случайного хаоса. \nСчастливого обучения!  \n \n ",
    "tags": [
        "chaos engineering",
        "chaos monkey",
        "kubernetes",
        "it-инфраструктура",
        "онлайн-образование",
        "it-инфраструктуры",
        "it-карьера"
    ]
}