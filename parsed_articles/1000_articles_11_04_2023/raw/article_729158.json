{
    "article_id": "729158",
    "article_name": "OpenAssistant: Вышла бесплатная открытая альтернатива ChatGPT",
    "content": "Участники открытого сообщества \nLAION-AI\n выпустили в открытый доступ первые обученные \nмодели\n \nOA_SFT_Llama_30B \nи \nOA_SFT_Llama_13B\n. и запустили ИИ-чатбот \nOpenAssistant\n на их основе. На текущий момент доступны модели в 13 и 30 млрд параметров, дообученные на мультиязычных датасетах, собранных сообществом. В основе моделей лежит уже успевшая стать популярной \nLLaMA\n. \nOpenAssistant \n- это диалоговый помощник на базе ИИ, который понимает задачи, может взаимодействовать со сторонними системами (подобно плагинам в ChatGPT) и динамически извлекать информацию из них. OpenAssistant позиционируется как открытая альтернатива ChatGPT.\n\"Мы хотим, чтобы OpenAssistant стал единой, объединяющей платформой, которую все другие системы используют для взаимодействия с людьми.\"\n \n- декларируют своё видение члены сообщества LAION.\nВы можете попробовать поговорить с OpenAssistant уже сейчаст \nтут\n.\nЕще вы можете принять участие в формировании датасета на своём языке \nтут\n.\nТехнические детали\nМодели обучали на мощностях, выделенных \nRedmond AI\n при поддержке \nWeights & Biases\n. Инференс моделей обеспечивается благодаря \nHugging Face\n и \nStability AI\n. В основе дообученных моделей лежат концепции \nInstructGPT\n, \nRLHF \n(Reinforcement Learning from Human Feedback) и модель вознаграждения (\nreward-model\n) на базе \ndeBERTa\n. Контекст модели в 30 млрд увеличен в 2 раза, до 1024 токена.\nСообщество приложило усилия для \nформирования \nполноценного датасета, который составляется и проверяется большой группой людей на разных языках и разного уровня подготовки. Для целей сбора датасета, реализован алгоритм, при котором одна группа участников сообщества формируют вопросы и ответы, а другая группа занимается валидацией в несколько уровней.\nДатасет является мультиязычным, основные доли занимают Английский (59%) и Испанский (42%). Доля Русского языка на уровне 8%. Мы можем повлиять на это, приняв участие в разметке датасета.\nСтоит учесть тот факт, что при подготовке датасета \nне использовались\n ответы от других языковых моделей, таких как ChatGPT, чтобы исключить попадание синтетических данных. Весь код Open Assistant лицензирован под Apache 2.0. Это означает, что он доступен для широкого круга целей, включая коммерческое использование.\nOpenAssistent это:\nПерсонализированный кастомизируемый диалоговый ИИ ассистент\nСистема извлечения информации из внешних ресурсов и знаний\nСистема взаимодействия с другими системами через API интерфейсы\nСистема генерации и автодополнения кода для разработчиков\nOpenAssistent \nобъединяет все знания в одном месте:\nИспользует современные технологии глубокого обучения\nСпособен запускаться на пользовательском оборудовании\nДообучен на обратной связи от живых людей\nОткрыт и доступен для всех\nИнференс\nВы можете запустить \nOpenAssistent \nу себя на компьютере локально на CPU. Для этого вам нужно:\n1. \nСкачать \nи распаковать файлы из архива.\n2. \nСкачать \nмодель и поместить в ту же директорию.\n3. Открыть терминал (cmd.exe) и запустить с помощью команды:\nmain.exe -m D:\\LLaMA_cpp\\qunt4_0.bin -n -1 --ctx_size 2048 --batch_size 16 --keep 512 --repeat_penalty 1.0 -t 32 --temp 0.4 --top_k 30 --top_p 0.18 --interactive-first -ins --color\nгде D:\\LLaMA_cpp\\qunt4_0.bin  - это путь до скачанной модели.\nтак выглядит инференс модели в 13 млрд.\nТесты\nТесты проводились на модели в 30 млрд:\nНа русском языке: \nOpenAssistant\nChatGPT\nO\nСправилась! Или был пример в датасете?\nВроде как да, но вроде и нет?\nНу такое.\nНа английском языке:\nОшибка!. Верный ответ: Option D. This is an alternating number of subtraction series. First, 1 is subtracted, then 2 is added.\nПравильный ответ: D. Book. Rest are all parts of a book.\nЛогично!\nНу вроде адекватный ответ.\nПо генерации кода по запросу всё выглядит лучше.\nВердикт.\nВ целом круто, что сообщество развивает подобные проекты. Я уверен, у этого проекта есть огромный потенциал и в будущем мы ещё о нём услышим! Силу сообщества нельзя недооценивать!\nНа данный момент модель пока \nсырая\n. До ChatGPT даже версии GPT-3.5 ей пока далеко. Еще один немаловажный нюанс - это лицензия основной модели LLaMA. C ней вопрос пока далеко не однозначный, т.к. по сути она была слита и авторы это публично никак не комментируют.\nПодписывайтесь на мой канал в дзене https://dzen.ru/agi (про ИИ, языковые модели, новости и тенденции) и телеграм канал https://t.me/hardupgrade (про организацию, структурирование и управление информацией, второй мозг).\n \n ",
    "tags": [
        "НЛП",
        "Языковые модели",
        "ИИ",
        "ии и машинное обучение",
        "llama",
        "openassistant"
    ]
}