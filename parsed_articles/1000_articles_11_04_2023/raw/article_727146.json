{
    "article_id": "727146",
    "article_name": "ChatGPT на стероидах: возможности плагина-ретривера для семантического поиска",
    "content": "OpenAI добавил поддержку плагинов в ChatGPT, и теперь он может подключаться к сторонним сервисам и искать информацию в сети. А помните, была такая компания Гугл?\nВ этой статье я хотел бы рассказать о самом, на мой взгляд, интересном плагине, который позволяет искать ответы в собственной базе.\nОсновные преимущества плагина\nСемантический поиск: Плагин позволяет получать наиболее релевантные фрагменты документов, задавая вопросы на естественном языке.\nИнтеграция с векторными базами данных: Retrieval Plugin использует модель эмбеддингов OpenAI для генерации векторных представлений документов и их поиска в векторной базе данных. Причем он позволяет использовать разные базы для векторного поиска.\nФункция памяти для ChatGPT: Плагин позволяет сохранять фрагменты разговоров для дальнейшего использования, тем самым обеспечивая контекстно-зависимый диалог.\nУстановка и интеграция плагина\nЧтобы начать использовать Retrieval Plugin, вам потребуется:\nПолучить \nключ\n для использования OpenAI API.\nСгенерировать \nBEARER_TOKEN\n. Можно использовать этот \nсервис\n.\nНастроить базу данных для хранения собственных документов. Плагин предоставляет возможность выбрать из следующего списка (\npinecone\n, \nweaviate\n, \nzilliz\n, \nmilvus\n, \nqdrant\n, или \nredis\n), но код можно допилить и для собственного варианта (куда же без elasticsearch). В обзоре я буду использовать \npinecone\n.\nСоздать и настроить собственный сервер FastAPI.\nНастраиваем хранилище pinecone\nРегистрируемся\n в pinecone. Можно с помощью github-аккаунта.\nПолучаем ключ API.\nСоздаем свой собственный индекс, это можно сделать в приложении либо через питоновскую библиотеку.\nИдекс в pinecone\nimport os, pinecone\n\n# PINECONE_ENVIRONMENT - можно посмотреть в приложении, в моем примере выше это значение равно us-west4-gcp\n# PINECONE_INDEX - название для вашего индекса\n\npinecone.init(api_key=os.environ['PINECONE_API_KEY'],\n              environment=os.environ['PINECONE_ENVIRONMENT'])\n\npinecone.create_index(name=os.environ['PINECONE_INDEX'],\n                      dimension=1536, # размерность вектора, в данном случае будут использоваться эмбеддинги OpenAI\n                      metric='cosine',\n                      metadata_config={\n                          'indexed': ['source', 'source_id', 'url', 'created_at', 'author', 'document_id']\n                      } # создал слишком много полей, которые потом не использовал в тесте :)\n                     )\n\nНастраиваем окружение для проекта\nПоставьте Python 3.10\nКлонируйте репозиторий: \ngit clone https://github.com/openai/chatgpt-retrieval-plugin.git\nПерейдите в папку с репозиторием: \ncd /path/to/chatgpt-retrieval-plugin\nУстановите poetry: \npip install poetry\n. Можно использовать и другой способ создания виртуального окружения, но тогда надо будет внести исправления в код проекта.\nСоздайте виртуальное окружение с Python 3.10: \npoetry env use python3.10\nАктивируйте виртуальное окружение: \npoetry shell\nУстановите зависимости приложения: \npoetry install\nЗадайте необходимые переменные окружения.\nexport BEARER_TOKEN=<your_bearer_token>\nexport OPENAI_API_KEY=<your_openai_api_key>\n\nexport DATASTORE=pinecone\nexport PINECONE_API_KEY=<your_pinecone_api_key>\nexport PINECONE_ENVIRONMENT=<your_pinecone_env_key>\nexport PINECONE_INDEX=<your_pinecone_index>\nЗапустите API локально: \npoetry run start\n. Если вы все сделали по инструкции, то в терминале вы увидите нечто похожее на картинку ниже. Я создал индекс с оригинальным названием \ntest\n, поэтому плагин подключается к нему.\nЗапуск сервера\nЕсли перейти по ссылке \nhttp://0.0.0.0:8000/docs\n, то попадете на страничку с документацией. Здесь же можно производить отладку. Нажмите на \nauthorize\n и введите \nBEARER_TOKEN\n, который указали в настройках.\nОписание эндпоинтов\nПлагин предоставляет следующие эндпоинты для работы с документами:\n/upsert\n: Загрузка и хранение текста и метаданных одного или нескольких документов в векторной базе данных. Документы разбиваются на фрагменты размером около 200 токенов, каждый с уникальным идентификатором.\n/upsert-file\n: Позволяет загрузить один файл (PDF, TXT, DOCX, PPTX или MD) и сохранить его текст и метаданные в векторной базе данных. Файл конвертируется в простой текст и разбивается на части примерно по 200 токенов, каждая с уникальным идентификатором.\n/query\n: Запрос к векторной базе данных с использованием одного или нескольких запросов на естественном языке и дополнительных фильтров метаданных. Возвращает список объектов, каждый из которых содержит список наиболее релевантных фрагментов документов для заданного запроса.\n/delete\n: Удаление одного или нескольких документов из базы данных с использованием их идентификаторов, фильтра метаданных или флага удаления всех документов.\nТестируем индекс\nПришло время опробовать плагин в работе. К сожалению, это не получится сделать в самом приложении ChatGPT, т. к. функционал пока ограничен, и для интеграции нужно вставать в очередь. Но кое-что можно попробовать сделать, например, протестировать векторный поиск.\nПредставим себе, что мы хотим автоматизировать службу поддержки. Наша цель – научить бота автоматически отвечать на вопросы пользователей и давать им дополнительную информацию в виде ссылок на внутреннюю документацию(это может быть confluence).\nПопросим ChatGPT придумать нам примеры для такого индекса. Мой промт для этой цели:\nСгенерируй набор из 10 тестовых примеров документов, которые будут добавлены в векторное хранилище pinecone. В документах содержится информаци о запросах в службу поддержки компании. Каждый документ должен иметь следующую структуру:\n\n1. id: int (уникальный идентификатор документа)\n2. text: str(основной текст документа)\n3. metadata: dict(содержит дополнительную информацию о документе):\n\t- title (необязательное поле с названием или описанием документа)\n\t- url (ссылка на источник информации, предпочтительно страницу confluence)\n\nОбратите внимание, что тексты документов и метаданные должны быть разнообразными и содержательными. Результат должен быть реализован в виде python кода\nChatGPT мне предложил следующие варианты:\ndocuments = [\n    {\n        \"id\": 1,\n        \"text\": \"Как настроить автоматическое обновление ПО?\",\n        \"metadata\": {\n            \"title\": \"Настройка автоматического обновления\",\n            \"url\": \"https://confluence.example.com/display/support/automatic-updates\",\n        }\n    },\n    {\n        \"id\": 2,\n        \"text\": \"Необходимо восстановить удаленные данные. Какие есть варианты?\",\n        \"metadata\": {\n            \"title\": \"Восстановление удаленных данных\",\n            \"url\": \"https://confluence.example.com/display/support/data-recovery\",\n        }\n    },\n    {\n        \"id\": 3,\n        \"text\": \"Проблемы с подключением к интернету. Как исправить?\",\n        \"metadata\": {\n            \"title\": \"Решение проблем с подключением\",\n            \"url\": \"https://confluence.example.com/display/support/internet-connection-issues\",\n        }\n    },\n    {\n        \"id\": 4,\n        \"text\": \"Как ускорить работу компьютера?\",\n        \"metadata\": {\n            \"title\": \"Оптимизация работы компьютера\",\n            \"url\": \"https://confluence.example.com/display/support/computer-optimization\",\n        }\n    },\n    {\n        \"id\": 5,\n        \"text\": \"Как настроить VPN подключение?\",\n        \"metadata\": {\n            \"title\": \"Настройка VPN\",\n            \"url\": \"https://confluence.example.com/display/support/vpn-setup\",\n        },\n    },\n    {\n        \"id\": 6,\n        \"text\": \"Сбой при обновлении системы. Как решить проблему?\",\n        \"metadata\": {\n            \"title\": \"Решение проблем с обновлением системы\",\n            \"url\": \"https://confluence.example.com/display/support/update-failure\",\n        }\n    },\n    {\n        \"id\": 7,\n        \"text\": \"Как настроить электронную почту на мобильном устройстве?\",\n        \"metadata\": {\n            \"title\": \"Настройка электронной почты на мобильных устройствах\",\n            \"url\": \"https://confluence.example.com/display/support/mobile-email-setup\",\n        }\n    },\n    {\n        \"id\": 8,\n        \"text\": \"Проблемы с печатью на сетевом принтере. Как исправить?\",\n        \"metadata\": {\n            \"title\": \"Решение проблем с сетевой печатью\",\n            \"url\": \"https://confluence.example.com/display/support/network-printing-issues\",\n        }\n    },\n    {\n        \"id\": 9,\n        \"text\": \"Как восстановить пароль пользователя?\",\n        \"metadata\": {\n            \"title\": \"Восстановление пароля пользователя\",\n            \"url\": \"https://confluence.example.com/display/support/password-recovery\",\n        },\n    }\n   {\n        \"id\": 10,\n        \"text\": \"Как установить и настроить брандмауэр?\",\n        \"metadata\": {\n            \"title\": \"Установка и настройка брандмауэра\",\n            \"url\": \"https://confluence.example.com/display/support/firewall-setup\",\n        }\n    }\n]\n\nТеперь индексируем эти примеры в Pycone:\n# pip install requests tqdm\nimport os \nimport requests\nfrom requests.adapters import HTTPAdapter\nfrom requests.packages.urllib3.util.retry import Retry\nfrom typing import List, Dict, Optional\nfrom tqdm import tqdm\n  \nBEARER_TOKEN = os.environ.get('BEARER_TOKEN')\n\nheaders = {  \n    'Authorization': f'Bearer {BEARER_TOKEN}'\n}\n\ndef upsert_documents(\n      documents: List[Dict],\n      endpoint_url: str = 'http://localhost:8000',\n      batch_size: int = 100,\n      headers: Optional[Dict[str, str]] = None,\n      timeout: float = 10.0\n):\n    \n    s = requests.Session()\n\n    # Устанавливаем стратегию повторных попыток для 5xx ошибок\n    retries = Retry(\n        total=5,  # количество попыток перед вызовом ошибки\n        backoff_factor=0.1,\n        status_forcelist=[500, 502, 503, 504]\n    )\n    s.mount('http://', HTTPAdapter(max_retries=retries))\n\n    for i in tqdm(range(0, len(documents), batch_size)):\n        i_end = min(len(documents), i + batch_size)\n        try:\n            # Отправляем POST-запрос, разрешая до 5 повторных попыток\n            res = s.post(\n                f'{endpoint_url}/upsert',\n                headers=headers,\n                json={\n                    \"documents\": documents[i:i_end]\n                },\n                timeout=timeout\n            )\n            res.raise_for_status()\n        except requests.exceptions.RequestException as e:\n            print(f'Ошибка при вставке/обновлении: {e}')\n\n\nupsert_documents(documents, headers=headers)\nОсталось узнать, будет ли работать этот гениальный код. Для этого надо перейти по адресу \nhttp://0.0.0.0:8000/sub/docs\n (да, создатели не поленились и создали отдельную страничку) и написать запрос в нашу базу:\nКрик души\nИИ выдал следующие варианты решения проблемы нашего пользователя:\nОтвет ретривера\nНа сегодня у меня все – в следующей части, если CloseAI все-таки выдаст мне талон, посмотрим, как это будет работать в самом интерфейсе ChatGPT, а также попробуем сохранить историю наших запросов в векторной базе.\nНадеюсь, было полезно, спасибо за внимание!\nПишу про AI и NLP в \nтелеграм\n \n ",
    "tags": [
        "chatgpt",
        "plugin",
        "retrieval",
        "pinecone"
    ]
}