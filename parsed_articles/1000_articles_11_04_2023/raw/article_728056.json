{
    "article_id": "728056",
    "article_name": "Андрей Карпаты. Software 2.0. Непонятный софт будущего",
    "content": "\r\nКогда мы говорим о современных разработках в области нейросетей и машинного обучения, то первое имя, которое приходит на ум — это \nАндрей Карпаты\n. Молодой словак быстро стал звездой в данной области и одним из главных авторитетов по части конкретного программирования систем. Это тот человек, который \nобучал Джона Кармака\n, в частности.\n\r\n\n\r\nАндрей Карпаты — сооснователь компании \nOpenAI\n (GPT-4, ChatGPT) и ведущий разработчик \nавтопилота Tesla\n. Впрочем, из «Теслы» он недавно ушёл по очевидной причине: есть вероятность, что человечество стоит на пороге грандиозного открытия, с которым ничто не сравнится по важности — оно разделит историю нашего вида на \nдо\n и \nпосле\n сингулярности. Речь идёт об AGI, то есть ИИ общего назначения. Если так, то сейчас нет смысла работать больше ни над чем.\n\r\n\n\r\n\n▍ Карьера и проекты\n\r\nАндрей Карпаты родился в Братиславе (Словакия) в 1986 году и эмигрировал в Канаду в возрасте 15 лет.\n\r\n\n\r\nВ 2009 году завершил обучение в университете Торонто (информатика/физика + математика), в 2011-м — аспирантуру в университете Британской Колумбии (машинное обучение для робототехники), а в 2015 году защитил диссертацию, посвящённую конволюционным/рекуррентным нейронным сетям и их применению в компьютерном зрении, обработке естественного языка и их пересечении. \n\r\n\n\r\nРазработал и стал основным лектором первого курса по глубокому обучению в Стэнфордском университете — \nCS 231n: «Конволюционные нейронные сети для распознавания образов»\n. С годами этот класс стал из самых больших в Стэнфорде, а в первые годы вообще рос в геометрической прогрессии: 150 студентов в 2015 году, 330 в 2016-м, 750 в 2017-м.\n\r\n\n\r\nПопутно Андрей прошёл три стажировки в Google Brain в 2011 году (самообучение нейросети по видеоматериалам), затем в Google Research в 2013 году (обучение с учителем по видеоматериалам YouTube) и в DeepMind в 2015 году (глубокое обучение с подкреплением).\n\r\n\n\r\nВ 2015 году \nстал сооснователем\n научной лаборатории \nOpenAI\n, которая сейчас известна всему миру благодаря генератору изображений \nDALL-E\n, большой языковой модели \nGPT-4\n (вышла 14 марта 2023 года) и чат-боту \nChatGPT\n, который работает на этой модели.\n\r\n\n\r\n\nОригинальная модель GPT, иллюстрация из \nнаучной статьи от 11 июня 2018 года\n \n\r\n\n\r\nИзначально OpenAI планировалась как некоммерческая организация, которая будет «свободно сотрудничать» с университетами и исследователями со всего мира. Однако в 2019 году для некоммерческой корпорации была зарегистрирована коммерческая дочерняя компания OpenAI Limited Partnership (OpenAI LP) с ограничением на 100-кратный максимальный размер прибыли.\n\r\n\n\r\nВпрочем, к тому времени из организации уже ушли двое сооснователей: Илон Маск и Андрей Карпаты (в 2017-м). Первый сослался на конфликт интересов в связи с разработкой \nавтопилота Tesla\n, а второй перешёл на работу как раз в Tesla в качестве ведущего разработчика этого автопилота, над которым и трудился шесть лет, с перспективой создания полностью автономной системы \nFull Self-Driving\n.\n\r\n\n\r\nПосле шестилетнего напряжённого труда Андрей ушёл в саббатикал, уволился из Tesla, а последние полгода занимался только записью \nобучающих видеороликов на YouTube\n по созданию нейросетей, с пошаговыми инструкциями и \nфрагментами исходного кода на Github\n (эти видеоролики с примерами рекомендуются всем начинающим).\n\r\n\n\r\nВ рамках этой обучающей активности в начале 2023 года Андрей выложил в опенсорс \nNanoGPT\n — максимально простой код (300 строк \ntrain.py\n и 300 строк \nmodel.py\n) для обучения/настройки GPT среднего размера. Код написан на основе \nminGPT\n в обучающих целях, чтобы любой мог обучить нейросеть с нуля на приемлемом оборудовании. Всё предельно понятно (с пошаговыми инструкциями на видео). В частности, текущий \ntrain.py\n воспроизводит GPT-2 (124 млн) с OpenWebText на одном узле 8XA100 40GB всего за четыре дня обучения.\n\r\n\n\r\n\n\r\nВ феврале 2023 года Карпаты \nобъявил\n о возвращении в OpenAI.\n\r\n\n\r\n\n\r\n\n«Я присоединяюсь к OpenAI (снова :)). Как и многих других людей из сферы ИИ и за её пределами, меня очень вдохновляет влияние их работы, и я лично получил от неё большую пользу. Потенциал будущего особенно интересен; мне очень приятно снова влиться в работу и присоединиться к разработке», — написал Андрей.\n\r\nТаким образом, он снова вернулся в научную лабораторию, где трудился в 2015–2017 гг.\n\r\n\n\r\n\n▍ Software 2.0. Непонятный софт будущего\n\r\nПеред уходом из OpenAI в 2017 году Карпаты написал интересную статью \nSoftware 2.0\n, в которой рассказал об использовании нейросетей в программировании.\n\r\n\n\r\nПо его мнению, нейросети совершат фундаментальный сдвиг в разработке, позволив создавать принципиально более сложное ПО, недоступное для понимания человеку, как показано на иллюстрации ниже.\n\r\n\n\r\n\n\r\nКлассический стек Software 1.0 написан на понятных языках типа Python и C++. Он состоит из явных инструкций для компьютера, созданных программистом. Написав каждую строку кода, программист определяет конкретную точку в пространстве программы с некоторым желаемым поведением.\n\r\n\n\r\nВ отличие от этого, Software 2.0 будет написано на гораздо более абстрактном, недружественном человеку языке, например, в виде весов нейронной сети. Человек не будет принимать активного участия в написании кода, потому что весов очень много (в типичных сетях миллионы), а кодировать непосредственно в весах довольно сложно.\n\r\n\n\r\nПрограмма будет выглядеть примерно таким образом (фрагмент):\n\r\n\n\r\n\n\r\nЗадача программиста заключается не столько в написании кода, сколько в определении некоторой желаемой цели поведения программы. Например, «удовлетворить набор пар примеров на входе и выходе» или «выиграть партию в Go». Программист устанавливает цели и создаёт грубый скелет кода (т. е. архитектуру нейронной сети), который определяет подмножество программного пространства для поиска, а дальше использовать имеющиеся в его распоряжении вычислительные ресурсы для \nпоиска в этом пространстве программы, которая работает\n.\n\r\n\n\r\n«В случае нейросетей мы ограничиваем поиск непрерывным подмножеством программного пространства, где процесс поиска может быть сделан (что несколько удивительно) эффективным с помощью обратного распространения и стохастического градиентного спуска», — пишет Карпаты.\n\r\n\n\r\n\n\r\nТаким образом, Software 1.0 есть исходный код, написанный человеком (например, несколько файлов \n.cpp\n), который компилируется в двоичный файл, выполняющий полезную работу. \n\r\n\n\r\nВ Software 2.0 исходный код состоит из:\n\r\n\n\r\n\n\r\n\nНабора данных, который определяет желаемое поведение.\n\r\n\n\r\n\nАрхитектуры нейронной сети, которая даёт грубый скелет кода, но с множеством деталей (весов), которые необходимо заполнить.\n\r\n\n\r\nВ процессе обучения нейросети набор данных преобразуется в бинарную конечную нейросеть. В большинстве практических приложений архитектуры нейросетей и системы обучения станут стандартизированным товаром, поэтому большая часть «разработки» примет форму «курирования, выращивания, массирования и очистки помеченных наборов данных». \n\r\n\n\r\nЭто в корне меняет парадигму программирования, с помощью которой мы итеративно разрабатываем наше программное обеспечение. По мнению Карпаты, команды разработчиков разделяется на две группы: \n\r\n\n\r\n\n\r\n\nпрограммисты 2.0 (специалисты по маркировке данных) редактируют и расширяют наборы данных;\n\r\n\n\r\n\nнесколько программистов 1.0 поддерживают и итеративно разрабатывают окружающую инфраструктуру кода обучения, аналитику, визуализации и интерфейсы маркировки.\n\r\n\n\r\n\nПрограммное обеспечение (1.0) пожирает мир, а теперь ИИ (2.0) пожирает программное обеспечение.\n \n\r\n\n\r\nПереход с 1.0 на 2.0 мы сейчас видим во многих отраслях, где начинают активно применяться нейросети. \n\r\n\n\r\nВ недавнем посте \n«Глубокие нейросети 33 года назад и 33 года спустя»\n Карпаты экстраполировал развитие нейросетей с 1989 до 2055-го. Он предложил посмотреть на нейросети 1989 года с крошечными датасетами и представить, что точно так же будущие исследователи будут смотреть на нейросети 2023 года. Они будут казаться игрушечными и обучаться за одну минуту на личном ПК или смартфоне.\n\r\n\n\r\nДатасеты станут примерно в 10 миллионов раз больше, чем у наших детских экспериментов типа GPT-4 или GPT-5, которую некоторые нетерпеливые инвесторы уже \nсравнивают с AGI\n.\n\r\n\n\r\n\n\r\nДаже если архитектура нейросетей остаётся примерно такой же, увеличение количества параметров даёт качественный результат в функционировании моделей. Например, мозг человека и \nмозг мушки-дрозофилы\n функционально отличаются благодаря большой разнице в количестве нейронов (86 млрд и 100 тыс., соответственно) и \nсвязей\n между ними. В то же время сам механизм работы отдельных нейронов у человека и дрозофилы примерно одинаков.\n\r\n\n\r\n\nКоннектом\n мозга дрозофилы\n\r\n\n\r\nНесложно посчитать, что количественная разница между мозгом дрозофилы и человека гораздо меньше (860 000×), чем между нейросетями 2022 и 2055 гг. (10 000 000×).\n\r\n\n\r\nАндрей Карпаты считает, что в наиболее экстремальной экстраполяции через несколько десятилетий нам вообще не понадобится \nобучать\n новые нейросети:\n\r\n\n\r\n\n«В 2055 году мы будем просить выросший в десять миллионов раз мегамозг нейронной сети выполнить какую-нибудь задачу, проговорив (или подумав) её на родном языке. И если вы попросите достаточно вежливо, он подчинится. Да, вы по-прежнему сможете обучать нейронные сети… но зачем это будет нужно?»\n\r\n\n\r\n\nПослесловие\n. Согласно \nстатистике Metaculus\n, ещё год назад средневзвешенный прогноз пользователей по сроку появления сильного ИИ приходился на 2043 год. Но в апреле 2022 года после появления новостей о будущей GPT-4 произошёл тектонический сдвиг вниз до 2028-го года. На данный момент техносообщество сдвинуло наиболее вероятный срок ввода в эксплуатацию AGI уже на май 2026 года. То есть у нас остались считаные месяцы (37)…\n\r\n\n\r\n\n\r\nСудя по всему, технологии в этой области развиваются гораздо быстрее, чем предполагалось. Возможно, наши современники станут свидетелями самой важной революции в истории человечества. И не последняя роль в этом принадлежит разработчикам моделей для обучения нейросетей, в том числе Андрею Карпаты. \n\r\n\n\r\nЕсли когда-нибудь сбудется сюжет фильма «Терминатор» и будущие поколения пришлют в прошлое машину, чтобы изменить историю, то именно Андрей может стать главной целью для этой машины.\n\r\n\n\r\n\n\n                        \nПредыдущие статьи серии «Величайшие программисты современности»\n\n                        \n\r\n\nДжастин Танни\n\r\n\n\r\n\nДжей Фриман (saurik)\n\r\n\n\r\n\nМихал Залевски\n\r\n\n\r\n\nДжон Кармак: \n1\n, \n2\n\r\n\n\r\n\nМарк Руссинович\n\r\n\n\r\n\nЮрки Алакуйяла\n\r\n\n\n                    \n\r\n\nTelegram-канал с розыгрышами призов, новостями IT и постами о ретроиграх 🕹️\n \n ",
    "tags": [
        "ruvds_статьи",
        "Андрей Карпаты",
        "AGI",
        "сильный ИИ",
        "GPT-4",
        "OpenAI",
        "глубокое обучение",
        "Google Brain",
        "Google Research",
        "YouTube",
        "DeepMind",
        "DALL-E",
        "ChatGPT",
        "Software 2.0",
        "nanoGPT"
    ]
}