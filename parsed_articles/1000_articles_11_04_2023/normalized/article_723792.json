{
    "article_id": "723792",
    "article_name": "Часть 2. Перевод нейронной сети на базе Keras LSTM на работу с матричными операциями",
    "content": "первый часть  часть переводить обученный модель полносвязной сеть база keras работа матричный вычисление модель разрабатывать новостной агрегатор цель фильтрация нежелательный новость  посмотреть  статья руководство tensorflow увидеть один рекомендация классификация тест являться использование сеть долгий краткосрочный память lstm  мой задача сеть прямой распространение обладать достаточный качество предсказуемость стабильность результат объяснимый переобучение влияние архитектура сеть качество тд немаловажный  быстро обучаться отличие lstm  ради академический интерес обучать сеть c lstm бинарона классификация текст перевести она также работа матрица пакет numpy это также наглядно показывать устраивать ячейка lstm  сеть lstm итак tensorflow рассматривать следующий архитектура сеть model  tfkerassequential   encoder      tfkeraslayersembedding         input_dimlenencoderget_vocabulary         output_dim64          use masking to handle the variable sequence lengths         mask_zerotrue     tfkeraslayersbidirectionaltfkeraslayerslstm64     tfkeraslayersdense64 activationrelu     tfkeraslayersdense1  выглядеть графический вид архитектура сеть сайт tensorflow   httpswwwtensorfloworgtexttutorialstext_classification_rnn  модуль textvectorization  tfkeraslayersembedding тот первый часть мой работа вкратце напоминать textvectorization преобразовывать слово уникальный числовой индекс embedding затем преобразовывать плотный вектор  далее идти слой lstm который помощь слой  tfkeraslayersbidirectional  проходиться два направление начало последовательность конец наоборот затем объединять результат начинать смоделировать простой архитектура   tfkeraslayersbidirectional   рассматривать следующий модель model  tfkerassequential    tfkeraslayersembedding         input_dimlenencoderget_vocabulary         output_dim64         mask_zerotrue     tfkeraslayerslstm64     tfkeraslayersdense64 activationrelu     tfkeraslayersdense1 activationsigmoid  визуальный понимание код модель  tfkeraslayerslstm рассматривать типовой схема ячейка lstm подписывать функция который должный вычислять  архитектура ячейка lstm получать вес обученный модель слой просто слой dense embedding  это делаться следующий образ   это написать  количество ячейка память задаваться объявление слой tfkeraslayerslstmunits units  intintmodellayers1trainable_weights0shape14 printno units  units  w  modellayers1get_weights0 u  modellayers1get_weights1 b  modellayers1get_weights2  w_i  w units w_f  w units units  2 w_c  w units  2 units  3 w_o  w units  3  u_i  u units u_f  u units units  2 u_c  u units  2 units  3 u_o  u units  3  b_i  bunits b_f  bunits units  2 b_c  bunits  2 units  3 b_o  bunits  3 вес  w  использоваться математический операция входной последовательность  x  тот выход слой embedding вес  u   преобразование состояние  h  прошлый итерация  b   это смещение bias символ   означать операция  npmultiply  символ   обычный поэлементный суммирование вектор   учет особенность работа ячейка lstm индекс название коэффициент обозначать функциональный назначение элемент индекс  f  функция забыванияforget gate   посуть спомощь умножение накоэффициент 0до 1управляется значение состояние  t   дляудаление информация опрошлый шаг обработка код длявычисление   letter  это очередной символ слой embedding  h_st  выход предыдущий ячейка  selff_t  selfsigmoidnpdotletter selfw_f                           npdotselfh_st selfu_f                           selfb_f индекс  i  добавление информация ксостояние входной вентиль   наоснова выход предыдущий ячейка  h t1  ввод x t  определяться какой значение использовать изввод x вовнутренний состояние код  letter  это очередной символ слой embedding  h_st  выход предыдущий ячейка  selfi_t  selfsigmoidnpdotletter selfw_i                           npdotselfh_st selfu_i                           selfb_i  индекс   подготовка функция  ĉ t selfct_t  nptanhnpdotletter selfw_c                       npdotselfh_st selfu_c                       selfb_c готовый расчет новый клеточный состояние  t  selfstate  npmultiplyselff_t selfstate  npmultiplyselfi_t selfct_t индекс    расчет выходной значение применять гиперболический тангенс текущий состояние ячейка умножать преобразовывать значение текущий входной символ  selfh_st  npmultiplyselfsigmoidnpdotletter selfw_o                                        npdotselfh_st selfu_o                                       selfb_o                         nptanhselfstate полный код ячейка lstm выглядеть следующий образ def lstmself data    инициализация начальный состояние ячейка выходной состояние работа первый итерация     selfstatenpzerosselfunits     selfh_stnpzerosselfunits       проходить символ прямой направление      for letter in data                  selff_t  selfsigmoidnpdotletter selfw_f  npdotselfh_st selfu_f  selfb_f                  selfi_t  selfsigmoidnpdotletter selfw_i  npdotselfh_st selfu_i  selfb_i                  selfct_t  nptanhnpdotletter selfw_c  npdotselfh_st selfu_c  selfb_c          selfstate  npmultiplyselff_t selfstate  npmultiplyselfi_t selfct_t          selfh_st  npmultiplyselfsigmoidnpdotletter selfw_o  npdotselfh_st selfu_o selfb_o nptanhselfstate              return nparrayselfh_st bidirectional lstm случай использование  tfkeraslayersbidirectional  создаваться слой lstm проходить цепочка слово прямой направление второй  обратный результат конкатенироваться  результат обучение получать два группа весы lstm прямой обратный направление соответственно   вес получать обученный модель следующий образ selfvocal_dict  vocal_dictk k for k in rangelenvocal_dict  selfunits  units   слой прямой прохождение selfw_farward  lstm_weights0 selfu_farward  lstm_weights1 selfb_farward  lstm_weights2 selfw_i_farward  selfw_farward selfunits selfw_f_farward  selfw_farward selfunits selfunits  2 selfw_c_farward  selfw_farward selfunits  2 selfunits  3 selfw_o_farward  selfw_farward selfunits  3  selfu_i_farward  selfu_farward selfunits selfu_f_farward  selfu_farward selfunits selfunits  2 selfu_c_farward  selfu_farward selfunits  2 selfunits  3 selfu_o_farward  selfu_farward selfunits  3  selfb_i_farward  selfb_farwardselfunits selfb_f_farward  selfb_farwardselfunits selfunits  2 selfb_c_farward  selfb_farwardselfunits  2 selfunits  3 selfb_o_farward  selfb_farwardselfunits  3   слой обратный прохождение selfw_backward  lstm_weights3 selfu_backward  lstm_weights4 selfb_backward  lstm_weights5 selfw_i_backward  selfw_backward selfunits selfw_f_backward  selfw_backward selfunits selfunits  2 selfw_c_backward  selfw_backward selfunits  2 selfunits  3 selfw_o_backward  selfw_backward selfunits  3  selfu_i_backward  selfu_backward selfunits selfu_f_backward  selfu_backward selfunits selfunits  2 selfu_c_backward  selfu_backward selfunits  2 selfunits  3 selfu_o_backward  selfu_backward selfunits  3  selfb_i_backward  selfb_backwardselfunits selfb_f_backward  selfb_backwardselfunits selfunits  2 selfb_c_backward  selfb_backwardselfunits  2 selfunits  3 selfb_o_backward  selfb_backwardselfunits  3  реализация  tfkeraslayersbidirectionaltfkeraslayerslstmunits  такой образ следующий def lstm_farwardself data            selfstatenpzerosselfunits     selfh_stnpzerosselfunits     for letter in data                  selff_t  selfsigmoidnpdotletter selfw_f_farward  npdotselfh_st selfu_f_farward  selfb_f_farward               selfi_t  selfsigmoidnpdotletter selfw_i_farward  npdotselfh_st selfu_i_farward  selfb_i_farward               selfct_t  nptanh npdotletter selfw_c_farward  npdotselfh_st selfu_c_farward  selfb_c_farward               selfstate  npmultiplyselff_t selfstate  npmultiplyselfi_t selfct_t              selfh_st  npmultiplyselfsigmoidnpdotletter selfw_o_farward  npdotselfh_st selfu_o_farward selfb_o_farward nptanhselfstate      return nparrayselfh_st  def lstm_backwardself data          selfstatenpzerosselfunits     selfh_stnpzerosselfunits          for letter in data1                  selff_t  selfsigmoidnpdotletter selfw_f_backward  np",
    "tags": [
        "keras",
        "матрицы",
        "ml"
    ]
}