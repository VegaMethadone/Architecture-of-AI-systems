{
    "article_id": "727560",
    "article_name": "Основные инструменты для работы в Data Engineering: введение для начинающих Data Engineer'ов",
    "content": "все привет  звать надя занимать должность  data engineer  компания который специализироваться разработка мобильный игра статья хотеть поделиться информация основной инструмент который использовать свой работа данные рассказывать каждый подробно отмечать каждый компания инструмент мочь отличаться опыт совпадать опыт другой  data engineerов  однако постараться поделиться информация который полезный профессионал область тот начинать свой путь  data engineering  быть рад материал помогать структурировать закреплять свой знание статья рассказывать такой инструмент python pyspark amazon s3 apache impala amazon redshift databricks apache airflow github git ниже рассматривать основной возможность каждый инструмент предоставлять ссылка материал смочь изучать подробно глубокий понимание пример использование каждый инструмент также планировать написать отдельный статья python начинать самый базовый насколько известно большинство специалист работа данные использовать основной язык программирование  python  возникать вопрос  почему именно  python  ответ очень простой это связанный  python  предоставлять множество инструмент работа данные обработка информация несколько причина почему  python  популярный  data engineering  простота   python  являться простой легко читать язык делать идеальный выбор работа данные особенно начинать многий высокоуровневый концепция такой функциональный программирование объектноориентированный программирование также легко изучаться  python  большой сообщество   python  иметь огромный сообщество разработчик который создавать поддерживать различный библиотека инструмент обработка данные это значительно упрощать работа данные позволять быстро находить решение проблема библиотека   python  существовать множество библиотека работа данные такой  pandas numpy scikitlearn matplotlib  многий другой предоставлять готовый решение различный задача такой анализ данные обработка визуализация инструмент   python  также иметь различный инструмент который помогать работа данные например  jupyter notebook  позволять создавать интерактивный записной книжка анализ данные  pyspark  предоставлять возможность распределенный обработка большой объем данные кроме написание код важно учитывать паттерный проектирование принцип ооп это помогать создавать чистый понятный код также облегчать поддержка масштабирование приложение шикарный книга который мочь посоветовать   python вершина мастерство  автор   лучано рамальо хотеть пойти далеко пощупать паттерный проектирование однозначно это книга  паттерный проектирование  автор   эрик фримен элизабет фримен др pyspark python spark такой возможно мир возможно  pyspark   это фреймворк обработка большой объем данные  apache spark  написать язык  python  широко использоваться качество инструмент  data engineering  поскольку позволять обрабатывать анализировать данные реальный время работать данные разный источник проводить сложный аналитический вычисление помощь  pyspark   data engineers  мочь работать данные разный источник такой  hadoop distributed file system hdfs   amazon s3 apache cassandra apache hbase  другой  pyspark  позволять объединять данные разный источник один место провожать различный трансформация обработка данные также агрегировать данные провожать аналитический вычисление очень важный  pyspark  позволять использовать распределять вычисление обработка большой объем данные позволять работать данные параллельно несколько узел кластер значительно ускорять обработка большой объем данные снижать время выполнение задача amazon s3 начинать определение такой amazon s3  есть  amazon s3 simple storage service   это хранилище объект облако предоставлять компания  amazon web services   s3  предоставлять высокий доступность масштабируемость надежность безопасность хранение данные использовать хранение любой тип данные включая файл видео аудио изображение документ тд наш команда укладка данные бакет  s3  использоваться следовать процесс  игра пользователь мобильный игра действие такой нажатие экран покупка другой событие собираться внешний sdk отправляться наш бакет  s3  вид неструктурированный данные подход предоставлять мы удобство использование множество инструмент  big data  такой  impala   spark   hive  другой получение ценный информация этот данный  официальный документация  знакомство  s3  настройка apache impala делать дынный храниться s3   начинать мочь использовать  apache hadoop  который позволять распределенно обрабатывать анализировать большой объем данный однако работа данные храниться s3 должный использовать дополнительный инструмент   amazon s3a   s3a   это способ обращение данный храниться  s3   hadoop  устанавливать связь  impala   hadoop   impala  начинать работать интерактивный  sql запросовый движок который обращаться данные храниться бакета  s3  использовать  hadoop distributed file system hdfs  помощь  s3a  который предоставлять драйвер чтение запись данные  s3  impala   это инструмент выполнение быстрый sqlзапросов большой объем данные который храниться распределенный файловый система  hdfs  являться интерактивный  sql запросовый движок который позволять провожать анализ данные режим реальный время такой образ использовать  impala   hadoop  вместе  s3a  мочь получать доступ большой объем неструктурированный данные храниться бакета  s3  производить анализ обработка данные режим реальный время всетака укладывать данные  s3  бакета  impala  сначала необходимо создавать таблица  impala  указание местонахождение данный  s3  использовать команда  create table  указание параметр такой формат файл расположение данные  s3  тд пример команда создание таблица  impala  укладка давать  s3  create table my_table stored as parquet location s3amy_bucketpathtodata данный пример создавать таблица имя  my_table  указывать формат хранение данные  parquet  также расположение данный  s3  бакета  my_bucket  путь  pathtodata  создание таблица  impala  смочь обращаться данные  s3   hadoop  помощь  s3a  провожать операция анализ обработка данные режим реальный время amazon redshift amazon redshift   это облачный решение хранение анализ данные разрабатывать  amazon web services aws  оно представлять себя мощный колоночный база данные который обрабатывать большой объем данные поддерживать распределять архитектура data engineerы  мочь использовать  amazon redshift  многий цель такой хранение обработка большой объем данные   amazon redshift  обрабатывать терабайт данные обеспечивать быстрый доступ данные благодаря колоночный структура pyspark   amazon redshift  использоваться  pyspark  давать возможность выполнять запрос большой объем данные храниться  amazon redshift  использовать распределять вычисление использование  sql  анализ данные   amazon redshift  поддерживать  sql  делать доступный  data engineer  который знакомый  sql запрос интеграция другой инструмент   amazon redshift  интегрироваться другой сервис  aws  такой s3 тп позволять  data engineer  легко обрабатывать данные разный источник масштабируемость   amazon redshift  легко масштабироваться зависимость объем данные который нужно хранить обрабатывать оптимизация   amazon redshift  позволять производить оптимизация анализ данные помощь функция такой автоматический распределение сортировка данные ускорять запрос облегчать анализ большой объем данные шикарно написать  сайт  абсолютно  искать databricks databricks   это облачный платформа обработка анализ данные который позволять работать большой объем данные проводить исследование режим реальный время основывать apache spark предоставлять инструмент работа данные  python   r   sql   scala  один  преимущество   databricks  являться интеграция  pyspark  это обеспечивать  data engineer  возможность использовать  python  обработка анализ данные  spark  начало работа  databricks  необходимо понимать немой выполнение задача обработка анализ данные использоваться  apache spark  который запускаться кластер  кластер   это набор вычислительный ресурс виртуальный машина который выполняться задача кластер  databricks  настра",
    "tags": [
        "data en",
        "pyspark",
        "python",
        "data engineering",
        "airflow",
        "databricks",
        "redshift",
        "impala",
        "s3",
        "шаблоны проектирования"
    ]
}