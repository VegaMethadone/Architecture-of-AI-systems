{
    "article_id": "728030",
    "article_name": "Ускорение работы моделей Stable Diffusion на процессорах Intel",
    "content": "недавно рассказывать последний поколение процессор intel xeon кодовый название sapphire rapids говорить новый аппаратный возможность ориентировать ускорение задача глубокий обучение разбираться использовать ускорение распределенный дообучение трансформер заниматься обработка естественный язык применять ускорение работа такой модель материал собираться останавливаться различный подход ускорение модель stable diffusion процессор sapphire rapids следующий похожий пост речь пойти распределенный дообучение время написание статья легко попробовать дело сервер процессор sapphire rapids воспользоваться инстанс amazon ec2 семейство r7iz  система все еще находиться статус preview получать доступ нужно зарегистрироваться  предыдущий материал пользоваться инстанс r7izmetal16xl 64 vcpu 512gb ram устанавливать ubuntu 2004 ami  ami07cd3e6c4915b2d18  код статья находить gitlab  библиотека diffusers библиотека diffusers очень сильно упрощать генерирование изображение помощь модель stable diffusion знакомый этот модель  иллюстрировать объяснение принцип работа начало создавать виртуальный окружение содержать необходимый библиотека  transformers  diffusers  accelerate pytorch  virtualenv sd_inference source sd_inferencebinactivate pip install pip upgrade pip install transformers diffusers accelerate torch1131 написать простой функция измерение производительность который запускать процесс генерирование изображение возвращать средний время выполнение один действие средний время ожидание результат import time  def elapsed_timepipeline prompt nb_pass10 num_inference_steps20      разогрев     images  pipelineprompt num_inference_steps10images     start  timetime     for _ in rangenb_pass         _  pipelineprompt num_inference_stepsnum_inference_steps output_typenp     end  timetime     return end  start  nb_pass далее  собирать stablediffusionpipeline тип данные float32  использовать умолчание измерять скорость генерирование изображение from diffusers import stablediffusionpipeline  model_id  runwaymlstablediffusionv15 pipe  stablediffusionpipelinefrom_pretrainedmodel_id prompt  sailing ship in storm by rembrandt latency  elapsed_timepipe prompt printlatency средний время ожидание результат составлять 323 секунда показывать раздел intel hugging face код запускать процессор intel xeon предыдущий поколение кодовый название ice lake выдавать результат примерно 45 секунда применение какихто особый прием процессор sapphire rapids точно такой код оказываться значительно быстро процессор ice lake давать ускорять optimum intel openvino пакет optimum intel ускорять этап ииконвейер архитектура intel api очень похожий обычный api библиотека diffusers  это крайность облегчать адаптация существующий код optimum intel поддерживать openvino  опенсорсный набор инструмент intel направлять организация высокопроизводительный работа модель глубокий обучение optimum intel openvino устанавливать pip install optimumopenvino переделывать optimum intel предыдущий фрагмент код  достаточно заменять stablediffusionpipeline ovstablediffusionpipeline  называться лет загружать модель pytorch конвертировать она формат openvino загрузка модель устанавливать флаг exporttrue  from optimumintelopenvino import ovstablediffusionpipeline  ov_pipe  ovstablediffusionpipelinefrom_pretrainedmodel_id exporttrue latency  elapsed_timeov_pipe prompt printlatency   забывать сохранять экспортировать модель ov_pipesave_pretrainedopenvino openvino автоматически оптимизировать модель расчет формат bfloat16  благодаря это средний время генерирование один изображение составлять 167 секунда получать очень приятный двукратный ускорение код вышеприведенный конвейер поддерживать динамический входной данные накладывать ограничение количество изображение разрешение применение stable diffusion приложение обычно ограничивать один несколько различный выходной разрешение такой 512x512 256x256 получаться иметь смысл попытка значительный ускорение код путем переделывание конвейер фиксировать разрешение нуждаться один выходной разрешение мочь просто поддерживать несколько экземпляр конвейер  один каждый необходимый разрешение ov_pipereshapebatch_size1 height512 width512 num_images_per_prompt1 latency  elapsed_timeov_pipe prompt применение статический разрешение вести резкий сокращение средний время генерирование изображение  47 секунда это  дополнительный 35кратное ускорение видеть openvino  это простой эффективный инструмент ускорение работа модель stable diffusion применять инструмент код запускать процессор sapphire rapids сравнение работа обычный код процессор xeon семейство ice lake получаться 10кратное ускорение мочь хотеть пользоваться инструмент openvino мочь пригождаться другой техника оптимизация который поговорить ниже пристегнуть ремень оптимизация системный уровень модель diffusers  это большой структура размер который исчисляться многий гигабайт генерирование изображение  это операция предусматривать интенсивный использование память установка высокопроизводительный библиотека выделение память должный способствовать ускорение операция работа память должный помогать параллельный выполнение такой операция несколько ядро процессор xeon просить обращать внимание подобный операция изменять стандартный библиотека выделение память система вернуться библиотека использовать умолчание удалять новый библиотека одинаковый интерес представлять библиотека jemalloc tcmalloc  показывать установка библиотека jemalloc  способствовать несколько больший улучшение производительность мой тест библиотека кроме подстраивать расчет определенный рабочий нагрузка например  максимизировать использование процессор подробность находить руководство настройка jemalloc  sudo aptget install y libjemallocdev export ld_preloadld_preloadusrlibx86_64linuxgnulibjemallocso export malloc_confoversize_threshold1background_threadtruemetadata_thpautodirty_decay_ms 60000muzzy_decay_ms60000 далее  устанавливать библиотека  libiomp  оптимизация параллельный обработка данные являться часть библиотека  intel openmp runtime  sudo aptget install intelmkl export ld_preloadld_preloadusrlibx86_64linuxgnulibiomp5so export omp_num_threads32  устанавливать инструмент командный строка  numactl  позволять прикреплять pythonпроцессы определять ядро избегать некоторый часть избыточный трата ресурс связанный переключение контекст numactl c 031 python sd_blog_1py благодаря этот оптимизация изначальный код использовать  diffusers  показывать результат 118 секунда это  3 раз быстро достигаться это какихлибо изменение код инструмент определенно отлично работать наш 32ядерном xeon еще далеко заканчивать добавлять наш арсенал пакет intel extension for pytorch ipex bf16 пакет  intel extension for pytorch  ipex расширять pytorch пользоваться возможность аппаратный ускорение который иметься процессор intel например  это  avx512  vector neural network instructions avx512 vnni  advanced matrix extensions  amx устанавливать пакет pip install intel_extension_for_pytorch113100 затем отредактировать код оптимизировать элемент конвейер использование ipex получать список вывести печать объект  pipe  потребоваться конвертировать формат  torchchannels_last  import torch import intel_extension_for_pytorch as ipex  pipe  stablediffusionpipelinefrom_pretrainedmodel_id   преобразование формат torchchannels_last pipeunet  pipeunettomemory_formattorchchannels_last pipevae  pipevaetomemory_formattorchchannels_last pipetext_encoder  pipetext_encodertomemory_formattorchchannels_last pipesafety_checker  pipesafety_checkertomemory_formattorchchannels_last   создание случайный входной данные включение jitкомпиляции sample  torchrandn246464 timestep  torchrand1999 encoder_hidden_status  torchrandn277768 input_example  sample timestep encoder_hidden_status   оптимизация использование ipex pipeunet  ipexoptimizepipeuneteval dtypetorchbfloat16 inplacetrue sample_inputinput_example pipevae  ipexoptimizepipevaeeval dtypetorchbfloat16 inplacetrue pipetext_encoder  ipexoptimizepipetext_encodereval dtypetorchbfloat16 inplac",
    "tags": [
        "stable diffusion",
        "машинное обучение"
    ]
}