{
    "article_id": "727484",
    "article_name": "Распознаем автомобильные номера на TorchServe",
    "content": "вокруг фреймворков инференс нейронок глаз разбегаться продолжать цикл реализация сервинг один задача разный инструмент прошлый  реализация  nvidia triton inference serve анонс просить  телегр канал  код статья находиться  репозиторий  задача качество задача взять распознавание российский автомобильный номер модель взять  репозиторий  пайплайн распознавание следующий  1 детекция номер помощь yolov5  2 вырезать номер прогоняться spatial transformer stn выравнивание  3 текст номер распознаваться lprnet фреймворк инференс использоваться torchserve данный фреймворк являться часть экосистема pytorch активно развиваться документация он говориться следующий torchserve is a performant flexible and easy to use tool for serving pytorch eager mode and torschripted models возможность поддержка  несколько формат  модель torchscript onnx ipex tensorrt объединение несколько модель  графworkflow  инференс  api  rest grpc api  управление модель метрика  коробка конвертировать модель triton torchserve требовать пользователь перевести модель свой формат утилита  torchmodelarchiver   torchworkflowarchiver  модель граф соответственно конвертация мы нужно модель формат torchserveonnxдр скрипт описывать пайплайн работа модель скрипт называться handler он  определяться  основной этап жизненный цикл модель инициализация предобработка предсказание постобработка др типовой задача  предопределять  модель stn lpr легко  конвероваться  torchserve поэтому хэндлер использоваться дополнительный библиотека  импорт  выглядеть import json import logging from abc import abc import numpy as np import torch from tstorch_handlerbase_handler import basehandler  yolo просто переводить torchscript часть логика обработка запрос оставаться снаружи модель копаться это желание также ради приближенный жизнь сценарий хэндлер модель yolo инициализироваться  torchhub  импорт видеть сторонний модуль from inference_torchservedata_models import plateprediction from nninferencepredictor import prepare_detection_input prepare_recognition_input from nnmodelsyolo import load_yolo from nnsettings import settings  это работать необходимо докерфайл  устанавливать  глобальный интерпретатор необходимый пакет torchserve нужно жестко задавать тип размерность вход выход модель поэтому никакой конфига модель определять нужно один сторона это удобный  порождать хаос следовать какомуто один формат конвертировать модель представлять себя zip архив расширение  mar  который лежать артефакт служебный информация вес скрипт дополнительный файл   marinf   manifestjson  stnpt  stnpy  взгляд решение архив неудобно разработка любой изменение необходимо заново конвертировать модель также испытывать проблема запуск немой удаленный дебагер torchserve загружать модель нужно полагать один папка   model storage   указывать  путь параметр запуск подниматься модель необходимо указывать  models all  делать пайплайн распознавание выбирать пайплайн распознавание номер автомобиль состоять последовательный предсказание несколько модель torchserve  workflow  позволять задавать последовательный параллельный граф обработка  последовательный  dag   pre_processing  m1   m1  m2   m2  postprocessing  input  function1  model1  model2  function2  output   параллельный граф dag   pre_processing model1 model2   model1 aggregate_func   model2 aggregate_func                            model1                                  input  preprocessing           aggregate_func                                                            model2  рассматривать задача  получаться  следующий последовательнопараллельный  граф  узел aggregate объединять координата номер распознавать текст           yolo                            v               plate         stn  coords                                         v                            lprnet                      v                 plate    aggregate texts      удобство простота данный модель  передаваться  вид словарь сериализация такой данные torchserve весьма  неэффективный  переводить строка добавлять перенос строка поэтому стараться передавать тензор байт учитывать workflow стартовать автоматически запуск сервер  необходимо явно посылать запрос это очень хотеться делать поднятие сервер   curl x post httplocalhost8081workflowsurlplate_recognition  использование модель модель определять сервер запускать выполнять определенный ранее модель workflow нужно посылать torchserve запрос использование plate_recognition пользоваться  rest   grpc  модель использоваться эндпоинт  predictions  workflow  wfpredict  response  requestspost     httplocalhost8080predictionsyolo dataimageopenrbread   response  requestspost     httplocalhost8080wfpredictplate_recognition      dataimageopenrbread   заключение инференс написать данный пример слишком простой целое бесполезный слишком сложный покрывать фишка фреймоврко инференс туториал раскрывать возможность torchserve поэтому советовать посмотреть документация получение  explanations  снятие  метрика работать сервер батчевание  подписываться  канал   рассказывать нейронка упор сервинг",
    "tags": [
        "torchserve",
        "triton",
        "инференс",
        "сервинг",
        "нейронные сети",
        "распознавание номеров",
        "plate recognition"
    ]
}