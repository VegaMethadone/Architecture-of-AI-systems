{
    "article_id": "727318",
    "article_name": "Снижаем размерность эмбеддингов предложений для задачи определения семантического сходства",
    "content": "привет хабр звать николай шукать data scientist участник  профессиональный сообщество nta  сегодня речь пойти ометод снижение размерность эмбеддинг длязадача определение семантический сходство предложение длячий это необходимый  скаждый год расти сложность модель решающий вопрос семантически контекстноориентированный обработка естественный язык  nlp  также забывать пропроблема мультиязычность модель это сильно сказываться наувеличение размер системный требование кжелеза дляих обучение дообучение дая просто запуск задача nlp сегодня это прикладной задача хотеться решать надоступный оборудование заразумный время аесли конкретно  я стоять задача находить обобщать текстовый данные представлять себя массив предложение точно знать чтосреди семантически схожий фраза однако прямой подход дляопределение семантический сходство набор фраза требовать память время решать проблема попытаться уменьшать размерность вектор признак предложение нокакпонимать останавливаться чтоэто давать какпонимать  врамок данный пост посмотреть какменяться оценка семантический сходство отизменение размерность эмбеддинг разный классический метод уменьшение навигация пост введение объятие hugging face разбираться датасет начинать снижение итог введение мера степень семантический сходство пары предложение любопытный аспект nlp отлично справляться сгруппировка схожий посмысл предложение предикат выискивать повтор убирать который снижать нагруженность модель который обрабатывать наш текстовый данные длярешение задача семантический сходство предложение нужно преобразовывать ввектор дляэтого воспользоваться эмбеддинг навход подаваться набор предложение наш случай дляпопарный сравнение анавыход преобразовываться вчисловой вектор этот предложение собственно подэмбеддинг быть понимать результат преобразование текстовой сущность вчисловой вектор модель преобразование выглядеть насегодня самый простой эффективный способ создание контекстуализированный эмбеддинг использовать  трансформер  модель машинный обучение отлично зарекомендовать всфера nlp архитектурный трансформер схожий сrnn система кодировщикдекодировщик кроме также предназначать дляобработка последовательность архитектура трансформер выглядеть следующий образ источник вотличие отrnn трансформер нетребовать обработка последовательность попорядок входной данные это текст трансформер нетребоваться обрабатывать конец текст обработка начало благодаря этот трансформер распараллеливаться легкий rnn оттого выигрывать вскорости обучение также важный особенность данный архитектура являться механизм внимание фокусироваться наважный сточка зрение контекст слово отдавать напрямую вобработка благодаря это трансформер обладать хороший долгосрочный память хороший умение учитывать контекст это делать трансформер выбор номер длярешение наш задача семантический сходство такой образ получать следующий модель определение семантический сходство функция метрика заключаться вопределение близость получать вектор дляэтого использовать разный инструмент останавливаться накосинусный сходство a b пмерной вектор θ угол они ab скалярный произведение вектор a b a b длина вектор вевклидов пространство a i  b i   iые компонент вектор a b соответственно дляуменьшение количество признак предложение воспользоваться классический метод снижение размерность цель уменьшать количество слабо информативный признак дляоблегчение модель нонепотерять вкачество информация тот получать значение семантический сходство какминимум незначительно плохой доуменьшение размерность схема снижение размерность выглядеть следующий образ получать эмбеддинг пониженный размерность также отправляться навход вфункция метрика вычисляться семантический сходство  приступать креализация описывать схема  объятие hugging face дляподбор датасет создание модель семантический сходство обращаться кзамечательный платформа  hugging face  stsb multi mt  это набор мультиязычный перевод англоязычный оригинал классический stsbenchmark датасет состоять изтреха колонка первый предложение второй предложение метрика схожесть 0до 5далее эталонный оценка датасти разбивать 3части train test dev какврамок пост вопрос точный донастройка рассматриваться небыть ограничиваться dev сплит 15тыс строка русскоязычный часть датасет  загружать датасет df_dev  load_datasetstsb_multi_mt nameru splitdev первый пять строка датасет sentence1 sentence2 similarity_score человек твердый шляпа   танцевать мужчина твердый шляпа танцевать 5 маленький ребенок ехать верхом   лошадь ребенок ехать лошадь 475 мужчина кормить мышь змея человек кормить змея мышь 5 женщина играть гитара человек играть гитара 24 женщина играть флейта человек играть флейта 275 среди модель выбор пасть  distilusebasemultilingualcasedv1  иссемейство  sentencetransformers   архитектура модель выглядеть следующий образ навход вмодель подаваться предложение оно проходить слой трансформер distilbertmodel преобразовываться вэмбеддинг который слой пулинг попадать наполносвязный слой dense свектор смещение bias тангенсальный активационный функция навыход получать эмбеддинг сразмерность 512 данный модель отображать предложение 512мерное векторный пространство  загружать модель model  sentencetransformerdistilusebasemultilingualcasedv1 разбираться датасет обрабатывать наш датасет длячий нормализовать эталонный оценка приводить кзначение 0до 1 измодель вытаскивать эмбеддинг рассчитать косинусный сходство который послужить основа длясравнение сцелевой метрика датасет изменять метрика снижение размерность res   f  true for df in df_dev     score  floatdfsimilarity_score50  нормализация эталонный оценка     embeddings  modelencodedfsentence1 dfsentence2     semantic_sim  1  cosineembeddings0 embeddings1  косинусный сходство пара предложение     resappenddfsentence1 dfsentence2 score semantic_sim     if f  true         mas_embed  embeddings         f  false     else             mas_embed  npconcatenatemas_embed embeddings axis0 собирать единый датафрейм df  pddataframeres columnssenetence1 sentence2 score semantic_sim начинать снижение мочь приступать кприменение метод снижение размерность выбирать четыре метод доступный вмодуль scikitlearndecomposition матричный декомпозиция pca  метод главный компонент fastica быстрый алгоритм дляанализ независимый компонент factor analysis  fa факторный анализ truncatedsvd  усеченный сингулярный разложение from sklearndecomposition import pca from sklearndecomposition import fastica from sklearndecomposition import factoranalysis from sklearndecomposition import truncatedsvd длясравнение метод себя сэталонный значение воспользоваться евклидов расстояние  x вектор эталонный оценка y m  вектор приближение присокращение размерность доm n число пар предложение длякоторых рассчитать косинусный сходство x i  y i  iые элемент соответствующий вектор эталонный оценка семантический   сходство семантический   сходство размерность 50 метод ica 10000 0958966 0953331 09500 0903258 0909175 10000 0938772 0916701 04800 0828721 0835421 05500 0805219 0771535 05230 0783895 0762820 такой образ получать вектор эталонный оценка основной вектор приближение семантический сходство вектор приближение петь размерность iго метод например размерность 50и метод ica приводить пример код дляметод ica eucl_dis_ica   for el in dims     ica  fastican_components  el     mas_embed_fit  icafit_transformmas_embed           семантический сходство     tmp_res       for i in range 0 3000 2         semantic_sim  1  cosinemas_embed_fiti mas_embed_fiti1         tmp_resappendsemantic_sim           евклидов расстояние      dffreduce_sim_ica_el  tmp_res     dfeucl_dis_ica  dfscore  dffreduce_sim_ica_el2     eucl_dis_icaappenddfeucl_dis_icasum  05 итого получать функция зависимость евклидовый расстояние число размерность находить локальный минимум евклидовый расстояние доэталонный оценка наинтересовать интервал 50 450 размерность получать оптимальный количество размерность существенный потеря информация визуализировать рассчитать данные pltfigurefigsize1275 dpi 80 pltplotdims eucl_dis_pca colorta",
    "tags": [
        "эмбеддинги",
        "эмбеддинг",
        "обработка текстов",
        "nlp",
        "natural language processing",
        "обработка текста"
    ]
}